{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02.01-FDDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarekGit/FACES_DNN/blob/master/notebooks/02_01_FDDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqNoJtMiLBfs",
        "colab_type": "text"
      },
      "source": [
        "### [Spis treści](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Praca_Dyplomowa.ipynb)\n",
        "### [poprzedni - 3. Bazy danych](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/02_00_Datasety.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV0_iV-tZQo8",
        "colab_type": "text"
      },
      "source": [
        "# FDDB (Face Detection Data Set and Benchmark)\n",
        "\n",
        "FDDB (Face Detection Data Set and Benchmark) [[1]](Bibliografia.ipynb) jest zbiorem danych dostępnych publicznie na [http://vis-www.cs.umass.edu/fddb/](http://vis-www.cs.umass.edu/fddb/). Zawiera 2845 zdjęć z 5171 oznaczonymi twarzami. Dataset został przygotowany tak by posiadał szeroki zakres trudności. Zawiera zróżnicowanie i często trudne do detekcji pozy głowy oraz zdjęcia o niskiej rozdzielczości i ostrości. Wystepują w nim obrazy kolorowe jak i w skali szarości o różnym stopniu jasności. Anotacji twarzy na zdjęciach dokonano za pomocą elips."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNFyJfgPZUk7",
        "colab_type": "text"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/DarekGit/FACES_DNN/master/Figures/2002_07_31_big_img_636.jpg\" alt=\"Zdjęcie z anotacjami eliptycznymi.\" width=\"600\" ><br>\n",
        "\n",
        "\n",
        "Rys. Zdjęcie z anotacjami eliptycznymi. <a href=\"https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Bibliografia.ipynb\">[1]</a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHIaVaILZhAl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Wszystkie zdjęcia wykorzystane do stworzenia datasetu pochodzą ze zbioru danych [\"Faces in the Wild\"](http://tamaraberg.com/faceDataset/index.html) [[3]](notebooks/Bibliografia.ipynb).\n",
        "\n",
        "Żródłem zdjęć był serwis informacyjny Yahoo. Autorzy FDDB analizując dostępny zbiór danych znaleźli wiele duplikatów zdjęć pochodzących z tego samego źródła. Zdecydowali się usunąć jak najwięcej duplikatów zdjęć. Przykładem takiej sytuacji są dwa pierwsze zdjęcia przedstawione na poniżej. Różnią się jedynie rozdzielczością oraz intensywnością kolorów. Poza i wyraz twarzy są identyczne dlatego zdjęcia zostały zakfalifikowane jako duplikaty. Kolejne dwa zdjęca mimo, że są prawie identyczne nieznacznie różnią się pozą głowy co spowodowało, że na etapie tworzenia datasetu zostały zakfalifikowane jako różne i nie zostały usunięte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hK1O5VuZjX5",
        "colab_type": "text"
      },
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/DarekGit/FACES_DNN/master/Figures/near_duplicate_images_c.png\" width=\"350\" alt=\"near_duplicate_images\"/>\n",
        "<img src=\"https://raw.githubusercontent.com/DarekGit/FACES_DNN/master/Figures/near_duplicate_images_d.png\" width=\"350\" alt=\"near_duplicate_images\"/>\n",
        "<img src=\"https://raw.githubusercontent.com/DarekGit/FACES_DNN/master/Figures/near_duplicate_images_a.png\" width=\"350\" alt=\"near_duplicate_images\"/>\n",
        "<img src=\"https://raw.githubusercontent.com/DarekGit/FACES_DNN/master/Figures/near_duplicate_images_b.png\" width=\"350\" alt=\"near_duplicate_images\"/>\n",
        "<br> Rys. Duplikaty i zdjęcia bliskie duplikatu. <a href=\"https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Bibliografia.ipynb\">[1]</a>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eew-N2n4Zsv9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Z zestawu danych wykluczono wszystkie obszary twarzy o wysokości lub szerokości mniejszej niż 20 pikseli. W przypadku niektórych twarzy podjęcie decyzji, czy przedstawia „twarz” nie było jednoznaczne. Czynniki takie jak niska rozdzielczość (prostokąt zielony), rozmycie obrazu (prostokąt niebieski) i pozycja głowy (prostokąt czerwony) utrudniały ocenę zdjęć trakcie anotacji."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWM6W7qeZs0O",
        "colab_type": "text"
      },
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/DarekGit/FACES_DNN/master/Figures/challenges_in_face_labeling.png\" width=\"450\" alt=\"challenges_in_face_labeling\"/>\n",
        "<br> Rys. Róźnorodność regionów reprezentujących obraz twarzy. <a href=\"https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Bibliografia.ipynb\">[1]</a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlX4kJ-Biz8i",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "W procesie anotacji autorzy przyjeli szerego zasad dotyczacych oceny ważności regionów obrazu jako regionów twarzy. Przyjęto min. zasadę by odrzucać obszary twarzy, w przypadku których żadne z dwóch oczu (ani okularów) nie było widoczne na zdjeciu. Pomijano również twarze co do których nie można było jednoznacznie oszacować ich pozycji, rozmiaru lub orientacji. Wszystkie wytyczne zostały umieszczone w załączniku A do artykułu \"FDDB: A Benchmark for Face Detection in Unconstrained Settings\". <a href=\"https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Bibliografia.ipynb\">[1]</a>\n",
        "<br><br>\n",
        "Ponieważ pojedyncza ludzka decyzja dotycząca określenia etykiety dla niektórych regionów obrazu może być niespójna, zastosowaliśmy podejście oparte na statystykach zgodności z wieloma ludzkimi adnotatorami. Wszystkie te regiony twarzy były prezentowane różnym osobom za pośrednictwem interfejsu internetowego w celu uzyskania wielu niezależnych decyzji dotyczących ważności tych regionów obrazu jako regionów twarzy. Adnotatorzy zostali poinstruowani, aby odrzucić obszary twarzy, w przypadku których żadne z dwóch oczu (ani okularów) nie było widoczne na obrazie. Poproszono ich również o odrzucenie regionu twarzy, jeśli nie byli w stanie (jakościowo) oszacować jego pozycji, rozmiaru lub orientacji. \n",
        "<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTrj5eJWIubx",
        "colab_type": "text"
      },
      "source": [
        "## Metryki FDDB\n",
        "\n",
        "Do oceny stopnia dopasowania pomiędzy detekcją a anotowanym regionem przyjęto miarę Intersection over Union, dla detekcji $d_{i}$ i anotacji $l_{j}$ opisaną przez autorów jako:<br><br>\n",
        "$$S(d_{i}, l_{j})=\\frac{area(d_{i}) \\cap area(l_{j})}{area(d_{i}) \\cup area(l_{j})}$$\n",
        "<br>\n",
        "Przyjęto również 2 metryki ewaluacji:\n",
        "\n",
        "* Discrete score (DS) : $y_{i}=\\delta_{S(d_{i},v_{i})>0.5}$\n",
        "* Continuous score (CS): $y_{i}=S(d_{i}, v_{i})$,\n",
        "<br>\n",
        "dla detekcji $d_{i}$ i dopasowania $v_{i}$.<br>\n",
        "\n",
        "W przypadku abu metryk autorzy zalecają analizę krzywych ROC w celu porównania wydajności modeli na tym zbiorze danych.\n",
        "Przykładowe krzywe ROC dla detektorów Viola-Jones detector, Mikolajczyk’s face detector, W. Kienzle face detection library zostały przedstawione na poniższych wykresach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLN4pNJkZ-uO",
        "colab_type": "text"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/DarekGit/FACES_DNN/master/Figures/roc_discrete_score.png\" width=\"400\" alt=\"ROC discrete score (DS)\"/><br>\n",
        "<i>ROC discrete score (DS)</i>\n",
        "<br><br>\n",
        "<img src=\"https://raw.githubusercontent.com/DarekGit/FACES_DNN/master/Figures/roc_continuous_score.png\" width=\"400\" alt=\"ROC continuous score (CS)\"/><br> \n",
        "<i>ROC continuous score (CS)</i>\n",
        "<br>\n",
        "<b>Rys. Krzywe ROC dla różnych algorytmów wykrywania twarzy. <a href=\"https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Bibliografia.ipynb\">[1]</a>\n",
        "</b>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3RwA8KYiz_9",
        "colab_type": "text"
      },
      "source": [
        "## Pobranie datasetu\n",
        "\n",
        "Oryginalny zestaw obrazów można pobrać ze strony http://tamaraberg.com/faceDataset/originalPics.tar.gz <br>Rozpakowanie pliku **originalPics.tar.gz** do wskazanego podkatalogu tworzy określoną strukturę katalogów zawierających zdjęcia:\n",
        "```\n",
        "FDDB/ rok/ miesiąc/ dzień/ big/ *.jpg\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMFWwn6d_RQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir FDDB\n",
        "!wget  http://tamaraberg.com/faceDataset/originalPics.tar.gz \n",
        "!tar -xf originalPics.tar.gz -C FDDB\n",
        "!wget  http://vis-www.cs.umass.edu/fddb/FDDB-folds.tgz\n",
        "!tar -xf FDDB-folds.tgz -C FDDB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiYzkR1WEenr",
        "colab_type": "text"
      },
      "source": [
        "## Annotacje\n",
        "\n",
        "Rozpakowanie pliku **FDDB-folds.tgz** tworzy katalog **FDDB-folds** zawieracjący pliki z anotacjami zdjęć FDDB-fold-xx-ellipseList.txt i pliki **FDDB-fold-xx.txt** przechowujące ścieżki go zdjęć.  \n",
        "Przykładowa zawartość pliku **FDDB-fold-01.txt**\n",
        "```txt\n",
        "2002/08/11/big/img_591\n",
        "2002/08/26/big/img_265\n",
        "2002/07/19/big/img_423\n",
        "2002/08/24/big/img_490\n",
        "```\n",
        "oraz **FDDB-fold-01-ellipseList.txt**\n",
        "\n",
        "```\n",
        "2002/08/11/big/img_591\n",
        "1\n",
        "123.583300 85.549500 1.265839 269.693400 161.781200  1\n",
        "2002/08/26/big/img_265\n",
        "3\n",
        "67.363819 44.511485 -1.476417 105.249970 87.209036  1\n",
        "41.936870 27.064477 1.471906 184.070915 129.345601  1\n",
        "70.993052 43.355200 1.370217 340.894300 117.498951  1\n",
        "2002/07/19/big/img_423\n",
        "1\n",
        "87.080955 59.379319 1.550861 255.383099 133.767857  1\n",
        "2002/08/24/big/img_490\n",
        "1\n",
        "54.692105 35.056825 -1.384924 145.665694 78.101005  1\n",
        "```\n",
        "\n",
        "Format zastosowanych anotacji został określony zgodnie z ponizszym szablonem:\n",
        "\n",
        "```\n",
        "<nazwa pliku wraz ze ścieżka>\n",
        "<ilość twarzy anotowanych na zdjęciu>\n",
        "<anotacja twarzy 1>\n",
        "<anotacja twarzy 2>\n",
        "...\n",
        "<anotacja twarzy n>\n",
        "```\n",
        "\n",
        "Każda twarz jest oznaczona przez:\n",
        "```\n",
        "<major_axis_radius minor_axis_radius angle center_x center_y 1>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlVXXxHy9aC",
        "colab_type": "text"
      },
      "source": [
        "## Wyniki detekcji\n",
        "\n",
        "By wykorzystać narzędzia do ewaluacji wyników detekcji udostępnione wraz z datasetem FDDB należy wyniki zapisać zgodnie z poniższym szablonem. \n",
        "\n",
        "```\n",
        "<nazwa pliku wraz ze ścieżka>\n",
        "<ilość twarzy anotowanych na zdjęciu>\n",
        "<anotacja twarzy 1>\n",
        "<anotacja twarzy 2>\n",
        "...\n",
        "<anotacja twarzy n>\n",
        "```\n",
        "\n",
        "Anotacje twarzy mogą zostać zapisane w dwuch formatach:\n",
        "* anotacje prostokątne w formacie <left_x top_y width height detection_score> \n",
        "* anotacje eliptyczne w formacie identycznym jak dane wejściowe  <major_axis_radius minor_axis_radius angle center_x center_y detection_score>.\n",
        "\n",
        "Wymagane jest również by kolejność plików była zgodna z annotatedList.txt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-6s8TNwuACQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### Utworzone metryki datasetu, pomiary i testy zostały umieszczone jako załącznik w pliku [02_01_FDDB_DD.ipynb](02_01_FDDB_DD.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2uLLg-g3lOF",
        "colab_type": "text"
      },
      "source": [
        "W notebook 02_01_FDDB_DD.ipynb wykonano pomiary, przegląd oraz testy datasetu. Podstawowe dane o zdjęciach zapisano w strukturze metrics, która jest używana później do szybkiego dostępu do zdjęć i danych.\n",
        "Na podstawie przeglądu zdjęć ustalono, iż górną krawędź prostokąta opisującego twarz należy odbniżyć do 0.6 górnego promienia elipsy.\n",
        "Opis FDDB zawarty jest w pliku: https://github.com/DarekGit/FACES_DNN/blob/master/data/FDDB_metrics.json\n",
        "\n",
        "<br>Do analizy datasetu FDDB utworzono:\n",
        "\n",
        "narzędzia do wizualizacji oznaczenia twarzy (elipsy/obrócone prostokąty/ground truth).\n",
        "funkcję do pomiaru i wizualizacji mAP.\n",
        "\n",
        "<br>**Zbiór FDDB nie zawiera wydzielonego zestawu zdjęć do walidacji.**\n",
        "<br>Ze zbioru FDDB wybrano zdjęcia do walidacji testów. Do wyboru przyjęto założenia, że ilość twarzy powinna zapewniać błąd pomiaru mniejszy od 0,5%, rozkład wielkości zdjęć small, medium i large powinien być proporcjonalny do rozkładu cełego zbioru, oraz cechy mAP mierzone po MTCNN powinny być pdobne do cech mAP dla całego zbioru. Zdjęcia do walidacji zostały oznaczone w metrics w polu 'val'=True.\n",
        "\n",
        "<br>Wykonano również pierwsze pomiary datasetu FDDB na pretrenowanym modelu MTCNN a otrzymane wyniki były punktem odniesienia do dalszych badań. Za punkt odniesienia przyjęto **wynik AP50 na poziomie 92,4%**.\n",
        "\n",
        "Wyniki detekcji w FDDB dla predefiniowanego modelu MTCNN zawarte są w pliku: https://github.com/DarekGit/mAP/blob/master/data/MTCNN_results.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93UTPcfu8gI1",
        "colab_type": "text"
      },
      "source": [
        "### [następny - WIDER FACE](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/02_02_WIDER_FACE.ipynb)\n",
        "### [Spis treści](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Praca_Dyplomowa.ipynb)"
      ]
    }
  ]
}