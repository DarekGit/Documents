{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_00_Podsumowanie.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarekGit/FACES_DNN/blob/master/notebooks/08_00_Podsumowanie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlFNzbPN9W1R",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "[Spis treści](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Praca_Dyplomowa.ipynb) | [1. Wstęp](01_00_Wstep.ipynb) | [2. Metryki oceny detekcji](02_00_Miary.ipynb) | [3. Bazy danych](03_00_Datasety.ipynb) | [4. Przegląd metod detekcji](04_00_Modele.ipynb) | [5. Detekcja twarzy z wykorzystaniem wybranych architektur GSN](05_00_Modyfikacje.ipynb) | [6. Porównanie modeli](06_00_Porownanie.ipynb) | [7. Eksport modelu](07_00_Eksport_modelu.ipynb) | [8. Podsumowanie i wnioski](08_00_Podsumowanie.ipynb) | [Bibliografia](Bibliografia.ipynb)\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1QsrZV2S_oc",
        "colab_type": "text"
      },
      "source": [
        "## 8. Podsumowanie i wnioski"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15YadEQoT5vY",
        "colab_type": "text"
      },
      "source": [
        "do edycji..\n",
        "\n",
        "\n",
        "\n",
        "W niniejszej pracy opracowano i przeanalizowano modele umożliwiające detekcję twarzy w oparciu o architekturę Faster R-CNN. W trakcie pracy zastosowano dwa rozwiązania.\n",
        "W pierwszym wykorzystano Faster R-CNN z FPN Resnet50. W oparciu o to rozwiązanie zostały wytrenowane 2 modele: faster_rcnn_R_50_FPN_3x pretrenowany na datasecie COCO train2017 a następnie dotrenowany na zbiorze treningowym WIDER FACE oraz scratch_faster_rcnn_R_50_FPN_gn trenowany od zera na zbiorze treningowym WIDER FACE. \n",
        "Kierując się opisem procedury trenowania zaproponowanej w artykule \"Rethinking ImageNet Pre-training\" [15] udało się uzyskać bardzo dobre wyniki i porównywalne wyniki.\n",
        "\n",
        "\n",
        "W drugim rozwiązaniu do  detekcji twarzy wykorzystano Faster R-CNN MobileNet \n",
        "V2.\n",
        "W czasie treningu zastosowano nowoczesne rozwiązania pozwalające na szybsze i stabilniejsze trenowanie sieci takie jak: Frozen Batch Normalization, Batch normalization, funkcję aktywacji Mish.\n",
        "Dzięki zastosowanej procedurze trenowania uzyskano poprawę wyników o 2pp. \n",
        "Wykazano, iż odchudzanie sieci poprzez separowanie warstw konwolucyjnych, nie wpływa znacząco na pogorszenie wyników. A usprawnienia z innych rozwiązań mogą znaczą poprawić jej działanie. Lepiej radzi sobie z obrazami dużej rozdzielczości.\n",
        "\n",
        "Wytrenowany sieci neuronowe zostały zostały przebadane pod względem skuteczności i porównane.\n",
        "Generalnie uzyskano dobre wyniki mAP, AP50, time, które nie odbiegają od wyników osiąganych przez inne zespoły pracujące na datasecie WIDER FACE.\n",
        "Potwierdzono również skuteczność przygotowanego modułu mAP. w ramach porównań Zaobserwowano rozbieżności z pomiarem Detectron2 na pozomie poniżej 1pp, a jednocześnie moduł mAP umożliwiał w prosty sposób wykonanie pomiarów dla sieci zewnętrznych np. MTCNN.\n",
        "\n",
        "Na koniec udało się przeporwadzić eksport do innych modeli i wykazać skuteczność działania na przykładzie TorchSrcipt (jit)\n",
        "\n",
        "\n",
        "Przygotowaliśmy własna bazę zdjęć FACES DD dużej rozdzilczości średnio 6Mpix. Z ciekawaszych obserwacji należy wskazać, iż MobileNet uzyskał lepsze wyniki dla tej bazy, pomimo zdjęć dużej rozdzielczości."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KabdpqB_8hih",
        "colab_type": "text"
      },
      "source": [
        "> 1. Generalnie uzyskano dobre wyniki mAP, AP50, time, które nie odbiegają od wyników osiąganych przez inne zespoły pracujące na datasecie WIDER FACE.\n",
        "\n",
        "> 1.  Potwierdziliśmy skuteczność własnego modułu mAP, w ramach porównań zaobserwowaliśmy rozbieżności z pomiarem Detectron2 na pozomie poniżej 1pp, a jednocześnie moduł mAP umożliwiał w prosty sposób wykonanie pomiarów dla sieci zewnętrznych np. MTCNN.\n",
        "\n",
        "> 1. Na przykładzie MobileNet wykazaliśmy, iż odchudzanie sieci poprzez separowanie warstw konwolucyjnych, nie wpływa znacząco na pogorszenie wyników. A usprawnienia z innych rozwiązań mogą znaczą poprawić jej działanie. Lepiej radzi sobie z obrazami dużej rozdzielczości.\n",
        "\n",
        "1. Na tym tle wyróżnia się DeTr, który wprowadza genralizację rozwiązania przez zastosowanie tylko sieci transformer. Dla ImageNet udało się uzyskać (80 klas do 100 obiektów na obraz) wyniki lepsze od innych rozwiązań. Jednak nadal mamy problem z uczeniem sieci do innych zastosowań.\n",
        "> 1. Dzięki zastosowanej procedurze trenowania uzyskano poprawę wyników o 2pp dla Detctron2 z MobileNetV2. Przygotowano również dodatkowe narzędzia opisane w uwagach praktycznych ułatwiające prace z repozytoriami i zewnętrznymi sieciami.\n",
        "> 1. Z powodzeniem zasotoswaliśmy nowe usprawnienia jak funkcja aktywacji Mish, przełączanie w trakcie procesu uczenia BN/FrozenBN, GIoU.\n",
        "\n",
        "> 1. Przygotowaliśmy własna bazę zdjęć FACES DD dużej rozdzilczości średnio 6Mpix. Z ciekawaszych obserwacji należy wskazać, iż MobileNet uzyskał lepsze wyniki dla tej bazy, pomimo zdjęć dużej rozdzielczości.\n",
        "\n",
        "\n",
        "> 1. Udało się przeporwadzić eksport do innych modeli i wykazać skuteczność działania na przykładzie TorchSrcipt (jit)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SrZyY8TA9cbC"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}