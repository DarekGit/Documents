{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_00_Podsumowanie.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarekGit/FACES_DNN/blob/master/notebooks/08_00_Podsumowanie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlFNzbPN9W1R",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "[Spis treści](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Praca_Dyplomowa.ipynb) | [1. Wstęp](01_00_Wstep.ipynb) | [2. Metryki oceny detekcji](02_00_Miary.ipynb) | [3. Bazy danych](03_00_Datasety.ipynb) | [4. Przegląd metod detekcji](04_00_Modele.ipynb) | [5. Detekcja twarzy z wykorzystaniem wybranych architektur GSN](05_00_Modyfikacje.ipynb) | [6. Porównanie modeli](06_00_Porownanie.ipynb) | [7. Eksport modelu](07_00_Eksport_modelu.ipynb) | [8. Podsumowanie i wnioski](08_00_Podsumowanie.ipynb) | [Bibliografia](Bibliografia.ipynb)\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1QsrZV2S_oc",
        "colab_type": "text"
      },
      "source": [
        "Pierwsze tezy do podsumowania:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KabdpqB_8hih",
        "colab_type": "text"
      },
      "source": [
        "1. Generalnie uzyskano dobre wyniki mAP, AP50, time, które nie odbiegają od wyników osiąganych przez inne zespoły pracujące na datasecie WIDER FACE.\n",
        "1.  Potwierdziliśmy skuteczność własnego modułu mAP, w ramach porównań zaobserwowaliśmy rozbieżności z pomiarem Detectron2 na pozomie poniżej 1pp, a jednocześnie moduł mAP umożliwiał w prosty sposób wykonanie pomiarów dla sieci zewnętrznych np. MTCNN.\n",
        "1. Na przykładzie MobileNet wykazaliśmy, iż odchudzanie sieci poprzez separowanie warstw konwolucyjnych, nie wpływa znacząco na pogorszenie wyników. A usprawnienia z innych rozwiązań mogą znaczą poprawić jej działanie. Lepiej radzi sobie z obrazami dużej rozdzielczości.\n",
        "1. Na tym tle wyróżnia się DeTr, który wprowadza genralizację rozwiązania przez zastosowanie tylko sieci transformer. Dla ImageNet udało się uzyskać (80 klas do 100 obiektów na obraz) wyniki lepsze od innych rozwiązań. Jednak nadal mamy problem z uczeniem sieci do innych zastosowań.\n",
        "1. Dzięki zastosowanej procedurze trenowania uzyskano poprawę wyników o 2pp dla Detctron2 z MobileNetV2. Przygotowano również dodatkowe narzędzia opisane w uwagach praktycznych ułatwiające prace z repozytoriami i zewnętrznymi sieciami.\n",
        "1. Z powodzeniem zasotoswaliśmy nowe usprawnienia jak funkcja aktywacji Mish, przełączanie w trakcie procesu uczenia BN/FrozenBN, GIoU.\n",
        "1. Przygotowaliśmy własna bazę zdjęć FACES DD dużej rozdzilczości średnio 6Mpix. Z ciekawaszych obserwacji należy wskazać, iż MobileNet uzyskał lepsze wyniki dla tej bazy, pomimo zdjęć dużej rozdzielczości.\n",
        "1. Udało się przeporwadzić eksport do innych modeli i wykazać skuteczność działania na przykładzie TorchSrcipt (jit)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SrZyY8TA9cbC"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}