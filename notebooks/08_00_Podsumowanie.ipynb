{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_00_Podsumowanie.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNvLpErUmYUFgUnD0M7RucS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarekGit/FACES_DNN/blob/master/notebooks/08_00_Podsumowanie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlFNzbPN9W1R",
        "colab_type": "text"
      },
      "source": [
        "### [Spis treści](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Praca_Dyplomowa.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KabdpqB_8hih",
        "colab_type": "text"
      },
      "source": [
        "Pierwsze tezy do podsumowania:\n",
        "1. Generalnie uzyskano dobre wyniki:\n",
        "    1. mAP, AP50, time - które nie odbiegają od wyników osiąganych przez inne zespoły\n",
        "    2. nie udało się porównać modeli w ramach konkursu\n",
        "2.  potwierdziliśmy skuteczność własnego modułu mAP, w ramach porównań zaobserwowaliśmy rozbieżności z pomiarem Detectron2 na pozomie poniżej 1pp, a jednocześnie moduł mAP umożliwiał w prosty sposób wykonanie pomiarów dla sieci zewnętrznych np. MTCNN\n",
        "3. Obserwujemy ujednolicanie rozwiązań dla różnych modeli na przykładzie YOLO V4 można wskazać, iż zawiera ona rozwiazania z Retinanet, RCNN, SPP, Resnet oraz cały dodatkowy zestaw usprawnień, które obecnie są wykorzystywane w innych rozwiązaniach.\n",
        "4. Na przykładzie MobileNet wykazaliśmy, iż odchudzanie sieci poprzez separowanie warstw konwolucyjnych, nie wpływa znacząco na pogorszenie wyników. A usprawnienia z innych rozwiązań mogą znaczą poprawić jej działanie. Lepiej radzi sobie z obrazami dużej rozdzielczości.\n",
        "5. Na tym tle wyróżnia się DeTr, który wprowadza genralizację rozwiązania przez zastosowanie tylko sieci transformer. Dla ImageNet udało się uzyskać (80 klas do 100 obiektów na obraz) wyniki lepsze od innych rozwiązań. Jednak nadal mamy problem z uczeniem sieci do innych zastosowań.\n",
        "6. Dzięki zastosowanej procedurze trenowania uzyskano poprawę wyników o 2pp dla Detctron2 z MobileNetV2. Przygotowano również dodatkowe narzędzia opisane w uwagach praktycznych ułatwiające prace z repozytoriami i zewnętrznymi sieciami.\n",
        "7. Z powodzeniem zasotoswaliśmy nowe usprawnienia jak funkcja aktywacji Mish, przełączanie w trakcie procesu uczenia BN/FrozenBN, GIoU.\n",
        "7. Przygotowaliśmy własna bazę zdjęć FACES DD dużej rozdzilczości średnio 6Mpix. Z ciekawaszych obserwacji należy wskazać, iż MobileNet uzyskał lepsze wyniki dla tej bazy, pomimo zdjęć dużej rozdzielczości.\n",
        "8. Udało się przeporwadzić eksport do innych modeli i wykazać skuteczność działania na przykładzie TorchSrcipt (jit)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SrZyY8TA9cbC"
      },
      "source": [
        "### [Spis treści](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Praca_Dyplomowa.ipynb)"
      ]
    }
  ]
}