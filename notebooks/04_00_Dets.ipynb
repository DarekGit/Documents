{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_00_Dets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNFFo3nlQKmFbFd1sb/o2oN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarekGit/FACES_DNN/blob/master/notebooks/04_00_Dets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUYQvot5WYlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl1gpedgbEWv",
        "colab_type": "text"
      },
      "source": [
        "##Podstawowe Metody Wykrywania Obiektów<br>\n",
        "<b>Wykrywanie obiektów </b> jest jedną z dziedzin, która przeżywa gwałtowny rozwój w obszarze sieci neuronowych. Konieczoność jednoczesnego określenia lokalizacji oraz klasy obietków sprawia, że jest to jedno z najtrudniejszych zadań w dziedzinie sieci neuronowych. Model w tym zastosowaniu musi  określić, gdzie znajdują się obiekty na danym obrazie, zwanym lokalizacją obiektu i do której kategorii należy każdy obiekt, czyli klasyfikacją obiektu.<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsDvky1dnK0w",
        "colab_type": "text"
      },
      "source": [
        "###<br><b>1. Histogram of Oriented Gradients (HOG)</b><br>\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"../Figures/Dets/HOG.png?raw=1\" alt=\"R_CNN\" width=\"400\" >\n",
        "</div>\n",
        "\n",
        "<br>Histogram zorientowanych gradientów (HOG) zasadniczo jest deskryptorem cech, który jest używany do wykrywania obiektów w przetwarzaniu obrazów. Metoda histogramu zorientowanych gradientów obejmuje wykrywanie orientacji gradientu we wskazanych częściach obrazu, metodami typu przesuwane okno wykrywania lub obszar zainteresowania (ROI). Jedną z zalet funkcji podobnych do HOG jest ich prostota. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7yc1faYb_wE",
        "colab_type": "text"
      },
      "source": [
        "###<br><b>2. Region-based Convolutional Neural Networks (R-CNN)</b><br>\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"../Figures/Dets/R_CNN.png?raw=1\" alt=\"R_CNN\" width=\"400\" >\n",
        "</div>\n",
        "\n",
        "<br>The Region-based Convolutional Network method (RCNN) to połączenie propozycji obszarów występowania obiektów (ROI) z sieciami konwolucyjnymi (CNN). R-CNN wykorzystuje głębokie sieci  neuronowe do lokalizowania obiektów i uczeniu modelu o dużej pojemności przy zastosowaniu  niewielkiej ilości danych wejściowych z adnotacjami. Osiąga wyższą dokładność wykrywania obiektów dzięki zastosowaniu głębokiej sieci ConvNet do klasyfikowania propozycji obiektów. R-CNN ma możliwość skalowania do tysięcy klas obiektów bez wykorzystania metod pomocniczych. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK10oZJmuRFQ",
        "colab_type": "text"
      },
      "source": [
        "###<br><b>3. Single Shot Detector (SSD)</b><br>\n",
        "\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"../Figures/Dets/SSD.png?raw=1\" alt=\"SSD\" width=\"400\" >\n",
        "</div>\n",
        "\n",
        "<br> Single Shot Detector (SSD) to metoda wykrywania obiektów na obrazach za pomocą jednej głębokiej sieci neuronowej.  Sieć detektorów  łączy prognozy z wielu map obiektów o różnych rozdzielczościach, aby w naturalny sposób obsługiwać obiekty o różnych rozmiarach. <br>\n",
        "\n",
        "Zalety SSD:\n",
        "- Sieć SSD całkowicie eliminuje generowanie propozycji i kolejne etapy ponownego próbkowania pikseli lub funkcji i łączy wszystkie obliczenia w jednej sieci.\n",
        "- Łatwy do przeszkolenia i prosty do zintegrowania z innymi systemami.\n",
        "- SSD ma konkurencyjną dokładność w stosunku do metod, które wykorzystują dodatkowy krok propozycji obiektu, i jest znacznie szybszy, zapewniając jednolitą strukturę zarówno dla szkolenia, jak i detekcji.\n",
        "\n",
        "\n",
        "<br>Więcej informacji dostępnych jest na stronie:<br\"https://arxiv.org/pdf/1512.02325.pdf%EF%BC%89\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxyz6eBnppE9",
        "colab_type": "text"
      },
      "source": [
        "###<br><b>4. Fast R-CNN</b><br>\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"../Figures/Dets/Fast_R_CNN.png?raw=1\" alt=\"Fast R_CNN\" width=\"400\" >\n",
        "</div>\n",
        "\n",
        "<br> Napisany w Pythonie i C ++ (Caffe), Fast Region-Based Convolutional Network lub Fast R-CNN to algorytm uczący się do wykrywania obiektów. Algorytm ten eliminuje głównie wady R-CNN i SPPnet, jednocześnie poprawiając ich szybkość i dokładność. <br>\n",
        "\n",
        "<br>Zalety Fast R-CNN:\n",
        "\n",
        "- Wyższa jakość wykrywania (mAP) niż R-CNN, SPPnet\n",
        "- Trening jednoetapowe, z wykorzystaniem wieloelementowej  fuckji straty\n",
        "\n",
        "\n",
        "<br>Więcej informacji na stronie: „http://openaccess.thecvf.com/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf”\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "324DCa7jsuS0",
        "colab_type": "text"
      },
      "source": [
        "###<br><b>5. Spatial Pyramid Pooling (SPP-net)</b><br>\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"../Figures/Dets/SPP.png?raw=1\" alt=\"SPP\" width=\"400\" >\n",
        "</div>\n",
        "\n",
        "<br> Spatial Pyramid Pooling (SPP-net) to struktura sieciowa, która może generować reprezentację o stałej długości niezależnie od rozmiaru / skali obrazu.SPP-net poprawia  metody klasyfikacji obrazów oparte na CNN. Korzystając z sieci SPP można obliczyć mapy cech z całego obrazu tylko raz, a następnie połączyć cechy w podobrazach w celu wygenerowania reprezentacji o stałej długości. Ta metoda pozwala uniknąć wielokrotnego obliczania cech konwolucyjnych.\n",
        "\n",
        "<br> Więcej informacji dostępnych jest na stronie:<br>\n",
        "\"https://arxiv.org/pdf/1406.4729.pdf)%C3%AC%20%CB%9C\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JhZcpqfwDSr",
        "colab_type": "text"
      },
      "source": [
        "###<br><b>6. Faster R-CNN</strong></b><br>\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"../Figures/Dets/Faster_R_CNN.png?raw=1\" alt=\"Faster RCNN\" width=\"400\" >\n",
        "</div>\n",
        "\n",
        "<br> Faster R-CNN to algorytm wykrywania obiektów podobny do R-CNN. Algorytm ten wykorzystuje Region Proposal Network (RPN), który współdzieli funkcje splotu pełnego obrazu z siecią detekcyjną bardzije efektywnie niż R-CNN i Fast R-CNN. Sieć propozycji regionów jest siecią konwolucyjną, która jednocześnie przewiduje granice obiektu oraz ocenia klasę obiektu dla każdej propozycji.\n",
        "\n",
        "\n",
        "\n",
        "<br>Więcej informacji dostępnych jest na stronie:<br>\n",
        "\"http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1gADrvByVis",
        "colab_type": "text"
      },
      "source": [
        "###<br><b>7. Region-based Fully Convolutional Network (R-FCN)</b><br>\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"../Figures/Dets/R_FCN.png?raw=1\" alt=\"R_FCN\" width=\"400\" >\n",
        "</div>\n",
        "\n",
        "<br> Region-based Fully Convolutional Networks lub R-FCN to  detektor bazujący na regionach do wykrywania obiektów. W przeciwieństwie do innych detektorów opartych na regionach, które stosują kosztowną podsieć ROI, taką jak Fast R-CNN lub Faster R-CNN, ten detektor jest w pełni splotowy, a prawie wszystkie obliczenia są wspólne dla całego obrazu.\n",
        "\n",
        "<br> R-FCN składa się ze współdzielonych, w pełni konwolucyjnych warstw, i daje lepsze wyniki niż Faster R-CNN. .\n",
        "\n",
        "<br> Więcej informacji dostępnych jest na stronie:<br>\n",
        "<a href=\"https://arxiv.org/pdf/1605.06409.pdf\" rel=\"nofollow\">arxiv.org</a>.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSZizC0SWZMS",
        "colab_type": "text"
      },
      "source": [
        "###<br><b>8. YOLO (You Only Look Once)</b><br>\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"../Figures/Dets/YOLO.png?raw=1\" alt=\"YOLO\" width=\"400\" >\n",
        "</div>\n",
        "\n",
        "<br>You Only Look Once lub YOLO to jeden z popularnych algorytmów wykrywania obiektów używanych na całym świecie. Według naukowców z Facebook AI Research, ujednolicona architektura YOLO jest niezwykle szybka. Podstawowy model YOLO przetwarza obrazy w czasie rzeczywistym z szybkością 45 klatek na sekundę, a dla wersji Fast YOLO uzyskujemy aż 155 klatek na sekundę, jednocześnie osiągając dwukrotnie wyższą wartość MAP niż wcześniejszych detektorów działających w czasie rzeczywistym.\n",
        "\n",
        "\n",
        "<br>Więcej informacji dostępnych jest na stronie:<br><a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf\" \n",
        "rel=\"nofollow\">cv-foundation.org</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUOsSpcD1vQT",
        "colab_type": "text"
      },
      "source": [
        "###<br>Uwaga:<br>\n",
        "\n",
        "Dla entuzjastów, zagadnieniami komputerowego przetwarzania obrazów zajmuje się dedykowana konferencja <a href=\"https://cvdc.adasci.org/\" data-wpel-link=\"external\" target=\"_blank\" rel=\"nofollow\">Computer Vision DEVCON</a>. Jest to dwudniowa konferencja, która ma na celu zgromadzenie praktyków komputerowego przetwarzania obrazów i innowatorów na jednej platformie, aby dzielić się i omawiać najnowsze osiągnięcia w tej dziedzinie. Ostatnia odbyła sie w dniach 13-14 Sierpnia 2020 roku."
      ]
    }
  ]
}