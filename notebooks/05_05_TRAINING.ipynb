{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_05_TRAINING.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOaNlucXXQYa/zhE2Y4IpEJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarekGit/FACES_DNN/blob/master/notebooks/05_05_TRAINING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIKTH5ChEoQE",
        "colab_type": "text"
      },
      "source": [
        "## Procedura trenowania sieci na przykładzie Detectron2 z MobileNetV2\n",
        "\n",
        "W celu przyspieszenia procesu uczenia i wyboru hiperparametrów do modofikacji i testów, rozdzielono notebooki na cześć trenującą oraz analizy wyników cząstkowych.\n",
        "<br><br>Notebook trenujący odkłada wyniki cząstkowe do katalogu dedykowanego dla używanej konfiguracji. Ze względu na rozmiar zebranych wyników przekraczający 50GB wykorzystano google drive.\n",
        "<br>Przykład notebooka trenującego końcowy etap modelu 'BN_Mish_V2_250+F_2_50k': <br>\n",
        "[ mobilenet_v2_Mish_V22F.ipynb](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/WIDERFACE_Detectron2_from_scratch_DD_mobilenet_v2_Mish_V22F.ipynb)\n",
        "\n",
        "<br>Notebook testowy posiada zesłownikowany dostęp do wyników cząstkowych oraz narządzenia do analizy i porównania wyników.<br>\n",
        "Notebook testujący: [ mobilenet_v2_test.ipynb](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/WIDERFACE_Detectron2_DD_mobilenet_v2_test.ipynb)\n",
        "\n",
        "<br>W trakcie trenowaniu modelu dla wybranych parametrów modelu - wykonywano testy wyników cząstkowych. W przypadku osiągnięcia optymalmaksymalnego nego wyniku dla danej konfiguracji - tworzono podkatalog z nowym notebookiem ze zmodyfikowanym zestawem parametrów sieci i rozpoczynano doszkalanie sieci od  etapu najlepszego wyniku poprzedniego treningu. Wyboru parametrów dokonano pod kątem optymalizacji wyników mAP50.\n",
        "<br>W ten sposób powstało drzewo katalogów dla testów z kolejnymi notebookami dla zmodyfikowanych zestawów hiperparametrów. Każdy katalog zawiera notebook ze specyficznymi parametrami, pliki konfugraycyjne, wyniki cząstkowe, wizualizacje wyników.\n",
        "<br>Dla przyspeiszenia procesu trenowano kilka modeli jednocześnie.\n",
        "\n",
        "<br>Trening rozpoczęto od parametrów domyślnych w repozytorium  Detectron2 z backbone MobilenetV2, nstępnie sprawdzono trening dla BN w dwóch wersjach, kolejnym etapem był trening dla BN z Mish w 3 wersjach, z następującymi podkatologami:\n",
        "```\n",
        "- MN2\n",
        "- MN2_BN \n",
        "- MN2_BN_V2\n",
        "- MN2_Mish \n",
        "- MN2_Mish_V2 \n",
        "           - V22  \n",
        "                  - V222\n",
        "           - V22F \n",
        "           - V22F2\n",
        "                  - V22F22\n",
        "           - V22F3 \n",
        "           - V22F4 \n",
        "- MN2_Mish_V3 \n",
        "           - V32 \n",
        "```\n",
        " z następującymi modyfikacjami parametrów trenujących:\n",
        "```\n",
        "- MN2        FrozenBN LR 1e-3 GAMMA 0.5 SCHEDULER 40k,100k,200k,400k do 800k iteracji\n",
        "\n",
        "- MN2_BN     Frozen -> Batch Normalization\n",
        "\n",
        "- MN2_BN_V2  poprawiono normalizacje dla WiderFace GAMMA 0.3 SCHEDULER 50k,150k,250k,400k do 800k iteracji\n",
        "\n",
        "- MN2_Mish   wprowadzono funkcję aktywacji Mish, BN GAMMa 0.3  SCHEDULER 50k,150k,250k,400k do 800k iteracji\n",
        "\n",
        "- MN2_Mish_V2 LR 2e-3 GAMMA 0.3 SCHEDULER 150k,210k,270k,330k do 400k iteracji\n",
        "\n",
        "           - V22   douczanie od 250k, LR = 4e-6 GAMMA 0.2 SCHEDULER 30k,50k do 70k iteracji\n",
        "\n",
        "                  - V222 do 120k iteracji\n",
        "\n",
        "           - V22F douczanie od 250k z FrozenBN LR = 4e-6 GAMMA 0.2 SCHEDULER 30k,50k do 100k iteracji\n",
        "\n",
        "           - V22F2 douczanie od 250k z FrozenBN LR = 1e-3 GAMMA 0.2 SCHEDULER 30k,50k do 70k iteracji\n",
        "\n",
        "                  - V22F22 do 300k\n",
        "\n",
        "           - V22F3 douczanie od 250k z FrozenBN LR = 2e-5 GAMMA 0.2 SCHEDULER 30k,50k do 70k iteracji\n",
        "\n",
        "           - V22F4 douczanie od 250k z FrozenBN LR = 1e-4 GAMMA 0.2 SCHEDULER 30k,50k do 70k iteracji\n",
        "\n",
        "- MN2_Mish_V3 LR 5e-3 GAMMA 0.3 SCHEDULER 150k,210k,270k,330k do 400k iteracji\n",
        "\n",
        "           - V32 douczanie od 80k z FrozenBN LR = 5e-4 GAMMA 0.1 SCHEDULER 25k,50k do 70k iteracji\n",
        "\n",
        "```\n",
        "Domyślnie  zastosowano:\n",
        "* Agumentację\n",
        "  * ResizeShortestEdge(short_edge_length=(640, 672, 704, 736), max_size=1333, sample_style='choice'),\n",
        "  * RandomFlip(),\n",
        "* Batch size: 2,\n",
        "* Scheduler: WarmupMultiStepLR do 1000 iteracji\n",
        "\n",
        "<br><b>Łączenie skatalogowano pomiary dla 14 zestawów hiperparametrów i przeanalizowano ponad 100 wyników pośrednich mAP w tym ich wizualizacje. W analizie zmian parametrów kierowano się optymalizacją mAP50.</b>\n",
        "<br><br> \n",
        "## Wyniki:\n",
        "\n",
        "Jako punkt odniesienia zastosowano wyniki dla MN2 z parametrami domyślnymi dla 800 tysięcy iteracji:<br>\n",
        "AP50 WIDER FACE - 43%, FACES DD 73%\n",
        "\n",
        "<br>Dla BN wyniki poprawiono odpowiednio na 50% i 90% przy dwa razy mniejszej liczbie iteracji\n",
        "\n",
        "<br>BN_V2 nie wniosła dodatkowej poprawy\n",
        "\n",
        "<br>Funkcja aktywacji Mish - zasadaniczo nie poprawiła wyników, ale znacząco przyspiszono trening, porównywalny wynik uzyskano dla 200k iteracji\n",
        "\n",
        "<br>Dla konfiguracji z funkcją aktywacji Mish_V2 uzyskano wyniki mAP50 na poziomie- 54% dla 250k, 92% dla 250k iteracji\n",
        "\n",
        "<br><b>Ostatecznie uzyskano poprawę wyników mAP50 o 12pp dla WIDER FACE oraz 20pp dla FACES DD, przy 8krotnym przyspieszeniu procesu trenowania.</b>\n",
        "<br><br>\n",
        "```\n",
        "- MN2         maks. mAP50 43% WIDER FACE 73% FACES DD dla 800k iteracji\n",
        "- MN2_BN      maks. mAP50 50% WIDER FACE 90% FACES DD dla 800k iteracji\n",
        "- MN2_BN_V2   test przeprowadzono do 500k iteracji bez poprawy wyniku\n",
        "- MN2_Mish    maks WIDER FACE 50%, 90% FACES DD dla 200k iteracji\n",
        "- MN2_Mish_V2 maks WIDER FACE 54,73%, 92,39% FACES DD 250k iteracji\n",
        "           - V22  maks 52,57% 92,05% dla 70k iteracji\n",
        "                  - V222 maks 53,65% 92% dla 120k iteracji - przerwany\n",
        "           - V22F  maks 55,24%  92,52% dla 100k iteracji\n",
        "           - V22F2 maks 55,34%  92,96% dla 50k iteracji\n",
        "                  - V22F22 bez poprawy\n",
        "           - V22F3 maks 55,23%  92,74% dla 10k iteracji\n",
        "           - V22F4 maks 54,94% dla 10k,  92,64% dla 20k iteracji\n",
        "- MN2_Mish_V3 maks 51,06%  90,49% dla 80k iteracji\n",
        "           - V32 maks 52,76%  dla 20k, 91,78% dla 30k iteracji\n",
        "```\n",
        "<br>\n",
        "Przykładowe wizualizacje dla MN2_Mish_V2 250k iteracji:\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://github.com/DarekGit/FACES_DNN/blob/master/Figures/Detectron2_Wider_Face_mAP_MN2_BN_Mish_V2_250k.png?raw=1\" alt=\"mAP MishV2 WIDER 250k\" align=\"center\" width=\"1000\" >\n",
        "<img src=\"https://github.com/DarekGit/FACES_DNN/blob/master/Figures/Detectron2_Faces_DD_mAP_MN2_BN_Mish_V2_250k.png?raw=2\" alt=\"mAP MishV2 FACESDD 250k\" align=\"center\" width=\"1000\" >\n",
        "</div>\n",
        "\n",
        "po douczeniu z FrozenBN V2 dla 50k iteracji:\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://github.com/DarekGit/FACES_DNN/blob/master/Figures/Detectron2_Wider_Face_mAP_MN2_BN_Mish_V2_250%2BF_2_50k.png?raw=1\" alt=\"mAP MishV2 FrozenBN WIDER +50k\" align=\"center\" width=\"1000\" >\n",
        "<img src=\"https://github.com/DarekGit/FACES_DNN/blob/master/Figures/Detectron2_Faces_DD_mAP_MN2_BN_Mish_V2_250%2BF_2_50k.png?raw=2\" alt=\"mAP MishV2 FrozenBN FACESDD +50k\" align=\"center\" width=\"1000\" >\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oN1odukYVME",
        "colab_type": "text"
      },
      "source": [
        "## 8. Do dalszej oceny i porównania wybrano:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20HgLG9ZX88h",
        "colab_type": "text"
      },
      "source": [
        "### Model '800k' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyzpjCoFYgxJ",
        "colab_type": "text"
      },
      "source": [
        "parametry domyślne - jako punkt odniesienia \n",
        "<br>\n",
        "Zastosowane rozwiązanie wykorzystuję architekturę MobileNet V2 w backbone opisaną w podrozdziale [5.2. MOBILENETV2](05_02_MOBILENETV2.ipynb).\n",
        "* Agumentację\n",
        "  * ResizeShortestEdge(short_edge_length=(640, 672, 704, 736), max_size=1333, sample_style='choice'),\n",
        "  * RandomFlip(),\n",
        "* FrozenBatchNorm2d, \n",
        "* Batch size: 2, \n",
        "* Scheduler: WarmupMultiStepLR\n",
        "* Bazowy LR: 0.001 z liniowym rozgrzewaniem (linear warm-up), zmniejszany dwukrotnie przy 40k/10k/200k/400k do 800k iteracji \n",
        "<br><br>\n",
        "\n",
        "Zapis trenowania modelu został dołączony do pracy jako załącznik w pliku: <br>\n",
        "[ mobilenet_v2_800k.ipynb]( https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/WIDERFACE_Detectron2_from_scratch_DD_mobilenet_v2_800k.ipynb)\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-xzr-lTYDzo",
        "colab_type": "text"
      },
      "source": [
        "### Model 'BN_800k' \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGVXJh3iYhtU",
        "colab_type": "text"
      },
      "source": [
        "dodano BN - pokazanie wpływu BN przy małym batchu=2<br>\n",
        "\n",
        "Zastosowane rozwiązanie wykorzystuję architekturę MobileNet V2 w backbone opisaną w podrozdziale [5.2. MOBILENETV2](05_02_MOBILENETV2.ipynb).\n",
        "* Agumentację\n",
        "  * ResizeShortestEdge(short_edge_length=(640, 672, 704, 736), max_size=1333, sample_style='choice'),\n",
        "  * RandomFlip(),\n",
        "* <b>BatchNorm2d,</b> \n",
        "* Batch size: 2, \n",
        "* Scheduler: WarmupMultiStepLR\n",
        "* Bazowy LR: 0.001 z liniowym rozgrzewaniem (linear warm-up), zmniejszany dwukrotnie przy 40k/10k/200k/400k do 800k iteracji \n",
        "<br><br>\n",
        "\n",
        "Zapis trenowania modelu został dołączony do pracy jako załącznik w pliku: <br>\n",
        "[ mobilenet_v2_BN.ipynb](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/WIDERFACE_Detectron2_from_scratch_DD_mobilenet_v2_BN.ipynb)\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz3euVMLYalt",
        "colab_type": "text"
      },
      "source": [
        "### 'BN_Mish_V2_250+F_2_50k' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUyPFdXkYieu",
        "colab_type": "text"
      },
      "source": [
        "najlepszy wynik uczenie z Mish BN 250k + 50k z FrozenBN<br>\n",
        "\n",
        "Zastosowane rozwiązanie wykorzystuję architekturę MobileNet V2 w backbone opisaną w podrozdziale [5.2. MOBILENETV2](05_02_MOBILENETV2.ipynb).\n",
        "* Agumentację\n",
        "  * ResizeShortestEdge(short_edge_length=(640, 672, 704, 736), max_size=1333, sample_style='choice'),\n",
        "  * RandomFlip(),\n",
        "* <b>funkcję aktywacji Mish,</b> \n",
        "* BatchNorm2d,\n",
        "* Batch size: 2, \n",
        "* Scheduler: WarmupMultiStepLR\n",
        "* Bazowy LR: 0.002 z liniowym rozgrzewaniem (linear warm-up) do 1000 iteracji, zmniejszany 0.3 po 150k,210k  do 250k iteracji\n",
        "\n",
        "- <b>douczanie:</b>\n",
        "* <b>FrozenBatchNorm2d,</b>\n",
        "* LR: 4e-6, zmniejszony pięciokrotnie po 30k do 50k iteracji\n",
        "<br><br>\n",
        "\n",
        "Zapis trenowania modelu został dołączony do pracy jako załącznik w pliku: <br>\n",
        "[ mobilenet_v2_Mish_V22F.ipynb](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/WIDERFACE_Detectron2_from_scratch_DD_mobilenet_v2_Mish_V22F.ipynb)\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aCB49OxX8-8",
        "colab_type": "text"
      },
      "source": [
        "### Model 'BN_Mish_V3_80+30k'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fguBB8-AYi84",
        "colab_type": "text"
      },
      "source": [
        " najszybsze uczenie 110k iteracji<br>\n",
        " \n",
        "Zastosowane rozwiązanie wykorzystuję architekturę MobileNet V2 w backbone opisaną w podrozdziale [5.2. MOBILENETV2](05_02_MOBILENETV2.ipynb).\n",
        "* Agumentację\n",
        "  * ResizeShortestEdge(short_edge_length=(640, 672, 704, 736), max_size=1333, sample_style='choice'),\n",
        "  * RandomFlip(),\n",
        "* <b>funkcję aktywacji Mish,</b> \n",
        "* BatchNorm2d,\n",
        "* Batch size: 2, \n",
        "* Scheduler: WarmupMultiStepLR\n",
        "* Bazowy LR: 0.005 z liniowym rozgrzewaniem (linear warm-up),  do 80k iteracji\n",
        "\n",
        "- <b>douczanie:</b>\n",
        "* LR: 5e-4, zmniejszony dziesięciokrotnie po 25k do 30k iteracji\n",
        "<br><br>\n",
        "\n",
        "Zapis trenowania modelu został dołączony do pracy jako załącznik w pliku: <br>\n",
        "[ mobilenet_v2_Mish_V32.ipynb](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/WIDERFACE_Detectron2_from_scratch_DD_mobilenet_v2_Mish_V32.ipynb)\n",
        "<br>\n"
      ]
    }
  ]
}