{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_05_TRAINING.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzv8aTGJKe8abwk1yOzdXm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarekGit/FACES_DNN/blob/master/notebooks/05_05_TRAINING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIKTH5ChEoQE",
        "colab_type": "text"
      },
      "source": [
        "Procedura trenowania sieci na przykładzie Detectron2 z MobileNetV2 \n",
        "1. rozdzielono notebooki na cześć trenującą oraz analizy wyników cząstkowych\n",
        "2. Notebook testowy odkłada wyniki cząstkowe do katalogu dedykowanego dla danej konfiguracji- wybrano google drive\n",
        "3. Notebook testowy posiada zesłownikowany dostęp do wyników cząstkowych oraz narządzenia do analizy i porównania wyników.\n",
        "4. w przypadku osiągnięcia punktu najlepszego wyniku dla danych parametrów - rozpoczynano nowy notebook trenujący ze zmienionymi parametrami trenowania w kolejnym katalogu - budując drzewo katalogów dla testów z kolejnymi notebookami dla zmodyfikowanego zestawu hiperparametrów. Każdy katalog zawiera notbook ze specyficnymi paramtrami, pliki konfugraycyjne, wynki cząstkowe, wizualizacje wyników.\n",
        "5. Trening rozpoczęto od parametrów domyślnych w repo detectron2, nstępnie sprawdzono trening dla BN w dwóch wersjach, następnie trening rozpoczęto dla BN z MIsh w 3 wersjach, z podkatologami z modyfikacjami parametrów trenujących\n",
        "- MN2 \n",
        "- MN2_BN\n",
        "- MN2_BN_V2  \n",
        "- MN2_Mish\n",
        "- MN2_Mish_V2\n",
        "           - V22\n",
        "                  - V222\n",
        "           - V22F \n",
        "           - V22F2 \n",
        "                  - V22F22 \n",
        "           - 22F3 \n",
        "           - V22F4\n",
        "- MN2_Mish_V3 \n",
        "           - V32\n",
        "6. Łączenie skatalogowano pomiary dla 14 zestawów hiperparametrów i przeanalizowano ponad 100 wyników pośrednich mAP w tym ich wizualizacje. W analizie zmian parametrów kierowano się optymalizacją mAP50. \n",
        "7. Wyniki. \n",
        "\n",
        "Jako punkt odniesienia zastosowano wyniki dla MN2 z parametrami domyślnymi dla 800 tysięcy iteracji\n",
        "\n",
        "AP50 WIDER FACE - 43%, FACES DD 73%\n",
        "\n",
        "Dla BN wyniki poprawiono odpowiednio na 50% i 90% przy dwa razy mniejszej liczbie iteracji\n",
        "\n",
        "BN_V2 nie wniosła dodatkowej poprawy\n",
        "\n",
        "MIsh - zasadaniczo nie poprawiła wyników, ale uzyskano je już na poziomie 200k iteracji\n",
        "\n",
        "Mish_V2 - 54% dla 250k, 92% dla 250k \n",
        "\n",
        "Uzyskano poprawę o 11pp i 20pp, przy 8krotnym przyspieszeniu procesu trenowania.\n",
        "\n",
        "\n",
        "8. Do dalszej oceny i porównania wybrano:\n",
        "\n",
        "BN_Mish_V2_250+F_2_50k - najlepszy wynika uczenie z Mish BN 250k + 50k z FrozenBN \n",
        "\n",
        "BN_Mish_V3_80+30k - najszybsze uczenie 110k iteracji \n",
        "\n",
        "800k - parametry domyślne - jako punkt odniesienia dla pierwszego podejścia \n",
        "\n",
        "BN_800k - włączenie BN - pokazanie wpływu BN przy małym batchu=2\n",
        "\n"
      ]
    }
  ]
}