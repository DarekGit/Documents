{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_03_DETECTRON2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPe0k+9RtwwG33PuvG+G44A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarekGit/FACES_DNN/blob/master/notebooks/4_03_DETECTRON2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnGizuPeN_hD",
        "colab_type": "text"
      },
      "source": [
        "# Detectron2 \n",
        "Detectron2 to system detekcji obiektów stworzony przez Facebook AI Research, posiadający implementacje najnowocześniejszych algorytmów wykrywania obiektów w tym Faster R-CNN, Mask R-CNN (state-of-the-art object detection algorithms). System został napisany w PyTorchu. Przez twórców został udostępniony jako biblioteka open-source, która może być wykorzystana do obsługi i rozwoju różnych projektów badawczych.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZdsI0ABRxba",
        "colab_type": "text"
      },
      "source": [
        "### Instalacja środowiska"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXCTbVLqR4L4",
        "colab_type": "text"
      },
      "source": [
        "Środowisko instalowane jest z repozytorium umieszczonym przez Facebook AI Research na [GitHub](https://github.com/facebookresearch/detectron2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBt48tE3R3dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "\n",
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -q -e detectron2_repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md1xunzZSf4D",
        "colab_type": "text"
      },
      "source": [
        "Po instalacji detectron2 w środowisku Colab niezbędne jest ponowne uruchomienie środwiska wykonawczego (Ctrl+M.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCbH1tEsTFWG",
        "colab_type": "text"
      },
      "source": [
        "Import podstawowych modułów:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wE3hP1dTClC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2 import model_zoo\n",
        "import detectron2.utils.comm as comm\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer, HookBase\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_train_loader\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX9RUKJbRrZM",
        "colab_type": "text"
      },
      "source": [
        "### Struktura repozytorium\n",
        "Poniżej znajduje się drzewo katalogów detectron2 i opis zawartości katalogów.\n",
        "\n",
        "```\n",
        "detectron2/\n",
        "\n",
        "├─checkpoint  <- checkpointer \n",
        "├─config      <- domyślne konfiguracje\n",
        "├─data        <- programy obsługi zbiorów danych i programy ładujące dane\n",
        "├─engine      <- moduły trenowania i predykcji\n",
        "├─evaluation  <- evaluatory dla podstawowych typów zbiorów danych\n",
        "├─export      <- konwerter modeli detectron2 do caffe2 (ONNX)\n",
        "├─layers      <- warstwy niestandardowe np.: Deformable convolution\n",
        "├─model_zoo   <- wytreniwane modele\n",
        "├─modeling   \n",
        "│  ├─meta_arch <- meta architektury np. R-CNN, RetinaNet\n",
        "│  ├─backbone  \n",
        "│  │    ├─backbone.py   <- zawiera abstrakcyjną klasę bazową Backbone\n",
        "│  │    ├─build.py      <- wywołanie funkcji konstruktora określonej w config\n",
        "│  │    ├─fpn.py        <- zawiera klasę FPN \n",
        "│  │    ├─resnet.py     <- zawiera klasę ResNet \n",
        "│  ├─proposal_generator <- RPN\n",
        "│  └─roi_heads <- ROI heads \n",
        "├─solver       <- moduły zawierające modyfikacje optimizera i schedulera\n",
        "├─structures   <- klasy struktur np.: Boxes, Instances\n",
        "└─utils        <- moduły użytkowe np.: visualizer, logger \t\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBnXKq9Wz_3Q",
        "colab_type": "text"
      },
      "source": [
        "### Omówienie detectron2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8aSvL5O3XMR",
        "colab_type": "text"
      },
      "source": [
        "Architektura detectron2 zostanie omówiona na przykładzie Faster R-CNN z FPN Resnet50. Podstawową konfiguracją Faster R-CNN z FPN Resnet50 jest [Base-RCNN-FPN](https://github.com/facebookresearch/detectron2/blob/master/configs/Base-RCNN-FPN.yaml).\n",
        "Base-RCNN-FPN określa przede wszystkim meta architekturę GeneralizedRCNN, Backbone Network, RPN i ROI Heads. Klasy realizujące tą architekturę zostały zapisane w poniższych lokalizacjach:\n",
        "\n",
        "GeneralizedRCNN [meta_arch/rcnn.py](https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/meta_arch/rcnn.py)\n",
        " \n",
        "\n",
        "- Backbone Network: FPN (Feature Pyramid Network) [backbone/fpn.py](https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/backbone/fpn.py)\n",
        "  - ResNet [backbone/resnet.py](https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/backbone/resnet.py)\n",
        "\n",
        "- RPN (Region Proposal Network) [proposal_generator/rpn.py](https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/proposal_generator/rpn.py)\n",
        "  - StandardRPNHead [proposal_generator/rpn.py](https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/proposal_generator/rpn.py)\n",
        "  - RPNOutput [proposal_generator/rpn_outputs.py](https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/proposal_generator/rpn_outputs.py)\n",
        " \n",
        "- ROI Heads: StandardROIHeads [roi_heads/roi_heads.py](https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/roi_heads/roi_heads.py)\n",
        " - ROIPooler [poolers.py](https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/poolers.py)\n",
        " - FastRCNNConvFCHead [roi_heads/box_heads.py](https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/roi_heads/box_head.py)\n",
        " - FastRCNNOutputLayers [roi_heads/fast_rcnn.py](https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/roi_heads/fast_rcnn.py)\n",
        " - FastRCNNOutputs [roi_heads/fast_rcnn.py](https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/roi_heads/fast_rcnn.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAI499loDOzL",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/DarekGit/FACES_DNN/master/Figures/detectron2.png\" alt=\"detectron2\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "987fycBPNDLb",
        "colab_type": "text"
      },
      "source": [
        "## Backbone Network\n",
        "\n",
        "Implementację Feature Pyramid Network zawiera klasa FPN zapisana w pliku **backbone/fpn.py**. Wybór i konfiguracja sieci Resnet50 realizowana jest poprzez wywołanie funkcji **build_resnet_fpn_backbone** przyjmującej jako jeden z argumentów słownik **cfg** zawierający konfigurację całej architektury w tym głębokość modelu. Wybierając model Resnet50 otrzymujemy poniższa strukturę wynikową:\n",
        "\n",
        "```\n",
        "ResNet(\n",
        "  (stem): BasicStem()              <- BasicStem blok \n",
        "  (res2):                          <- blok res2\n",
        "    (0): BottleneckBlock()         <- (shortcut), stride=(1, 1)\n",
        "    (1): BottleneckBlock()         <- stride=(1, 1)\n",
        "    (2): BottleneckBlock()         <- stride=(1, 1)\n",
        "  (res3):                          <- blok res3\n",
        "    (0): BottleneckBlock()         <- (shortcut), stride=(2, 2)\n",
        "    (1): BottleneckBlock()         <- stride=(1, 1) \n",
        "    (2): BottleneckBlock()         <- stride=(1, 1)\n",
        "    (3): BottleneckBlock()         <- stride=(1, 1)\n",
        "  (res4):                          <- blok res4\n",
        "    (0): BottleneckBlock()         <- (shortcut), stride=(2, 2)\n",
        "    (1): BottleneckBlock()         <- stride=(1, 1)\n",
        "    (2): BottleneckBlock()         <- stride=(1, 1)\n",
        "    (3): BottleneckBlock()         <- stride=(1, 1)\n",
        "    (4): BottleneckBlock()         <- stride=(1, 1)\n",
        "    (5): BottleneckBlock()         <- stride=(1, 1)\n",
        "  (res5):                          <- blok res5\n",
        "    (0): BottleneckBlock()         <- (shortcut), stride=(2, 2)\n",
        "    (1): BottleneckBlock()         <- stride=(1, 1)\n",
        "    (2): BottleneckBlock()         <- stride=(1, 1)\n",
        ")\n",
        "```\n",
        "Struktura wszystkich bloków modelu została zapisana w pliku [faster_rcnn_R_50_FPN.txt](faster_rcnn_R_50_FPN.txt) <br>\n",
        "Reprezentuje ona model wygenerowany z konfiguracji [COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml](https://github.com/facebookresearch/detectron2/blob/master/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qPdtL0W6ydv",
        "colab_type": "text"
      },
      "source": [
        "- **BasicStem blok** jest realizowany przez klasę [BasicStem](https://github.com/facebookresearch/detectron2/blob/5b8f68436651c74608a3f4909cae570dbe23e51d/detectron2/modeling/backbone/resnet.py#L331). Składa się z konwolucji z kernel_size=(7, 7), stride=(2, 2), batch normalizacji. Po konwolucji wywołana jest funkcja aktywacji relu i max pooling kernel_size=3 i stride=2. Na wyjściu otrzymujemy tensor którego W, H są czterokrotnie mniejsze od rozmiaru obrazu na wejściu. \n",
        "\n",
        "- **BottleneckBlock** zastosowano aby zwiększyć głębokość sieci przy jednoczesnym zmniejszeniu parametrów. BottleneckBlock składa się z trzech konwolucji z kernel_size kolejno: (1, 1), (3, 3), (1, 1) ze stride=(1, 1). \n",
        "  \n",
        "  Występują tu trzy tyby bloków BottleneckBlock:\n",
        "\n",
        "  - BottleneckBlock z shortcut i stride=(1, 1)\n",
        "```\n",
        "      (res2): Sequential(\n",
        "        (0): BottleneckBlock(\n",
        "          (shortcut): Conv2d(\n",
        "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
        "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
        "          )\n",
        "          (conv1): Conv2d(\n",
        "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
        "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
        "          )\n",
        "          (conv2): Conv2d(\n",
        "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
        "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
        "          )\n",
        "          (conv3): Conv2d(\n",
        "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
        "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
        "          )\n",
        "        )\n",
        "```\n",
        "  - BottleneckBlock z shortcut i stride=(2, 2)\n",
        "```\n",
        "      (res4): Sequential(\n",
        "        (0): BottleneckBlock(\n",
        "          (shortcut): Conv2d(\n",
        "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
        "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
        "          )\n",
        "          (conv1): Conv2d(\n",
        "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
        "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
        "          )\n",
        "          (conv2): Conv2d(\n",
        "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
        "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
        "          )\n",
        "          (conv3): Conv2d(\n",
        "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
        "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
        "          )\n",
        "        )\n",
        "```\n",
        "  - BottleneckBlock z stride=(1, 1) bez połączenie skrótowego\n",
        "```\n",
        "      BottleneckBlock(\n",
        "          (conv1): Conv2d(\n",
        "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
        "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
        "          )\n",
        "          (conv2): Conv2d(\n",
        "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
        "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
        "          )\n",
        "          (conv3): Conv2d(\n",
        "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
        "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
        "          )\n",
        "        )\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvPt_jcENDQi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Region Proposal Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz1M_4zPNDOr",
        "colab_type": "text"
      },
      "source": [
        "ROI Heads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIVlzxhwasjo",
        "colab_type": "text"
      },
      "source": [
        "Aby załadować dane z datasetu niezbędne jest zarejestrowanie go z wykorzystaniem metody register klasy DatasetCatalog. \n",
        "\n",
        "```\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "train = annotations(\"train\")\n",
        "val = annotations('val')\n",
        "\n",
        "for d in [\"train\",\"val\"]:\n",
        "  DatasetCatalog.register(\"face_\" + d, lambda d=d: train if d == \"train\" else val)\n",
        "  MetadataCatalog.get(\"face_\" + d).set(thing_classes = ['face'])\n",
        "\n",
        "faces_metadata = MetadataCatalog.get(\"face_train\")\n",
        "\n",
        "```"
      ]
    }
  ]
}