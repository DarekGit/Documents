{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Uwagi_praktyczne.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOnHIjnTjfKuh6JoSd85tTb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarekGit/FACES_DNN/blob/master/notebooks/Uwagi_praktyczne.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeLqRcefqQmd",
        "colab_type": "text"
      },
      "source": [
        "###[Spis treści](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Praca_Dyplomowa.ipynb)\n",
        "[5. Detekcja twarzy z wykorzystaniem wybranych architektur GSN](05_00_Modyfikacje.ipynb)<br>\n",
        "[5.3 FrozenBN Mish](05_03_FrozenBN_Mish.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ug5YOSsqZas",
        "colab_type": "text"
      },
      "source": [
        "# 5.4 Uwagi praktyczne "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BKqNDzbOThhw"
      },
      "source": [
        "## Testy MMDetection\n",
        "\n",
        "Jednym z pierwszych testów wykonanych w ramach pracy było sprawdzenie jakości pracy różnych modeli używanych do detekcji obiektów.\n",
        "\n",
        "<br>Do testów wykorzystano zbiór FDDB oraz repozytorium MMDetection. Jako punkt odniesienia użyto wyników pretrenowanego MTCNN.\n",
        "\n",
        "<br>Po wstępnym douczaniu na FDDB otrzymano następujące wyniki AP50:\n",
        "<br>Faster_RCNN - 75,5%\n",
        "<br>Faster_RCNN z soft NMS - 74,6%\n",
        "<br>Faster_RCNN z soft NMS i zmienionymi Anchor box - 68,9%\n",
        "<br>SSD300 - 28,9%\n",
        "<br>Retina 101 - 57,5%\n",
        "<br> Wyniki dostępne w notebooku: [mmdet_v2](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/05_04_mmdet_DD_v2.ipynb)\n",
        "<br>Cascade_RCNN_Resnet50 -  78,2%\n",
        "<br> Wyniki dostępne w notebooku: [mmdet_v3](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/05_04_mmdet_DD_v3.ipynb)\n",
        "\n",
        "<br><b>Ze względu na znacznie gorsze wyniki w porównaniu do 92.4% MTCNN, nie kontynuowano prac w tym zakresie.</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVHZpAf7CR2m",
        "colab_type": "text"
      },
      "source": [
        "##JSON\n",
        "W pracy ze względu na uwiersalny dostęp do danych zapisanych w foramcie json, zastosowano ten format do zapisu metryk i wyniku prac.\n",
        "<br>W trakcie projektu zidentyfikowano problem z obługą danych typu intiger przez moduł Json. Moduł Json obsługuje tylko i wyłączenie dane całkowite z opisem 'int', natomiast w repozytoriarch często są stosowane rozszenia nazw dla danych typu intiger.\n",
        "W celu ominięcia ograniczenia funkcjonalności modułu Json zastosowano funkcję rekukrencyjną konwersji i ujednolicenia nazw dla danych typu intiger:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfYxjz6lCLoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "def to_int(data):\n",
        "  if isinstance(data,dict):\n",
        "    for key in data.keys(): data[key]=to_int(data[key])\n",
        "  if isinstance(data,list):\n",
        "    for k in range(len(data)): data[k]=to_int(data[k])\n",
        "  if isinstance(data,tuple):\n",
        "    data=list(data)\n",
        "    for k in range(len(data)): data[k]=to_int(data[k]) \n",
        "  if 'int' in data.__class__.__name__: \n",
        "    data=int(data)\n",
        "  return data\n",
        "\n",
        "#json obsluguje calkowite tylko w typie int\n",
        "with open('Results.json','w') as f:\n",
        "  json.dump(to_int(results_data),f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6QzYFKkDaJV",
        "colab_type": "text"
      },
      "source": [
        "UWAGA. w przypadku kopiowania danych należy zastosować metodę deepcopy(), która kopuję również dane wskazywane w kolejnych warstwach struktury danych."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xid611IfFDJL",
        "colab_type": "text"
      },
      "source": [
        "##DETR\n",
        "\n",
        "W przypadku repozytorium DETR zastosowanym w Detectron2 w trakcie uczenia z dużymi learning rate (>1e-4) na bazie WIDER FACE, napotkano problem pojawiania się wyników typu np.nan w koordynatach detekowanych obwiedni obiektów.\n",
        "Dane tego typu charakteryzyją się tym, że nie można wykonać na nich kolejnych obliczeń.\n",
        "W standarowym repozytorium zastosowano kontrolę przerywającą dalszy proces:<br>\n",
        "    # degenerate boxes gives inf / nan results\n",
        "    # so do an early check\n",
        "    assert (boxes1[:, 2:] >= boxes1[:, :2]).all()\n",
        "    assert (boxes2[:, 2:] >= boxes2[:, :2]).all()\n",
        "\n",
        "W celu utrzymania procesu wprowadziliśmy funkcję korekcji danych, w tym podmiany danych dla typu np.nan oraz uporządkowania koordynat.    \n",
        "Identyfikację wystąpienia wyniku typu nan, wykonano stosując porównanie:<br>\n",
        "**if x != x == True**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7HkfQHPHRt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Fix_boxs(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self,boxs): #placing max size in nan value, ordering of boxes coordinates\n",
        "    #if nan appears put all mask row to True\n",
        "    self.mask_nan = (boxs!=boxs).sum(axis=-1)[:,None].expand(*boxs.shape) > 0 \n",
        "    #for nan rows put box max size [0,0,1,1] \n",
        "    boxs[self.mask_nan] = torch.tensor([0,0,1,1]*self.mask_nan[:,0].sum(), dtype=torch.float, device=boxs.device )\n",
        "\n",
        "    #for coordinates [l,t,r,b] if r < l or b < t put True for r,l and t,b respectively\n",
        "    self.mask_ord = (boxs[:,2:]<boxs[:,:2]).float()  @ torch.tensor([[1,0,1,0],[0,1,0,1]],dtype=torch.float, device=boxs.device) ==1\n",
        "    #for mask_ord put respectively [r,_,l,_] and [_,b,_,t]\n",
        "    boxs[self.mask_ord] = boxs[:,[2,3,0,1]][self.mask_ord]\n",
        "    return boxs\n",
        "\n",
        "  def backward(self,input):\n",
        "    input[self.mask_ord] = input[:,[2,3,0,1]][self.mask_ord] #back to input order\n",
        "    #input[self.mask_nan] = torch.zeros_like(input, device = input.device)[self.mask_nan] #gradient canceling for nan if necessary  \n",
        "    return input\n",
        "\n",
        "fix_boxs=Fix_boxs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5Un2sT-Hg4C",
        "colab_type": "text"
      },
      "source": [
        "UWAGA:<br>\n",
        "W rozwiązaniu zastosowano klasę torch.nn.Module dla zachowania pełnej funkcjonalności w procesie uczenia. Klasa musi wykonywać odpowiednie korekty w metodzie forward i backward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eerTGxkuI85M",
        "colab_type": "text"
      },
      "source": [
        "##Ekstrakcja cech z wybranych warstw modelu.\n",
        "\n",
        "W celu ekstrakcji cech z zewnętrznego modelu, zastosowano metodę dokładania warstwy z klasą zapamiętującą dane do późniejszego wykorzystania.\n",
        "<br>Format opisujący nazwy modułów modelu został zaczerpnięty z funkcji named_modules.\n",
        "\n",
        "<br>Poniżej przedstawiono przykład dołączeniu warstwy do ektrakcji cech modelu.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8qyuRbPQFbv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "0587c228-0f0f-4f3d-ed4c-e89f843182bc"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "!pip -q install facenet-pytorch\n",
        "from facenet_pytorch import MTCNN\n",
        "mtcnn = MTCNN(image_size=224, margin=0, keep_all=True) \n",
        "\n",
        "class View(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(View, self).__init__()\n",
        "        self.data = None\n",
        "        self.gradInput = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.data = input\n",
        "        return input\n",
        "\n",
        "    def backward(self,input, gradOutput):\n",
        "        self.gradInput = input\n",
        "        return input\n",
        "\n",
        "def add_view(net,name, View_Layer, before = False):\n",
        "  if isinstance(name,str): name=name.split('.')\n",
        "  if len(name)>1: \n",
        "    add_view(net._modules[name[0]],name[1:],View_Layer,before=before)\n",
        "  else: \n",
        "    if before:\n",
        "      net._modules[name[0]] = nn.Sequential(View_Layer,net._modules[name[0]])\n",
        "    else:\n",
        "      net._modules[name[0]] = nn.Sequential(net._modules[name[0]],View_Layer)\n",
        "\n",
        "for n,m in mtcnn.named_modules():\n",
        "  print(n,end='; ')\n",
        "print('')\n",
        "\n",
        "views ={}\n",
        "for l in [\"onet.softmax6_1\",\"onet.dense6_2\",\"rnet.dense5_2\"]:\n",
        "    print(l,' - Add_View')\n",
        "    view = View()\n",
        "    add_view(mtcnn,l,view)\n",
        "    views[l] = view"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "; pnet; pnet.conv1; pnet.prelu1; pnet.pool1; pnet.conv2; pnet.prelu2; pnet.conv3; pnet.prelu3; pnet.conv4_1; pnet.softmax4_1; pnet.conv4_2; rnet; rnet.conv1; rnet.prelu1; rnet.pool1; rnet.conv2; rnet.prelu2; rnet.pool2; rnet.conv3; rnet.prelu3; rnet.dense4; rnet.prelu4; rnet.dense5_1; rnet.softmax5_1; rnet.dense5_2; onet; onet.conv1; onet.prelu1; onet.pool1; onet.conv2; onet.prelu2; onet.pool2; onet.conv3; onet.prelu3; onet.pool3; onet.conv4; onet.prelu4; onet.dense5; onet.prelu5; onet.dense6_1; onet.softmax6_1; onet.dense6_2; onet.dense6_3; \n",
            "onet.softmax6_1  - Add_View\n",
            "onet.dense6_2  - Add_View\n",
            "rnet.dense5_2  - Add_View\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXemt5d4WmFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "img=Image.open('D.jpg')\n",
        "dboxes,confs = mtcnn.detect(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u66GUsG9apeL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7240e5d9-a108-4d79-b16b-50ae873e1669"
      },
      "source": [
        "dboxes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[130.05042, 109.73867, 405.13043, 492.75626]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzrbWb77YrZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "3a149574-82e3-45af-cb54-622273e74539"
      },
      "source": [
        "views['onet.softmax6_1'].data, views['onet.dense6_2'].data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.6094e-03, 9.9839e-01],\n",
              "         [2.2715e-03, 9.9773e-01],\n",
              "         [6.4953e-05, 9.9994e-01],\n",
              "         [5.1406e-04, 9.9949e-01],\n",
              "         [2.0288e-04, 9.9980e-01],\n",
              "         [1.0813e-03, 9.9892e-01]]),\n",
              " tensor([[ 0.1666, -0.0402, -0.1149, -0.0242],\n",
              "         [ 0.1598, -0.0361, -0.1217, -0.0219],\n",
              "         [ 0.1961, -0.0720, -0.0578, -0.0342],\n",
              "         [ 0.1790, -0.0427, -0.1300, -0.0621],\n",
              "         [ 0.1450, -0.0807, -0.1443, -0.0803],\n",
              "         [ 0.1590, -0.0514, -0.0933,  0.0146]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_-fa-qQYwAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5406004b-51a3-4891-fbf0-fd4cfbd35ae6"
      },
      "source": [
        "mtcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MTCNN(\n",
              "  (pnet): PNet(\n",
              "    (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (prelu1): PReLU(num_parameters=10)\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (conv2): Conv2d(10, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (prelu2): PReLU(num_parameters=16)\n",
              "    (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (prelu3): PReLU(num_parameters=32)\n",
              "    (conv4_1): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (softmax4_1): Softmax(dim=1)\n",
              "    (conv4_2): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (rnet): RNet(\n",
              "    (conv1): Conv2d(3, 28, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (prelu1): PReLU(num_parameters=28)\n",
              "    (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (conv2): Conv2d(28, 48, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (prelu2): PReLU(num_parameters=48)\n",
              "    (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (conv3): Conv2d(48, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (prelu3): PReLU(num_parameters=64)\n",
              "    (dense4): Linear(in_features=576, out_features=128, bias=True)\n",
              "    (prelu4): PReLU(num_parameters=128)\n",
              "    (dense5_1): Linear(in_features=128, out_features=2, bias=True)\n",
              "    (softmax5_1): Softmax(dim=1)\n",
              "    (dense5_2): Sequential(\n",
              "      (0): Linear(in_features=128, out_features=4, bias=True)\n",
              "      (1): View()\n",
              "    )\n",
              "  )\n",
              "  (onet): ONet(\n",
              "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (prelu1): PReLU(num_parameters=32)\n",
              "    (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (prelu2): PReLU(num_parameters=64)\n",
              "    (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (prelu3): PReLU(num_parameters=64)\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (conv4): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (prelu4): PReLU(num_parameters=128)\n",
              "    (dense5): Linear(in_features=1152, out_features=256, bias=True)\n",
              "    (prelu5): PReLU(num_parameters=256)\n",
              "    (dense6_1): Linear(in_features=256, out_features=2, bias=True)\n",
              "    (softmax6_1): Sequential(\n",
              "      (0): Softmax(dim=1)\n",
              "      (1): View()\n",
              "    )\n",
              "    (dense6_2): Sequential(\n",
              "      (0): Linear(in_features=256, out_features=4, bias=True)\n",
              "      (1): View()\n",
              "    )\n",
              "    (dense6_3): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TffzP7eYp3dL",
        "colab_type": "text"
      },
      "source": [
        "<br><br>\n",
        "[5.5 Procedura treningu](05_05_TRAINING.ipynb)<br>\n",
        "[5. Detekcja twarzy z wykorzystaniem wybranych architektur GSN](05_00_Modyfikacje.ipynb)<br>\n",
        "###[Spis treści](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Praca_Dyplomowa.ipynb)"
      ]
    }
  ]
}