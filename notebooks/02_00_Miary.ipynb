{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_00_Miary.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarekGit/FACES_DNN/blob/master/notebooks/02_00_Miary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGDuVj2fqC9y",
        "colab_type": "text"
      },
      "source": [
        "### [Spis treści](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Praca_Dyplomowa.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGAf1cvJfBrD",
        "colab_type": "text"
      },
      "source": [
        "## 2. Metryki oceny detekcji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnrVpReapR7H",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "W procesie wykrywania i rozpoznawania twarzy kluczowa jest prawidłowa ocena skuteczności detekcji. W poniższych punktach zostały przedstawione podstawowe metryki detekcji. \n",
        "\n",
        "W punkcie 2.6. została przedstawiona ujednolicona miara mAP przygotowana do oceny  wszystkich modeli używanych w pracy do detekcji twarzy wraz z przykładem użycia w notebooku: [mAP notebook](../notebooks/02_01_mAP.ipynb \"mAP notebook\").\n",
        "<br>Należy zwrócić uwagę, iż w większości repozytoriów i konkursów stosowana jest głównie miara mAP, jednak może ona posiadać nieznaczne modyfikacje w zależności od sposoby implementacji. Implementacja nie powinna mieć istotnego wpływu na wynik, ale nawet różnice poniżej 1pp mogą przesądzać o wyborze modelu do dalszych prac. Dlatego zależało nam na przygotowaniu jednej spójnej miary do oceny wszystkich badanych modeli. \n",
        "<br><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCci3gPgrctn",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. Intersection Over Union (IOU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXoth-22snN2",
        "colab_type": "text"
      },
      "source": [
        "Intersection Over Union jest miarą bazującą na indeksie Jaccarda oceniającego względny stopień dopasowania pól jako stosunek części wspólnej do pola łącznego. Poprzez zastosowanie IoU możemy określić czy mamy przypadek ważnej detekcji (True Positive) czy też nie (False Positive). Domyślnie do detekcji sotosuje się  próg $IoU \\ge 50\\%$.\n",
        "\n",
        "$\\text{IOU}=\\frac{\\text{pole}\\left(B_{p} \\cap B_{gt} \\right)}{\\text{pole}\\left(B_{p} \\cup B_{gt} \\right)}$\n",
        "\n",
        "gdzie:<br>\n",
        "$B_{p}$ oznacza predicted Box (wykryte), $B_{gt}$ oznacza ground truth Box (wskazane)\n",
        "\n",
        "\n",
        "<br>Obrazek poniżej ilustruje IoU pomiędzy wskazanym polem/obwiednią (w kolorze zielonym - ground truth bounding box) a wykrytym polem/obwiednią (w kolorze czerwonym - detected bounding box.\n",
        "<br>\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://github.com/DarekGit/Faces_DNN/blob/master/Figures/iou.png?raw=1\" alt=\"Intersection Over Union\"  >\n",
        "<br>\n",
        "Rys. 1. IoU pomiędzy wskazanym polem (w kolorze zielonym - ground truth bounding box) <br>a wykrytym polem (w kolorze czerwonym - detected bounding box).\n",
        "</div>\n",
        "<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwVdOoUpyuEq",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. Precision i Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5sIE1L90ixe",
        "colab_type": "text"
      },
      "source": [
        "Podstawowe elementy Precision i Recall:\n",
        "\n",
        "* **True Positive (TP)**: Prawidłowa detekcja. Detekcja z IOU ≥ _threshold_  \n",
        "* **False Positive (FP)**: Nieprawidłowa detekcja. Detekcja z IOU < _threshold_  \n",
        "* **False Negative (FN)**: Nie wykryte wskazane pole  (ground truth).  \n",
        "* **True Negative (TN)**: Reprezentuje prawidłowy brak detekcji obiektu. W przypadku detekcji obiektów (w tym twarzy)  można przypisać bardzo wiele pól oznaczjący prawdziwy brak detekcji obiektu, a które nie są związane z jakością pracy modelu, dlatego nie stosuje się tego elementu w ocenie detektora.\n",
        "\n",
        "_threshold_: zależy od definicji miary, domyślnie przyjumje się wartośc 0.5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK2DBUjLzMdY",
        "colab_type": "text"
      },
      "source": [
        "### Precision\n",
        "\n",
        "Precyzja określa jaka część wyników uzyskanych w trakcie detekcji jako należących do danej klasy obiektów faktycznie do niej należy. Określa się jako stosunek True Positive do wszystkich uzyskanych detekcji dla danje klasy, podanym wzorem:\n",
        "\n",
        "<br>\n",
        "$\\text{Precision} = \\frac{\\text{TP}}{\\text{TP}+\\text{FP}}=\\frac{\\text{TP}}{\\text{all detections}}$ <br>\n",
        "\n",
        "\n",
        "### Recall \n",
        "\n",
        "Recall (czułość) określa zdolnością modelu do wykrycia wszystkich wskazanych obiektów (ground truth). Jest to stosunek True Positive do wszystkich wskazanych obiektów, podanym wzorem:\n",
        "\n",
        "<br>\n",
        "$\\text{Recall} = \\frac{\\text{TP}}{\\text{TP}+\\text{FN}}=\\frac{\\text{TP}}{\\text{all ground truths}}$ \n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISnp1G3v2CBN",
        "colab_type": "text"
      },
      "source": [
        "### 2.3. Krzywa Precision/Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1LAEtr115Nx",
        "colab_type": "text"
      },
      "source": [
        "Krzywa Precision i Recall jest dobrym sposobem oceny jakości detekcji obiektów, w zależności od stopnia pewności detekcji (confidence), dla danej klasy obiektów. Detektor obiektów uznaje się za dobry jeśli jego Precission pozostaje wysoki dla narastającego Recall, co oznacza, że przy zwiększeniu progu pewności (confidence treshold), Precission and Recall pozostają wysokie.\n",
        "\n",
        "Zły detektor potrzebuje zwiększyć ilość wykrywanych obiektów (zwiększyć False Positive = mniejsze Precission) w celu wykrycia  wskazanych obiektów (wysokie Recall).\n",
        "Normalnie krzywa zaczyna się od dużych wartości Precission i maleje wraz ze wzrostem Recall.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhWiST5fh5sG",
        "colab_type": "text"
      },
      "source": [
        "### 2.4. Average Precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh59-crT2OAK",
        "colab_type": "text"
      },
      "source": [
        "Metoda AP została zastosowana w konkursie PASCAL VOC w 2010 roku.\n",
        "<br><br>\n",
        "\n",
        "\n",
        "* <b>Interpolacja 11-punktowa</b>\n",
        "<br>\n",
        "\n",
        "\n",
        "Dla ułatwienia obliczeń w pierwszych implementacjach AP stosowano uśrednienie krzywej Precision x Recal do jedenastu rownomiernie rozłożonych punktów na osi Recall [0, 0.1, 0.2, ... , 1], wtedy:\n",
        "\n",
        "<br>\n",
        "$\\text{AP}=\\frac{1}{11} \\sum_{r\\in \\left \\{ 0, 0.1, ...,1 \\right \\}}\\rho_{\\text{interp}\\left ( r \\right )}$\n",
        "\n",
        "gdzie:\n",
        "<br>\n",
        "$\\rho_{\\text{interp}} = \\max_{\\tilde{r}:\\tilde{r} \\geq r} \\rho\\left ( \\tilde{r} \\right )$,<br>\n",
        " $\\rho\\left ( \\tilde{r} \\right )$ jest Precission dla Recall $\\tilde{r}$ .\n",
        "\n",
        "<br>W tym przypadku, mamy prostą formułę, AP jest obliczane tylko dla interpolacji w 11 punktach $r$ biorąc **maksymalne Precission dla Recall większego od $r$**.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "* <b>Interpolacja dla wszystkich punktów</b>\n",
        "<br>\n",
        "\n",
        "Jest dokładniejszą miarą AP niż interpolacja 11 punktowa, i może być wyrażona następująca formułą:\n",
        "\n",
        "$\\sum_{n=0} \\left ( r_{n+1} - r_{n} \\right ) \\rho_{\\text{interp}}\\left ( r_{n+1} \\right )$\n",
        " \n",
        "<br>gdzie:\n",
        "<br>$\\rho_{\\text{interp}}\\left ( r_{n+1} \\right ) = \\max_{\\tilde{r}:\\tilde{r} \\ge r_{n+1}} \\rho \\left ( \\tilde{r} \\right )$,<br>\n",
        "$\\rho \\left ( \\tilde{r} \\right )$  jest Precission dla Recall $\\tilde{r}$.\n",
        "\n",
        "<br>W tym przypadku AP obliczane jest dla wszystkich wartości maksymalnych Precission biorąc **maksymalny poziom Precission dla Recall większego lub równego $r+1$**. W ten sposób obliczamy pole pod krzywą interpolowaną (AUC).\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHfXRrPuj5N6",
        "colab_type": "text"
      },
      "source": [
        "### 2.5. COCO mAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atUxQasSj84W",
        "colab_type": "text"
      },
      "source": [
        "mAP zostało zastosowane w konkurcie COCO detection, jest bardzo popularną miarą wyrażającą jakość detekcji jedną liczbą dla zestawu IoU. \n",
        "<br>Najnowsze artykuły naukowe zwykle podają wyniki również dla COCO.\n",
        "<br>Z definicji mAP to średnia wartość Average Precision. W przypadku COCO mAP jest liczona poprzez uśrednianie AP dla wybranych IoU we wszystkich klasach obiektów.\n",
        "\n",
        "Charakterystyczny zapis AP @ [. 5: .95] odpowiada średniemu AP dla IoU od 0.5 do 0.95 z wielkością kroku 0.05. \n",
        "\n",
        "W konkursie COCO AP to średnia dla 10 poziomów IoU w 80 kategoriach (AP @ [.50: .05: .95]: zaczynając od 0.5,a kończąc na IoU = 0.95 z krokiem 0.05).\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0xwAPIikHZw",
        "colab_type": "text"
      },
      "source": [
        "### 2.6. Moduł mAP.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw88-hqyjOif",
        "colab_type": "text"
      },
      "source": [
        "Moduł zawiera ujednoliconą miarę mean Average Precision przygotowaną do oceny wszystkich modeli używanych w pracy do detekcji twarzy. \n",
        "Moduł zapewnia bardzo łatwe użycie metryki oraz wizualizację wyników.\n",
        "Metryka bazuje na danych podawanych w postaci list wykrytych  pól oraz pól wskazanych  w opisie datasetu (ground truth).\n",
        "Koordynaty pól powinny być przedstawione w postaci (left, top, right, bottom], w przypadku nieprawidłowej kolejności przygotowana miara wprowadza odpowiednie poprawki.\n",
        "<br><BR>\n",
        "\n",
        "Należy zwrócić uwagę, że w dostępnych materiałach, często pomijana jest kwestia sortowania wyników detekcji. Do określenia prawidłowej miary mAP wyniki detekcji muszą być posortowane malejąco względem pewności detekcji (confidence). <br> I tylko dla takiej kolejności obliczane są kolejne wartości:<br>\n",
        "<br>$Precission_i = (\\frac{\\sum_0^i{TP_i}}{\\sum_0^i{\\left(TP_i+FP_i\\right)}})$ <br>oraz <br>$Recall_i = (\\frac{\\sum_0^i{TP_i}}{All\\ Ground\\ Truth})$\n",
        "<br>\n",
        "<br> W module mAP zasotosowano obliczenie dla wszystkich punktów Recall, krzywe można wyświetlać jako interpolowane lub nie.\n",
        "<br><br>\n",
        "\n",
        "Przykład użycia modułu mAP.py podany jest w notebooku:  [02_01_mAP.ipynb](02_01_mAP.ipynb)\n",
        "<br><br>\n",
        "Moduł mAP dostępny jest na: https://github.com/DarekGit/mAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5IwjhI9jlyX",
        "colab_type": "text"
      },
      "source": [
        "### 2.7. GIoU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKQxqgX_lyWc",
        "colab_type": "text"
      },
      "source": [
        "W detekcji obiektów najczęściej stosowaną fukcją kosztu jest odległośc L1 lub L2 między koordynatami pól wykrytych a pól wskazanych (ground truth). Prowadzi to do rozbieżności wyników optymalizacji modelu a wartości maksymalnych AP, ponieważ nie ma silnej korelacji pomiędzy IoU a odległością koordynat pól.  Brak korelacji można wykazać na przykładzie dla stałej odległosci L2 pól:\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "<img src=\"https://github.com/DarekGit/Faces_DNN/blob/master/Figures/L2 versus IoU.jpg?raw=1\" alt=\"L2 versus IoU\" width=\"500\" ><br>\n",
        "\n",
        "\n",
        "Rys. 2. Dla tej samej odległosci różne wartości IoU.  <a href=\"https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Bibliografia.ipynb\">[14]</a>\n",
        "</div>\n",
        "\n",
        "\n",
        "<br><br> Natomiast zastosowanie IoU w fukcji kosztu jest problematyczne ze względu na brak informacji o odległości pól obiektu przy braku ich przecięcia, IoU=0.\n",
        "Rozwiązaniem tego zagadnienia jest generalizacja pojęcia IoU przez wpowadzenie elementu minimalnego pola C obejmującego pole wskazane i wykryte przez detektor i zdefinoowanie generalized IoU jako:\n",
        "\n",
        "<br>$GIoU = IoU - \\frac{C - \\text{area of Union}}{C}$\n",
        "\n",
        "<br>Miarę GIoU <a href=\"https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Bibliografia.ipynb\">[14]</a> stosuje się w optymalizacji funckji kosztu od 2020r jako element uzupełniający do odległości L1 lub L2 przy zastosowaniu odpowiednich wag dla poszczególnych elementów funkcji kosztu.\n",
        "Minimalizację wykonuje się dla $1 - GIoU$\n",
        "\n",
        "<br>Przykład użycia GIoU w funkcji kosztu dla modelu DeTr w Detectron2: \n",
        "https://github.com/DarekGit/detr/blob/master/util/box_ops.py\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AArdGStDkitb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision.ops.boxes import box_area\n",
        "\n",
        "def box_cxcywh_to_xyxy(x):\n",
        "    x_c, y_c, w, h = x.unbind(-1)\n",
        "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
        "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
        "    return torch.stack(b, dim=-1)\n",
        "\n",
        "\n",
        "def box_xyxy_to_cxcywh(x):\n",
        "    x0, y0, x1, y1 = x.unbind(-1)\n",
        "    b = [(x0 + x1) / 2, (y0 + y1) / 2,\n",
        "         (x1 - x0), (y1 - y0)]\n",
        "    return torch.stack(b, dim=-1)\n",
        "\n",
        "\n",
        "# modified from torchvision to also return the union\n",
        "def box_iou(boxes1, boxes2):\n",
        "    area1 = box_area(boxes1)\n",
        "    area2 = box_area(boxes2)\n",
        "\n",
        "    lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # [N,M,2]\n",
        "    rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])  # [N,M,2]\n",
        "\n",
        "    wh = (rb - lt).clamp(min=0)  # [N,M,2]\n",
        "    inter = wh[:, :, 0] * wh[:, :, 1]  # [N,M]\n",
        "\n",
        "    union = area1[:, None] + area2 - inter\n",
        "\n",
        "    iou = inter / union\n",
        "    return iou, union\n",
        "\n",
        "\n",
        "def generalized_box_iou(boxes1, boxes2):\n",
        "    \"\"\"\n",
        "    Generalized IoU from https://giou.stanford.edu/\n",
        "\n",
        "    The boxes should be in [x0, y0, x1, y1] format\n",
        "\n",
        "    Returns a [N, M] pairwise matrix, where N = len(boxes1)\n",
        "    and M = len(boxes2)\n",
        "    \"\"\"\n",
        "    # degenerate boxes gives inf / nan results\n",
        "    # so do an early check\n",
        "    assert (boxes1[:, 2:] >= boxes1[:, :2]).all()\n",
        "    assert (boxes2[:, 2:] >= boxes2[:, :2]).all()\n",
        "    iou, union = box_iou(boxes1, boxes2)\n",
        "\n",
        "    lt = torch.min(boxes1[:, None, :2], boxes2[:, :2])\n",
        "    rb = torch.max(boxes1[:, None, 2:], boxes2[:, 2:])\n",
        "\n",
        "    wh = (rb - lt).clamp(min=0)  # [N,M,2]\n",
        "    area = wh[:, :, 0] * wh[:, :, 1]\n",
        "\n",
        "    return iou - (area - union) / area"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8WXHlsS9O98",
        "colab_type": "text"
      },
      "source": [
        "<br>Przykład użycia mAP: \n",
        "<b>[mAP notebook](../notebooks/02_01_mAP.ipynb \"mAP notebook\")\n",
        "\n",
        "###<br> [3. Bazy danych](03_00_Datasety.ipynb)   \n",
        "### [Spis treści](https://github.com/DarekGit/FACES_DNN/blob/master/notebooks/Praca_Dyplomowa.ipynb)"
      ]
    }
  ]
}