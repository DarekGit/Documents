{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_DeTr_R50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarekGit/FACES_DNN/blob/master/notebooks/04_DeTr_R50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8l7TjawuG71",
        "colab_type": "text"
      },
      "source": [
        "Detectron2 z DeTr z Resnet50\n",
        "\n",
        "LR=1-4 \n",
        "\n",
        "Gamma=0.1\n",
        "\n",
        "Scheduler [] \n",
        "\n",
        "Max 3600k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC-BR8L2E3X2",
        "colab_type": "text"
      },
      "source": [
        "https://arxiv.org/pdf/2005.12872.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CHNa32TdpuN",
        "colab_type": "text"
      },
      "source": [
        "# Install detectron2\n",
        "\n",
        "Detectron2  https://github.com/facebookresearch/detectron2 <br>\n",
        "Detectron2 Beginner's Tutorial https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5 <br>\n",
        "Documentation https://detectron2.readthedocs.io <br>\n",
        "Detectron2 Model Zoo and Baselines https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md <br>\n",
        "Rethinking ImageNet Pre-training https://arxiv.org/pdf/1811.08883.pdf <br>\n",
        "\n",
        "Wykorzystano kody z <br>\n",
        "https://github.com/youngwanLEE/vovnet-detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVOnv0H2xbTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "212217f9-c6bd-4005-d48f-5492aab064d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms2PvHwVPYRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "def Wider_load(val=True,train=True,test=False):\n",
        "  os.makedirs('WIDER/', exist_ok=True)\n",
        "\n",
        "  if val:\n",
        "    #!gdown https://drive.google.com/uc?id=0B6eKvaijfFUDd3dIRmpvSk8tLUk\n",
        "    !gdown https://drive.google.com/uc?id=1-5A_pa_jDS7gk8mHVCBB7ApV5KN8jWDr -O WIDER/tempv.zip\n",
        "    !unzip -q WIDER/tempv.zip -d WIDER\n",
        "    !rm WIDER/tempv.zip  \n",
        "\n",
        "  if train:\n",
        "    ### WIDER Face Training Images\n",
        "    #!gdown https://drive.google.com/uc?id=0B6eKvaijfFUDQUUwd21EckhUbWs\n",
        "    !gdown https://drive.google.com/uc?id=1-1iJfmXKYvAx9uLdRDX5W6HHG_KZv1jH -O WIDER/temptr.zip\n",
        "    !unzip -q WIDER/temptr.zip -d WIDER\n",
        "    !rm WIDER/temptr.zip\n",
        "  \n",
        "  if test:\n",
        "    #!gdown https://drive.google.com/uc?id=0B6eKvaijfFUDbW4tdGpaYjgzZkU\n",
        "    !gdown https://drive.google.com/uc?id=1tTpUJZEQMKDVxKT6100V5FwDuGX_8sDi -O WIDER/tempt.zip\n",
        "    !unzip -q WIDER/tempt.zip -d WIDER\n",
        "    !rm WIDER/tempt.zip\n",
        "\n",
        "\n",
        "  ### Face annotations\n",
        "  !wget mmlab.ie.cuhk.edu.hk/projects/WIDERFace/support/bbx_annotation/wider_face_split.zip -O WIDER/tempa.zip\n",
        "  !unzip -q WIDER/tempa.zip -d WIDER\n",
        "  !rm WIDER/tempa.zip\n",
        "\n",
        "  #annotations\n",
        "  !gdown https://drive.google.com/uc?id=1_9ydMZlTNFXBOMl16xsU8FSBmK2PW4lN -O WIDER/tools.py\n",
        "\n",
        "\n",
        "  ### Examples and formats of the submissions\n",
        "  #!wget mmlab.ie.cuhk.edu.hk/projects/WIDERFace/support/example/Submission_example.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTdlDENQMRB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "35d16a07-57a2-4e82-a8e5-91163b140323"
      },
      "source": [
        "def repo_load():\n",
        "  !pip install cython pyyaml==5.1\n",
        "  !pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "\n",
        "  # install detectron2:\n",
        "  !git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "  !cd detectron2_repo && git reset a33fc53 --hard # v0.2\n",
        "  !pip install -q -e detectron2_repo\n",
        "\n",
        "\n",
        "repo_load()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n",
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.6/dist-packages (5.1)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-nsboob2w\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-nsboob2w\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (49.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.21)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=266458 sha256=a7358102284f8d761adf50aaab40ed73f607d24c71cd6dc53f0c738eb51ab36c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8eo8rn6l/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
            "Successfully built pycocotools\n",
            "\u001b[31mERROR: detectron2 0.2 has requirement pycocotools>=2.0.1, but you'll have pycocotools 2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0.1\n",
            "    Uninstalling pycocotools-2.0.1:\n",
            "      Successfully uninstalled pycocotools-2.0.1\n",
            "Successfully installed pycocotools-2.0\n",
            "fatal: destination path 'detectron2_repo' already exists and is not an empty directory.\n",
            "HEAD is now at a33fc53 release 0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpCvj21UPayq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "690e0854-a148-42fe-877a-f63062afe6ae"
      },
      "source": [
        "Wider_load()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-5A_pa_jDS7gk8mHVCBB7ApV5KN8jWDr\n",
            "To: /content/WIDER/tempv.zip\n",
            "363MB [00:06, 56.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-1iJfmXKYvAx9uLdRDX5W6HHG_KZv1jH\n",
            "To: /content/WIDER/temptr.zip\n",
            "1.47GB [00:23, 62.6MB/s]\n",
            "--2020-08-18 19:43:36--  http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/support/bbx_annotation/wider_face_split.zip\n",
            "Resolving mmlab.ie.cuhk.edu.hk (mmlab.ie.cuhk.edu.hk)... 137.189.99.12\n",
            "Connecting to mmlab.ie.cuhk.edu.hk (mmlab.ie.cuhk.edu.hk)|137.189.99.12|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3591642 (3.4M) [application/zip]\n",
            "Saving to: ‘WIDER/tempa.zip’\n",
            "\n",
            "WIDER/tempa.zip     100%[===================>]   3.42M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-08-18 19:43:36 (24.0 MB/s) - ‘WIDER/tempa.zip’ saved [3591642/3591642]\n",
            "\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_9ydMZlTNFXBOMl16xsU8FSBmK2PW4lN\n",
            "To: /content/WIDER/tools.py\n",
            "100% 4.47k/4.47k [00:00<00:00, 3.97MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQHoKyzznizS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "49776d5d-81ad-495b-fe37-b56984b96f34"
      },
      "source": [
        "!git clone https://github.com/DarekGit/detr.git  \n",
        "#!git clone https://github.com/facebookresearch/detr.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'detr'...\n",
            "remote: Enumerating objects: 182, done.\u001b[K\n",
            "remote: Total 182 (delta 0), reused 0 (delta 0), pack-reused 182\u001b[K\n",
            "Receiving objects: 100% (182/182), 12.82 MiB | 6.61 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzx4JAMasOcs",
        "colab_type": "text"
      },
      "source": [
        "<font color=red> Restart runtime to continue... <b>Crtl+M.</b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGYW4qkoKnHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "4335f520-c0df-41b2-f763-942a39987a38"
      },
      "source": [
        "!nvidia-smi\n",
        "from psutil import virtual_memory\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(virtual_memory().total / 1e9))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Aug 18 19:49:27 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucz8h0sBtzkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, torchvision\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import itertools\n",
        "import shutil\n",
        "import glob\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import ImageDraw, Image\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "import detectron2.utils.comm as comm\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer, HookBase\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_train_loader\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSh762BHzDlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from WIDER.tools import annotations,output_Files\n",
        "output_files=output_Files()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUhwnqHSqJRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/detr')\n",
        "from d2.train_net import Trainer, setup\n",
        "from d2.detr.config import add_detr_config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXMv27Egzvf5",
        "colab_type": "text"
      },
      "source": [
        "# Prepare the dataset\n",
        "\n",
        "## WIDER FACE: A Face Detection Benchmark\n",
        "http://shuoyang1213.me/WIDERFACE/ <br>\n",
        "\n",
        "https://arxiv.org/pdf/1511.06523.pdf <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMwVqEK1v9zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = annotations(\"train\")\n",
        "val = annotations('val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OofELeX8yX5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for d in [\"train\", \"val\"]:\n",
        "  DatasetCatalog.register(\"face_\" + d, lambda d=d: train if d == \"train\" else val)\n",
        "  MetadataCatalog.get(\"face_\" + d).set(thing_classes = ['face'])\n",
        "\n",
        "faces_metadata = MetadataCatalog.get(\"face_train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciNM6NTrfvNK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "bce7deff-7d49-43d3-98a8-3d3243cf4799"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "hist=dict(); hists={}\n",
        "for i in (range(len(train))):\n",
        "  f=len(train[i]['annotations'])\n",
        "  hist[f]= 1 +hist.get(f,0)\n",
        "  for k in sorted(hist):hists[k]=hist[k]\n",
        "\n",
        "pd.DataFrame(sorted([*zip(hist.keys(),hist.values())]), index=None, columns=['ilosc twarzy','ilosc obrazow'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ilosc twarzy</th>\n",
              "      <th>ilosc obrazow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>4635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>883</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>1001</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>1146</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>1750</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>1968</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>256 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     ilosc twarzy  ilosc obrazow\n",
              "0               1           4635\n",
              "1               2           1793\n",
              "2               3            827\n",
              "3               4            680\n",
              "4               5            504\n",
              "..            ...            ...\n",
              "251           883              1\n",
              "252          1001              1\n",
              "253          1146              2\n",
              "254          1750              1\n",
              "255          1968              1\n",
              "\n",
              "[256 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyQ2-ALw54Qt",
        "colab_type": "text"
      },
      "source": [
        "# \"detr_256_6_6_torchvision.yaml\"\n",
        "detr/configs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmaIYgDpVDAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = get_cfg()\n",
        "add_detr_config(cfg)\n",
        "\n",
        "cfg_file='detr_256_6_6_torchvision.yaml'\n",
        "cfg.merge_from_file('detr/d2/configs/'+cfg_file)\n",
        "\n",
        "cfg.MODEL.PIXEL_MEAN =(119.857,110.808,104.148)\n",
        "#cfg.MODEL.PIXEL_STD =(77.168,74.631,75.842)\n",
        "cfg.MODEL.PIXEL_STD =(0.6076259372440945, 0.5876417505511812, 0.5971849743307086)\n",
        "cfg.INPUT.FORMAT='RGB'\n",
        "cfg.MODEL.FORMAT='RGB'\n",
        "cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES=1\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class \n",
        "cfg.MODEL.DETR.NUM_CLASSES = 1\n",
        "cfg.MODEL.DETR.NUM_OBJECT_QUERIES = 2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veaaqv4g1cpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python detr/d2/converter.py --source_model https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth --output_model converted_model.pth >_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILZuPLmQvZKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg.DATASETS.TRAIN = (\"face_train\",)\n",
        "cfg.DATASETS.TEST = (\"face_val\",)\n",
        "cfg.DATASETS.VAL = (\"face_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 8\n",
        "\n",
        "cfg.MODEL.RESNETS.DEPTH = 50\n",
        "cfg.MODEL.BACKBONE.FREEZE_AT = 0\n",
        "cfg.MODEL.WEIGHTS = '' #\"converted_model.pth\" \n",
        "cfg.MODEL.RESNETS.NORM = 'FrozenBN'\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 1\n",
        "cfg.SOLVER.BASE_LR = 0.0001  #  LR\n",
        "cfg.SOLVER.MAX_ITER = 3600000    \n",
        "\n",
        "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupMultiStepLR\"\n",
        "cfg.SOLVER.WARMUP_ITERS = 3000\n",
        "cfg.SOLVER.WARMUP_FACTOR = .01\n",
        "cfg.SOLVER.STEPS =[]\n",
        "cfg.SOLVER.GAMMA = 0.1\n",
        "cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 0.1\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 10000\n",
        "cfg.TEST.EVAL_PERIOD = 6440\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfKvgofD6dEi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b3ebd15d-f73a-44d9-f34b-9bd0900782b4"
      },
      "source": [
        "# OUTPUT_DIR on Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "cfg.OUTPUT_DIR = os.path.join(\"./drive/My Drive/Face detection\", \"WIDER_DeTr\")\n",
        "#cfg.OUTPUT_DIR = os.path.join(\"OUTPUT\", \"WIDER_DeTr\")\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_R_0kY1NXXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81c2e308-7310-47b4-8286-1b1de32094fe"
      },
      "source": [
        "print(cfg.dump())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDNN_BENCHMARK: false\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: true\n",
            "  FILTER_EMPTY_ANNOTATIONS: false\n",
            "  NUM_WORKERS: 8\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: []\n",
            "  PROPOSAL_FILES_TRAIN: []\n",
            "  TEST:\n",
            "  - face_val\n",
            "  TRAIN:\n",
            "  - face_train\n",
            "  VAL:\n",
            "  - face_val\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: true\n",
            "    SIZE:\n",
            "    - 384\n",
            "    - 600\n",
            "    TYPE: absolute_range\n",
            "  FORMAT: RGB\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN:\n",
            "  - 480\n",
            "  - 512\n",
            "  - 544\n",
            "  - 576\n",
            "  - 608\n",
            "  - 640\n",
            "  - 672\n",
            "  - 704\n",
            "  - 736\n",
            "  - 768\n",
            "  - 800\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES:\n",
            "    - - -90\n",
            "      - 0\n",
            "      - 90\n",
            "    ASPECT_RATIOS:\n",
            "    - - 0.5\n",
            "      - 1.0\n",
            "      - 2.0\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES:\n",
            "    - - 32\n",
            "      - 64\n",
            "      - 128\n",
            "      - 256\n",
            "      - 512\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 0\n",
            "    NAME: build_resnet_backbone\n",
            "  DETR:\n",
            "    DEC_LAYERS: 6\n",
            "    DEEP_SUPERVISION: true\n",
            "    DIM_FEEDFORWARD: 2048\n",
            "    DROPOUT: 0.1\n",
            "    ENC_LAYERS: 6\n",
            "    GIOU_WEIGHT: 2.0\n",
            "    HIDDEN_DIM: 256\n",
            "    L1_WEIGHT: 5.0\n",
            "    NHEADS: 8\n",
            "    NO_OBJECT_WEIGHT: 0.1\n",
            "    NUM_CLASSES: 1\n",
            "    NUM_OBJECT_QUERIES: 2000\n",
            "    PRE_NORM: false\n",
            "  DEVICE: cuda\n",
            "  FORMAT: RGB\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: []\n",
            "    NORM: ''\n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: false\n",
            "  LOAD_PROPOSALS: false\n",
            "  MASK_ON: false\n",
            "  META_ARCHITECTURE: Detr\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: true\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN:\n",
            "  - 119.857\n",
            "  - 110.808\n",
            "  - 104.148\n",
            "  PIXEL_STD:\n",
            "  - 0.6076259372440945\n",
            "  - 0.5876417505511812\n",
            "  - 0.5971849743307086\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: false\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE:\n",
            "    - false\n",
            "    - false\n",
            "    - false\n",
            "    - false\n",
            "    DEPTH: 50\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES:\n",
            "    - res2\n",
            "    - res3\n",
            "    - res4\n",
            "    - res5\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: false\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_WEIGHTS:\n",
            "    - 1.0\n",
            "    - 1.0\n",
            "    - 1.0\n",
            "    - 1.0\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES:\n",
            "    - p3\n",
            "    - p4\n",
            "    - p5\n",
            "    - p6\n",
            "    - p7\n",
            "    IOU_LABELS:\n",
            "    - 0\n",
            "    - -1\n",
            "    - 1\n",
            "    IOU_THRESHOLDS:\n",
            "    - 0.4\n",
            "    - 0.5\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS:\n",
            "    - - 10.0\n",
            "      - 10.0\n",
            "      - 5.0\n",
            "      - 5.0\n",
            "    - - 20.0\n",
            "      - 20.0\n",
            "      - 10.0\n",
            "      - 10.0\n",
            "    - - 30.0\n",
            "      - 30.0\n",
            "      - 15.0\n",
            "      - 15.0\n",
            "    IOUS:\n",
            "    - 0.5\n",
            "    - 0.6\n",
            "    - 0.7\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS:\n",
            "    - 10.0\n",
            "    - 10.0\n",
            "    - 5.0\n",
            "    - 5.0\n",
            "    CLS_AGNOSTIC_BBOX_REG: false\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: ''\n",
            "    NORM: ''\n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 0\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: false\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES:\n",
            "    - res4\n",
            "    IOU_LABELS:\n",
            "    - 0\n",
            "    - 1\n",
            "    IOU_THRESHOLDS:\n",
            "    - 0.5\n",
            "    NAME: Res5ROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 1\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: true\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS:\n",
            "    - 512\n",
            "    - 512\n",
            "    - 512\n",
            "    - 512\n",
            "    - 512\n",
            "    - 512\n",
            "    - 512\n",
            "    - 512\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: false\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: ''\n",
            "    NUM_CONV: 0\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS:\n",
            "    - 1.0\n",
            "    - 1.0\n",
            "    - 1.0\n",
            "    - 1.0\n",
            "    BOUNDARY_THRESH: -1\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES:\n",
            "    - res4\n",
            "    IOU_LABELS:\n",
            "    - 0\n",
            "    - -1\n",
            "    - 1\n",
            "    IOU_THRESHOLDS:\n",
            "    - 0.3\n",
            "    - 0.7\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 2000\n",
            "    PRE_NMS_TOPK_TEST: 6000\n",
            "    PRE_NMS_TOPK_TRAIN: 12000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES:\n",
            "    - p2\n",
            "    - p3\n",
            "    - p4\n",
            "    - p5\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 1\n",
            "  WEIGHTS: ''\n",
            "OUTPUT_DIR: ./drive/My Drive/Face detection/WIDER_DeTr\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  BACKBONE_MULTIPLIER: 0.1\n",
            "  BASE_LR: 0.0001\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 10000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: full_model\n",
            "    CLIP_VALUE: 0.1\n",
            "    ENABLED: true\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 1\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 3600000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: false\n",
            "  OPTIMIZER: ADAMW\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: []\n",
            "  WARMUP_FACTOR: 0.01\n",
            "  WARMUP_ITERS: 3000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0.0001\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: false\n",
            "    FLIP: true\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES:\n",
            "    - 400\n",
            "    - 500\n",
            "    - 600\n",
            "    - 700\n",
            "    - 800\n",
            "    - 900\n",
            "    - 1000\n",
            "    - 1100\n",
            "    - 1200\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 6440\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: false\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPylJbuk9c30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "cfg_all=cfg_file.split('.')[-2]+'_ALL.json'\n",
        "cfg_all = os.path.join(cfg.OUTPUT_DIR, cfg_all)\n",
        "with open(cfg_all,'w') as f:\n",
        "  json.dump(cfg,f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BS-GIO0t5v-C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36950526-f038-4f13-a289-d3cffde0f984"
      },
      "source": [
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = Trainer(cfg) \n",
        "\n",
        "'''\n",
        "val_loss = Validation_Loss(cfg)  \n",
        "trainer.register_hooks([val_loss])\n",
        "trainer._hooks = trainer._hooks[:-2] + trainer._hooks[-2:][::-1]\n",
        "'''\n",
        "\n",
        "trainer.resume_or_load(resume=True)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[08/18 19:49:47 d2.engine.defaults]: \u001b[0mModel:\n",
            "Detr(\n",
            "  (detr): DETR(\n",
            "    (transformer): Transformer(\n",
            "      (encoder): TransformerEncoder(\n",
            "        (layers): ModuleList(\n",
            "          (0): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout1): Dropout(p=0.1, inplace=False)\n",
            "            (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout1): Dropout(p=0.1, inplace=False)\n",
            "            (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout1): Dropout(p=0.1, inplace=False)\n",
            "            (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (3): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout1): Dropout(p=0.1, inplace=False)\n",
            "            (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (4): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout1): Dropout(p=0.1, inplace=False)\n",
            "            (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (5): TransformerEncoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout1): Dropout(p=0.1, inplace=False)\n",
            "            (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (decoder): TransformerDecoder(\n",
            "        (layers): ModuleList(\n",
            "          (0): TransformerDecoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (multihead_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout1): Dropout(p=0.1, inplace=False)\n",
            "            (dropout2): Dropout(p=0.1, inplace=False)\n",
            "            (dropout3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): TransformerDecoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (multihead_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout1): Dropout(p=0.1, inplace=False)\n",
            "            (dropout2): Dropout(p=0.1, inplace=False)\n",
            "            (dropout3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): TransformerDecoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (multihead_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout1): Dropout(p=0.1, inplace=False)\n",
            "            (dropout2): Dropout(p=0.1, inplace=False)\n",
            "            (dropout3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (3): TransformerDecoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (multihead_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout1): Dropout(p=0.1, inplace=False)\n",
            "            (dropout2): Dropout(p=0.1, inplace=False)\n",
            "            (dropout3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (4): TransformerDecoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (multihead_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout1): Dropout(p=0.1, inplace=False)\n",
            "            (dropout2): Dropout(p=0.1, inplace=False)\n",
            "            (dropout3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (5): TransformerDecoderLayer(\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (multihead_attn): MultiheadAttention(\n",
            "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout1): Dropout(p=0.1, inplace=False)\n",
            "            (dropout2): Dropout(p=0.1, inplace=False)\n",
            "            (dropout3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (class_embed): Linear(in_features=256, out_features=2, bias=True)\n",
            "    (bbox_embed): MLP(\n",
            "      (layers): ModuleList(\n",
            "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (query_embed): Embedding(2000, 256)\n",
            "    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (backbone): Joiner(\n",
            "      (0): MaskedBackbone(\n",
            "        (backbone): ResNet(\n",
            "          (stem): BasicStem(\n",
            "            (conv1): Conv2d(\n",
            "              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "            )\n",
            "          )\n",
            "          (res2): Sequential(\n",
            "            (0): BottleneckBlock(\n",
            "              (shortcut): Conv2d(\n",
            "                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv1): Conv2d(\n",
            "                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "            (1): BottleneckBlock(\n",
            "              (conv1): Conv2d(\n",
            "                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "            (2): BottleneckBlock(\n",
            "              (conv1): Conv2d(\n",
            "                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (res3): Sequential(\n",
            "            (0): BottleneckBlock(\n",
            "              (shortcut): Conv2d(\n",
            "                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "              )\n",
            "              (conv1): Conv2d(\n",
            "                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "            (1): BottleneckBlock(\n",
            "              (conv1): Conv2d(\n",
            "                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "            (2): BottleneckBlock(\n",
            "              (conv1): Conv2d(\n",
            "                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "            (3): BottleneckBlock(\n",
            "              (conv1): Conv2d(\n",
            "                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (res4): Sequential(\n",
            "            (0): BottleneckBlock(\n",
            "              (shortcut): Conv2d(\n",
            "                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "              )\n",
            "              (conv1): Conv2d(\n",
            "                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "            (1): BottleneckBlock(\n",
            "              (conv1): Conv2d(\n",
            "                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "            (2): BottleneckBlock(\n",
            "              (conv1): Conv2d(\n",
            "                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "            (3): BottleneckBlock(\n",
            "              (conv1): Conv2d(\n",
            "                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "            (4): BottleneckBlock(\n",
            "              (conv1): Conv2d(\n",
            "                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "            (5): BottleneckBlock(\n",
            "              (conv1): Conv2d(\n",
            "                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (res5): Sequential(\n",
            "            (0): BottleneckBlock(\n",
            "              (shortcut): Conv2d(\n",
            "                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "              )\n",
            "              (conv1): Conv2d(\n",
            "                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "            (1): BottleneckBlock(\n",
            "              (conv1): Conv2d(\n",
            "                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "            (2): BottleneckBlock(\n",
            "              (conv1): Conv2d(\n",
            "                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "              )\n",
            "              (conv2): Conv2d(\n",
            "                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "              )\n",
            "              (conv3): Conv2d(\n",
            "                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): PositionEmbeddingSine()\n",
            "    )\n",
            "  )\n",
            "  (criterion): SetCriterion(\n",
            "    (matcher): HungarianMatcher()\n",
            "  )\n",
            ")\n",
            "\u001b[32m[08/18 19:49:47 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
            "\u001b[36m|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "|    face    | 159424       |\n",
            "|            |              |\u001b[0m\n",
            "\u001b[32m[08/18 19:49:47 d2.data.common]: \u001b[0mSerializing 12880 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/18 19:49:48 d2.data.common]: \u001b[0mSerialized dataset takes 12.74 MiB\n",
            "\u001b[32m[08/18 19:49:48 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[08/18 19:50:04 d2.engine.train_loop]: \u001b[0mStarting training from iteration 2440000\n",
            "\u001b[32m[08/18 19:50:11 d2.utils.events]: \u001b[0m eta: 3 days, 20:06:41  iter: 2440019  total_loss: 121.095  loss_ce: 0.067  loss_bbox: 0.365  loss_giou: 0.870  loss_ce_0: 0.070  loss_bbox_0: 0.338  loss_giou_0: 0.911  loss_ce_1: 0.068  loss_bbox_1: 0.413  loss_giou_1: 1.013  loss_ce_2: 0.071  loss_bbox_2: 0.315  loss_giou_2: 0.902  loss_ce_3: 0.073  loss_bbox_3: 0.359  loss_giou_3: 0.902  loss_ce_4: 0.073  loss_bbox_4: 0.405  loss_giou_4: 1.041  time: 0.2958  data_time: 0.0283  lr: 0.000100  max_mem: 5963M\n",
            "\u001b[32m[08/18 19:50:19 d2.utils.events]: \u001b[0m eta: 3 days, 20:30:33  iter: 2440039  total_loss: 148.961  loss_ce: 0.140  loss_bbox: 0.306  loss_giou: 1.172  loss_ce_0: 0.140  loss_bbox_0: 0.312  loss_giou_0: 1.204  loss_ce_1: 0.143  loss_bbox_1: 0.363  loss_giou_1: 1.248  loss_ce_2: 0.142  loss_bbox_2: 0.320  loss_giou_2: 1.152  loss_ce_3: 0.143  loss_bbox_3: 0.286  loss_giou_3: 1.214  loss_ce_4: 0.138  loss_bbox_4: 0.297  loss_giou_4: 1.205  time: 0.2951  data_time: 0.0020  lr: 0.000100  max_mem: 6176M\n",
            "\u001b[32m[08/18 19:50:25 d2.utils.events]: \u001b[0m eta: 3 days, 21:42:33  iter: 2440059  total_loss: 117.940  loss_ce: 0.061  loss_bbox: 0.318  loss_giou: 0.890  loss_ce_0: 0.066  loss_bbox_0: 0.318  loss_giou_0: 0.996  loss_ce_1: 0.058  loss_bbox_1: 0.371  loss_giou_1: 0.914  loss_ce_2: 0.065  loss_bbox_2: 0.282  loss_giou_2: 0.911  loss_ce_3: 0.064  loss_bbox_3: 0.316  loss_giou_3: 0.910  loss_ce_4: 0.065  loss_bbox_4: 0.373  loss_giou_4: 0.997  time: 0.2967  data_time: 0.0021  lr: 0.000100  max_mem: 6176M\n",
            "\u001b[32m[08/18 19:50:32 d2.utils.events]: \u001b[0m eta: 3 days, 22:42:13  iter: 2440079  total_loss: 146.574  loss_ce: 0.124  loss_bbox: 0.357  loss_giou: 1.117  loss_ce_0: 0.128  loss_bbox_0: 0.394  loss_giou_0: 1.144  loss_ce_1: 0.130  loss_bbox_1: 0.394  loss_giou_1: 1.152  loss_ce_2: 0.126  loss_bbox_2: 0.314  loss_giou_2: 1.078  loss_ce_3: 0.126  loss_bbox_3: 0.366  loss_giou_3: 1.120  loss_ce_4: 0.132  loss_bbox_4: 0.411  loss_giou_4: 1.194  time: 0.2984  data_time: 0.0019  lr: 0.000100  max_mem: 6176M\n",
            "\u001b[32m[08/18 19:50:37 d2.utils.events]: \u001b[0m eta: 3 days, 22:24:50  iter: 2440099  total_loss: 118.505  loss_ce: 0.068  loss_bbox: 0.293  loss_giou: 0.864  loss_ce_0: 0.072  loss_bbox_0: 0.312  loss_giou_0: 1.063  loss_ce_1: 0.068  loss_bbox_1: 0.373  loss_giou_1: 1.106  loss_ce_2: 0.071  loss_bbox_2: 0.276  loss_giou_2: 0.792  loss_ce_3: 0.073  loss_bbox_3: 0.248  loss_giou_3: 0.739  loss_ce_4: 0.070  loss_bbox_4: 0.308  loss_giou_4: 0.873  time: 0.2949  data_time: 0.0019  lr: 0.000100  max_mem: 6176M\n",
            "\u001b[32m[08/18 19:50:43 d2.utils.events]: \u001b[0m eta: 3 days, 22:31:28  iter: 2440119  total_loss: 119.545  loss_ce: 0.066  loss_bbox: 0.340  loss_giou: 0.947  loss_ce_0: 0.069  loss_bbox_0: 0.357  loss_giou_0: 0.975  loss_ce_1: 0.069  loss_bbox_1: 0.335  loss_giou_1: 0.946  loss_ce_2: 0.066  loss_bbox_2: 0.370  loss_giou_2: 1.155  loss_ce_3: 0.070  loss_bbox_3: 0.273  loss_giou_3: 0.883  loss_ce_4: 0.069  loss_bbox_4: 0.347  loss_giou_4: 0.941  time: 0.2961  data_time: 0.0019  lr: 0.000100  max_mem: 6260M\n",
            "\u001b[32m[08/18 19:50:49 d2.utils.events]: \u001b[0m eta: 3 days, 22:48:29  iter: 2440139  total_loss: 118.977  loss_ce: 0.062  loss_bbox: 0.343  loss_giou: 0.942  loss_ce_0: 0.063  loss_bbox_0: 0.341  loss_giou_0: 1.127  loss_ce_1: 0.061  loss_bbox_1: 0.300  loss_giou_1: 0.989  loss_ce_2: 0.065  loss_bbox_2: 0.334  loss_giou_2: 0.827  loss_ce_3: 0.064  loss_bbox_3: 0.324  loss_giou_3: 0.997  loss_ce_4: 0.062  loss_bbox_4: 0.316  loss_giou_4: 0.959  time: 0.2973  data_time: 0.0021  lr: 0.000100  max_mem: 6260M\n",
            "\u001b[32m[08/18 19:50:55 d2.utils.events]: \u001b[0m eta: 3 days, 22:52:35  iter: 2440159  total_loss: 129.652  loss_ce: 0.095  loss_bbox: 0.308  loss_giou: 1.067  loss_ce_0: 0.104  loss_bbox_0: 0.353  loss_giou_0: 1.080  loss_ce_1: 0.092  loss_bbox_1: 0.357  loss_giou_1: 1.149  loss_ce_2: 0.098  loss_bbox_2: 0.304  loss_giou_2: 1.032  loss_ce_3: 0.104  loss_bbox_3: 0.321  loss_giou_3: 1.038  loss_ce_4: 0.096  loss_bbox_4: 0.304  loss_giou_4: 0.981  time: 0.2975  data_time: 0.0022  lr: 0.000100  max_mem: 6260M\n",
            "\u001b[32m[08/18 19:51:01 d2.utils.events]: \u001b[0m eta: 3 days, 22:52:29  iter: 2440179  total_loss: 128.908  loss_ce: 0.082  loss_bbox: 0.309  loss_giou: 1.110  loss_ce_0: 0.087  loss_bbox_0: 0.302  loss_giou_0: 1.012  loss_ce_1: 0.093  loss_bbox_1: 0.338  loss_giou_1: 0.968  loss_ce_2: 0.090  loss_bbox_2: 0.290  loss_giou_2: 1.099  loss_ce_3: 0.091  loss_bbox_3: 0.302  loss_giou_3: 1.104  loss_ce_4: 0.088  loss_bbox_4: 0.310  loss_giou_4: 1.054  time: 0.2983  data_time: 0.0020  lr: 0.000100  max_mem: 6260M\n",
            "\u001b[32m[08/18 19:51:07 d2.utils.events]: \u001b[0m eta: 3 days, 22:52:23  iter: 2440199  total_loss: 122.848  loss_ce: 0.075  loss_bbox: 0.267  loss_giou: 0.966  loss_ce_0: 0.079  loss_bbox_0: 0.327  loss_giou_0: 1.069  loss_ce_1: 0.079  loss_bbox_1: 0.301  loss_giou_1: 0.893  loss_ce_2: 0.075  loss_bbox_2: 0.332  loss_giou_2: 0.942  loss_ce_3: 0.082  loss_bbox_3: 0.287  loss_giou_3: 0.892  loss_ce_4: 0.074  loss_bbox_4: 0.335  loss_giou_4: 0.930  time: 0.2981  data_time: 0.0020  lr: 0.000100  max_mem: 6260M\n",
            "\u001b[32m[08/18 19:51:13 d2.utils.events]: \u001b[0m eta: 3 days, 22:49:35  iter: 2440219  total_loss: 134.788  loss_ce: 0.106  loss_bbox: 0.275  loss_giou: 1.089  loss_ce_0: 0.105  loss_bbox_0: 0.295  loss_giou_0: 1.109  loss_ce_1: 0.108  loss_bbox_1: 0.358  loss_giou_1: 1.131  loss_ce_2: 0.101  loss_bbox_2: 0.258  loss_giou_2: 1.080  loss_ce_3: 0.109  loss_bbox_3: 0.260  loss_giou_3: 1.115  loss_ce_4: 0.103  loss_bbox_4: 0.314  loss_giou_4: 1.167  time: 0.2979  data_time: 0.0021  lr: 0.000100  max_mem: 6260M\n",
            "\u001b[32m[08/18 19:51:19 d2.utils.events]: \u001b[0m eta: 3 days, 22:49:29  iter: 2440239  total_loss: 126.849  loss_ce: 0.093  loss_bbox: 0.293  loss_giou: 1.173  loss_ce_0: 0.091  loss_bbox_0: 0.307  loss_giou_0: 1.233  loss_ce_1: 0.091  loss_bbox_1: 0.306  loss_giou_1: 1.190  loss_ce_2: 0.087  loss_bbox_2: 0.284  loss_giou_2: 1.271  loss_ce_3: 0.088  loss_bbox_3: 0.279  loss_giou_3: 1.136  loss_ce_4: 0.085  loss_bbox_4: 0.288  loss_giou_4: 1.174  time: 0.2978  data_time: 0.0019  lr: 0.000100  max_mem: 6260M\n",
            "\u001b[32m[08/18 19:51:25 d2.utils.events]: \u001b[0m eta: 3 days, 22:27:11  iter: 2440259  total_loss: 134.739  loss_ce: 0.111  loss_bbox: 0.307  loss_giou: 1.186  loss_ce_0: 0.110  loss_bbox_0: 0.247  loss_giou_0: 1.043  loss_ce_1: 0.113  loss_bbox_1: 0.349  loss_giou_1: 1.149  loss_ce_2: 0.112  loss_bbox_2: 0.302  loss_giou_2: 1.212  loss_ce_3: 0.116  loss_bbox_3: 0.285  loss_giou_3: 1.105  loss_ce_4: 0.113  loss_bbox_4: 0.286  loss_giou_4: 0.996  time: 0.2970  data_time: 0.0019  lr: 0.000100  max_mem: 6260M\n",
            "\u001b[32m[08/18 19:51:31 d2.utils.events]: \u001b[0m eta: 3 days, 22:23:56  iter: 2440279  total_loss: 120.586  loss_ce: 0.077  loss_bbox: 0.428  loss_giou: 1.090  loss_ce_0: 0.075  loss_bbox_0: 0.404  loss_giou_0: 1.051  loss_ce_1: 0.077  loss_bbox_1: 0.315  loss_giou_1: 1.000  loss_ce_2: 0.072  loss_bbox_2: 0.367  loss_giou_2: 1.023  loss_ce_3: 0.077  loss_bbox_3: 0.397  loss_giou_3: 1.032  loss_ce_4: 0.074  loss_bbox_4: 0.340  loss_giou_4: 0.899  time: 0.2969  data_time: 0.0019  lr: 0.000100  max_mem: 6260M\n",
            "\u001b[32m[08/18 19:51:37 d2.utils.events]: \u001b[0m eta: 3 days, 22:20:10  iter: 2440299  total_loss: 131.019  loss_ce: 0.093  loss_bbox: 0.332  loss_giou: 1.228  loss_ce_0: 0.091  loss_bbox_0: 0.315  loss_giou_0: 1.132  loss_ce_1: 0.091  loss_bbox_1: 0.386  loss_giou_1: 1.262  loss_ce_2: 0.090  loss_bbox_2: 0.366  loss_giou_2: 1.198  loss_ce_3: 0.097  loss_bbox_3: 0.341  loss_giou_3: 1.178  loss_ce_4: 0.094  loss_bbox_4: 0.397  loss_giou_4: 1.253  time: 0.2973  data_time: 0.0021  lr: 0.000100  max_mem: 6260M\n",
            "\u001b[32m[08/18 19:51:43 d2.utils.events]: \u001b[0m eta: 3 days, 22:22:03  iter: 2440319  total_loss: 118.706  loss_ce: 0.073  loss_bbox: 0.314  loss_giou: 1.095  loss_ce_0: 0.078  loss_bbox_0: 0.349  loss_giou_0: 1.228  loss_ce_1: 0.074  loss_bbox_1: 0.368  loss_giou_1: 1.146  loss_ce_2: 0.074  loss_bbox_2: 0.307  loss_giou_2: 1.038  loss_ce_3: 0.077  loss_bbox_3: 0.309  loss_giou_3: 1.056  loss_ce_4: 0.076  loss_bbox_4: 0.354  loss_giou_4: 1.122  time: 0.2977  data_time: 0.0021  lr: 0.000100  max_mem: 6381M\n",
            "\u001b[32m[08/18 19:51:49 d2.utils.events]: \u001b[0m eta: 3 days, 22:21:57  iter: 2440339  total_loss: 122.238  loss_ce: 0.076  loss_bbox: 0.302  loss_giou: 0.844  loss_ce_0: 0.079  loss_bbox_0: 0.280  loss_giou_0: 1.030  loss_ce_1: 0.078  loss_bbox_1: 0.375  loss_giou_1: 0.960  loss_ce_2: 0.082  loss_bbox_2: 0.308  loss_giou_2: 0.944  loss_ce_3: 0.082  loss_bbox_3: 0.323  loss_giou_3: 0.896  loss_ce_4: 0.080  loss_bbox_4: 0.309  loss_giou_4: 0.826  time: 0.2977  data_time: 0.0022  lr: 0.000100  max_mem: 6381M\n",
            "\u001b[32m[08/18 19:51:55 d2.utils.events]: \u001b[0m eta: 3 days, 22:26:42  iter: 2440359  total_loss: 122.076  loss_ce: 0.087  loss_bbox: 0.399  loss_giou: 0.821  loss_ce_0: 0.085  loss_bbox_0: 0.423  loss_giou_0: 0.984  loss_ce_1: 0.083  loss_bbox_1: 0.476  loss_giou_1: 0.992  loss_ce_2: 0.083  loss_bbox_2: 0.346  loss_giou_2: 0.976  loss_ce_3: 0.087  loss_bbox_3: 0.375  loss_giou_3: 0.891  loss_ce_4: 0.083  loss_bbox_4: 0.349  loss_giou_4: 0.958  time: 0.2988  data_time: 0.0020  lr: 0.000100  max_mem: 6387M\n",
            "\u001b[32m[08/18 19:52:01 d2.utils.events]: \u001b[0m eta: 3 days, 22:19:46  iter: 2440379  total_loss: 147.805  loss_ce: 0.132  loss_bbox: 0.326  loss_giou: 1.123  loss_ce_0: 0.130  loss_bbox_0: 0.312  loss_giou_0: 1.021  loss_ce_1: 0.132  loss_bbox_1: 0.394  loss_giou_1: 1.189  loss_ce_2: 0.134  loss_bbox_2: 0.374  loss_giou_2: 1.072  loss_ce_3: 0.138  loss_bbox_3: 0.340  loss_giou_3: 1.071  loss_ce_4: 0.131  loss_bbox_4: 0.339  loss_giou_4: 1.066  time: 0.2982  data_time: 0.0019  lr: 0.000100  max_mem: 6387M\n",
            "\u001b[32m[08/18 19:52:07 d2.utils.events]: \u001b[0m eta: 3 days, 22:23:03  iter: 2440399  total_loss: 141.345  loss_ce: 0.126  loss_bbox: 0.369  loss_giou: 1.067  loss_ce_0: 0.125  loss_bbox_0: 0.322  loss_giou_0: 1.001  loss_ce_1: 0.126  loss_bbox_1: 0.328  loss_giou_1: 1.006  loss_ce_2: 0.128  loss_bbox_2: 0.331  loss_giou_2: 1.031  loss_ce_3: 0.127  loss_bbox_3: 0.360  loss_giou_3: 1.022  loss_ce_4: 0.125  loss_bbox_4: 0.350  loss_giou_4: 1.035  time: 0.2984  data_time: 0.0021  lr: 0.000100  max_mem: 6388M\n",
            "\u001b[32m[08/18 19:52:13 d2.utils.events]: \u001b[0m eta: 3 days, 22:19:35  iter: 2440419  total_loss: 134.521  loss_ce: 0.100  loss_bbox: 0.359  loss_giou: 1.167  loss_ce_0: 0.097  loss_bbox_0: 0.353  loss_giou_0: 1.124  loss_ce_1: 0.104  loss_bbox_1: 0.300  loss_giou_1: 1.117  loss_ce_2: 0.104  loss_bbox_2: 0.328  loss_giou_2: 1.087  loss_ce_3: 0.106  loss_bbox_3: 0.311  loss_giou_3: 1.104  loss_ce_4: 0.103  loss_bbox_4: 0.360  loss_giou_4: 1.145  time: 0.2980  data_time: 0.0019  lr: 0.000100  max_mem: 6388M\n",
            "\u001b[32m[08/18 19:52:19 d2.utils.events]: \u001b[0m eta: 3 days, 22:19:29  iter: 2440439  total_loss: 123.488  loss_ce: 0.073  loss_bbox: 0.408  loss_giou: 1.034  loss_ce_0: 0.073  loss_bbox_0: 0.336  loss_giou_0: 1.118  loss_ce_1: 0.077  loss_bbox_1: 0.388  loss_giou_1: 0.993  loss_ce_2: 0.075  loss_bbox_2: 0.359  loss_giou_2: 0.990  loss_ce_3: 0.075  loss_bbox_3: 0.343  loss_giou_3: 1.034  loss_ce_4: 0.073  loss_bbox_4: 0.403  loss_giou_4: 1.043  time: 0.2981  data_time: 0.0020  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:52:25 d2.utils.events]: \u001b[0m eta: 3 days, 22:15:22  iter: 2440459  total_loss: 119.988  loss_ce: 0.069  loss_bbox: 0.409  loss_giou: 1.078  loss_ce_0: 0.069  loss_bbox_0: 0.319  loss_giou_0: 1.069  loss_ce_1: 0.070  loss_bbox_1: 0.412  loss_giou_1: 1.106  loss_ce_2: 0.074  loss_bbox_2: 0.311  loss_giou_2: 1.110  loss_ce_3: 0.076  loss_bbox_3: 0.370  loss_giou_3: 1.092  loss_ce_4: 0.070  loss_bbox_4: 0.367  loss_giou_4: 0.939  time: 0.2976  data_time: 0.0019  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:52:31 d2.utils.events]: \u001b[0m eta: 3 days, 22:13:19  iter: 2440479  total_loss: 120.335  loss_ce: 0.071  loss_bbox: 0.300  loss_giou: 0.909  loss_ce_0: 0.069  loss_bbox_0: 0.343  loss_giou_0: 0.974  loss_ce_1: 0.072  loss_bbox_1: 0.374  loss_giou_1: 1.004  loss_ce_2: 0.072  loss_bbox_2: 0.339  loss_giou_2: 0.947  loss_ce_3: 0.073  loss_bbox_3: 0.321  loss_giou_3: 0.911  loss_ce_4: 0.068  loss_bbox_4: 0.339  loss_giou_4: 1.002  time: 0.2974  data_time: 0.0020  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:52:37 d2.utils.events]: \u001b[0m eta: 3 days, 22:17:07  iter: 2440499  total_loss: 114.387  loss_ce: 0.058  loss_bbox: 0.305  loss_giou: 0.785  loss_ce_0: 0.061  loss_bbox_0: 0.272  loss_giou_0: 0.841  loss_ce_1: 0.061  loss_bbox_1: 0.304  loss_giou_1: 0.873  loss_ce_2: 0.062  loss_bbox_2: 0.319  loss_giou_2: 0.805  loss_ce_3: 0.066  loss_bbox_3: 0.227  loss_giou_3: 0.774  loss_ce_4: 0.061  loss_bbox_4: 0.258  loss_giou_4: 0.682  time: 0.2975  data_time: 0.0019  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:52:42 d2.utils.events]: \u001b[0m eta: 3 days, 22:15:04  iter: 2440519  total_loss: 129.614  loss_ce: 0.092  loss_bbox: 0.303  loss_giou: 1.026  loss_ce_0: 0.100  loss_bbox_0: 0.293  loss_giou_0: 1.180  loss_ce_1: 0.100  loss_bbox_1: 0.335  loss_giou_1: 1.049  loss_ce_2: 0.099  loss_bbox_2: 0.397  loss_giou_2: 1.094  loss_ce_3: 0.105  loss_bbox_3: 0.303  loss_giou_3: 1.025  loss_ce_4: 0.102  loss_bbox_4: 0.296  loss_giou_4: 1.151  time: 0.2970  data_time: 0.0020  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:52:48 d2.utils.events]: \u001b[0m eta: 3 days, 22:01:22  iter: 2440539  total_loss: 115.876  loss_ce: 0.060  loss_bbox: 0.300  loss_giou: 0.925  loss_ce_0: 0.064  loss_bbox_0: 0.313  loss_giou_0: 1.097  loss_ce_1: 0.063  loss_bbox_1: 0.380  loss_giou_1: 0.971  loss_ce_2: 0.061  loss_bbox_2: 0.306  loss_giou_2: 1.076  loss_ce_3: 0.068  loss_bbox_3: 0.320  loss_giou_3: 0.887  loss_ce_4: 0.062  loss_bbox_4: 0.293  loss_giou_4: 0.787  time: 0.2966  data_time: 0.0020  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:52:54 d2.utils.events]: \u001b[0m eta: 3 days, 22:04:56  iter: 2440559  total_loss: 139.142  loss_ce: 0.113  loss_bbox: 0.353  loss_giou: 1.203  loss_ce_0: 0.119  loss_bbox_0: 0.340  loss_giou_0: 1.096  loss_ce_1: 0.121  loss_bbox_1: 0.345  loss_giou_1: 1.168  loss_ce_2: 0.121  loss_bbox_2: 0.346  loss_giou_2: 1.115  loss_ce_3: 0.123  loss_bbox_3: 0.324  loss_giou_3: 1.144  loss_ce_4: 0.119  loss_bbox_4: 0.334  loss_giou_4: 1.228  time: 0.2970  data_time: 0.0020  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:53:00 d2.utils.events]: \u001b[0m eta: 3 days, 21:57:45  iter: 2440579  total_loss: 122.828  loss_ce: 0.080  loss_bbox: 0.312  loss_giou: 0.803  loss_ce_0: 0.086  loss_bbox_0: 0.321  loss_giou_0: 0.888  loss_ce_1: 0.086  loss_bbox_1: 0.287  loss_giou_1: 0.930  loss_ce_2: 0.084  loss_bbox_2: 0.284  loss_giou_2: 0.772  loss_ce_3: 0.092  loss_bbox_3: 0.300  loss_giou_3: 0.980  loss_ce_4: 0.086  loss_bbox_4: 0.297  loss_giou_4: 0.960  time: 0.2966  data_time: 0.0020  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:53:06 d2.utils.events]: \u001b[0m eta: 3 days, 21:58:09  iter: 2440599  total_loss: 119.733  loss_ce: 0.066  loss_bbox: 0.373  loss_giou: 0.943  loss_ce_0: 0.068  loss_bbox_0: 0.331  loss_giou_0: 0.970  loss_ce_1: 0.071  loss_bbox_1: 0.367  loss_giou_1: 0.932  loss_ce_2: 0.069  loss_bbox_2: 0.333  loss_giou_2: 0.870  loss_ce_3: 0.071  loss_bbox_3: 0.318  loss_giou_3: 0.883  loss_ce_4: 0.070  loss_bbox_4: 0.317  loss_giou_4: 0.868  time: 0.2966  data_time: 0.0020  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:53:12 d2.utils.events]: \u001b[0m eta: 3 days, 22:00:59  iter: 2440619  total_loss: 127.131  loss_ce: 0.081  loss_bbox: 0.406  loss_giou: 1.189  loss_ce_0: 0.088  loss_bbox_0: 0.355  loss_giou_0: 1.227  loss_ce_1: 0.089  loss_bbox_1: 0.359  loss_giou_1: 1.120  loss_ce_2: 0.086  loss_bbox_2: 0.378  loss_giou_2: 1.183  loss_ce_3: 0.092  loss_bbox_3: 0.337  loss_giou_3: 1.271  loss_ce_4: 0.084  loss_bbox_4: 0.394  loss_giou_4: 1.331  time: 0.2967  data_time: 0.0022  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:53:18 d2.utils.events]: \u001b[0m eta: 3 days, 21:57:28  iter: 2440639  total_loss: 116.703  loss_ce: 0.066  loss_bbox: 0.298  loss_giou: 0.800  loss_ce_0: 0.068  loss_bbox_0: 0.298  loss_giou_0: 0.878  loss_ce_1: 0.066  loss_bbox_1: 0.346  loss_giou_1: 0.708  loss_ce_2: 0.068  loss_bbox_2: 0.321  loss_giou_2: 0.736  loss_ce_3: 0.072  loss_bbox_3: 0.303  loss_giou_3: 0.746  loss_ce_4: 0.070  loss_bbox_4: 0.334  loss_giou_4: 0.808  time: 0.2964  data_time: 0.0019  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:53:24 d2.utils.events]: \u001b[0m eta: 3 days, 21:57:22  iter: 2440659  total_loss: 122.253  loss_ce: 0.073  loss_bbox: 0.391  loss_giou: 1.069  loss_ce_0: 0.074  loss_bbox_0: 0.343  loss_giou_0: 1.128  loss_ce_1: 0.075  loss_bbox_1: 0.356  loss_giou_1: 0.977  loss_ce_2: 0.073  loss_bbox_2: 0.357  loss_giou_2: 1.099  loss_ce_3: 0.076  loss_bbox_3: 0.367  loss_giou_3: 0.974  loss_ce_4: 0.073  loss_bbox_4: 0.327  loss_giou_4: 1.061  time: 0.2963  data_time: 0.0020  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:53:30 d2.utils.events]: \u001b[0m eta: 3 days, 21:57:16  iter: 2440679  total_loss: 131.912  loss_ce: 0.092  loss_bbox: 0.405  loss_giou: 1.108  loss_ce_0: 0.091  loss_bbox_0: 0.293  loss_giou_0: 1.071  loss_ce_1: 0.097  loss_bbox_1: 0.311  loss_giou_1: 1.203  loss_ce_2: 0.095  loss_bbox_2: 0.345  loss_giou_2: 1.122  loss_ce_3: 0.097  loss_bbox_3: 0.325  loss_giou_3: 1.214  loss_ce_4: 0.096  loss_bbox_4: 0.318  loss_giou_4: 1.025  time: 0.2962  data_time: 0.0019  lr: 0.000100  max_mem: 6533M\n",
            "\u001b[32m[08/18 19:53:35 d2.utils.events]: \u001b[0m eta: 3 days, 21:45:07  iter: 2440699  total_loss: 119.991  loss_ce: 0.062  loss_bbox: 0.339  loss_giou: 0.972  loss_ce_0: 0.064  loss_bbox_0: 0.302  loss_giou_0: 0.895  loss_ce_1: 0.066  loss_bbox_1: 0.314  loss_giou_1: 0.947  loss_ce_2: 0.065  loss_bbox_2: 0.335  loss_giou_2: 1.036  loss_ce_3: 0.063  loss_bbox_3: 0.300  loss_giou_3: 0.999  loss_ce_4: 0.069  loss_bbox_4: 0.288  loss_giou_4: 1.101  time: 0.2958  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 19:53:41 d2.utils.events]: \u001b[0m eta: 3 days, 21:45:58  iter: 2440719  total_loss: 123.161  loss_ce: 0.073  loss_bbox: 0.323  loss_giou: 0.871  loss_ce_0: 0.077  loss_bbox_0: 0.303  loss_giou_0: 0.945  loss_ce_1: 0.079  loss_bbox_1: 0.359  loss_giou_1: 0.911  loss_ce_2: 0.077  loss_bbox_2: 0.315  loss_giou_2: 0.914  loss_ce_3: 0.081  loss_bbox_3: 0.312  loss_giou_3: 1.026  loss_ce_4: 0.077  loss_bbox_4: 0.305  loss_giou_4: 0.855  time: 0.2956  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 19:53:47 d2.utils.events]: \u001b[0m eta: 3 days, 21:55:37  iter: 2440739  total_loss: 132.868  loss_ce: 0.090  loss_bbox: 0.334  loss_giou: 1.001  loss_ce_0: 0.094  loss_bbox_0: 0.307  loss_giou_0: 1.089  loss_ce_1: 0.095  loss_bbox_1: 0.336  loss_giou_1: 0.965  loss_ce_2: 0.094  loss_bbox_2: 0.342  loss_giou_2: 0.967  loss_ce_3: 0.095  loss_bbox_3: 0.326  loss_giou_3: 1.107  loss_ce_4: 0.094  loss_bbox_4: 0.363  loss_giou_4: 1.132  time: 0.2957  data_time: 0.0021  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 19:53:53 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
            "\u001b[36m|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "|    face    | 39708        |\n",
            "|            |              |\u001b[0m\n",
            "\u001b[32m[08/18 19:53:53 d2.data.common]: \u001b[0mSerializing 3226 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/18 19:53:53 d2.data.common]: \u001b[0mSerialized dataset takes 3.16 MiB\n",
            "\u001b[32m[08/18 19:53:53 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[08/18 19:53:53 d2.evaluation.coco_evaluation]: \u001b[0m'face_val' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/18 19:53:53 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at './drive/My Drive/Face detection/WIDER_DeTr/inference/face_val_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
            "\u001b[32m[08/18 19:53:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 3226 images\n",
            "\u001b[32m[08/18 19:53:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/3226. 0.0916 s / img. ETA=0:08:05\n",
            "\u001b[32m[08/18 19:54:01 d2.evaluation.evaluator]: \u001b[0mInference done 65/3226. 0.0901 s / img. ETA=0:05:11\n",
            "\u001b[32m[08/18 19:54:06 d2.evaluation.evaluator]: \u001b[0mInference done 116/3226. 0.0900 s / img. ETA=0:05:06\n",
            "\u001b[32m[08/18 19:54:11 d2.evaluation.evaluator]: \u001b[0mInference done 169/3226. 0.0906 s / img. ETA=0:04:57\n",
            "\u001b[32m[08/18 19:54:16 d2.evaluation.evaluator]: \u001b[0mInference done 219/3226. 0.0907 s / img. ETA=0:04:55\n",
            "\u001b[32m[08/18 19:54:21 d2.evaluation.evaluator]: \u001b[0mInference done 272/3226. 0.0911 s / img. ETA=0:04:48\n",
            "\u001b[32m[08/18 19:54:26 d2.evaluation.evaluator]: \u001b[0mInference done 322/3226. 0.0910 s / img. ETA=0:04:45\n",
            "\u001b[32m[08/18 19:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 376/3226. 0.0910 s / img. ETA=0:04:38\n",
            "\u001b[32m[08/18 19:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 431/3226. 0.0909 s / img. ETA=0:04:31\n",
            "\u001b[32m[08/18 19:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 480/3226. 0.0909 s / img. ETA=0:04:28\n",
            "\u001b[32m[08/18 19:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 533/3226. 0.0910 s / img. ETA=0:04:22\n",
            "\u001b[32m[08/18 19:54:51 d2.evaluation.evaluator]: \u001b[0mInference done 586/3226. 0.0910 s / img. ETA=0:04:16\n",
            "\u001b[32m[08/18 19:54:57 d2.evaluation.evaluator]: \u001b[0mInference done 640/3226. 0.0911 s / img. ETA=0:04:10\n",
            "\u001b[32m[08/18 19:55:02 d2.evaluation.evaluator]: \u001b[0mInference done 688/3226. 0.0910 s / img. ETA=0:04:07\n",
            "\u001b[32m[08/18 19:55:07 d2.evaluation.evaluator]: \u001b[0mInference done 743/3226. 0.0908 s / img. ETA=0:04:00\n",
            "\u001b[32m[08/18 19:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 796/3226. 0.0909 s / img. ETA=0:03:55\n",
            "\u001b[32m[08/18 19:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 849/3226. 0.0910 s / img. ETA=0:03:49\n",
            "\u001b[32m[08/18 19:55:22 d2.evaluation.evaluator]: \u001b[0mInference done 902/3226. 0.0910 s / img. ETA=0:03:44\n",
            "\u001b[32m[08/18 19:55:27 d2.evaluation.evaluator]: \u001b[0mInference done 949/3226. 0.0910 s / img. ETA=0:03:41\n",
            "\u001b[32m[08/18 19:55:32 d2.evaluation.evaluator]: \u001b[0mInference done 1003/3226. 0.0910 s / img. ETA=0:03:35\n",
            "\u001b[32m[08/18 19:55:37 d2.evaluation.evaluator]: \u001b[0mInference done 1057/3226. 0.0909 s / img. ETA=0:03:29\n",
            "\u001b[32m[08/18 19:55:42 d2.evaluation.evaluator]: \u001b[0mInference done 1112/3226. 0.0909 s / img. ETA=0:03:24\n",
            "\u001b[32m[08/18 19:55:47 d2.evaluation.evaluator]: \u001b[0mInference done 1165/3226. 0.0909 s / img. ETA=0:03:18\n",
            "\u001b[32m[08/18 19:55:52 d2.evaluation.evaluator]: \u001b[0mInference done 1218/3226. 0.0909 s / img. ETA=0:03:13\n",
            "\u001b[32m[08/18 19:55:57 d2.evaluation.evaluator]: \u001b[0mInference done 1264/3226. 0.0909 s / img. ETA=0:03:10\n",
            "\u001b[32m[08/18 19:56:02 d2.evaluation.evaluator]: \u001b[0mInference done 1318/3226. 0.0909 s / img. ETA=0:03:04\n",
            "\u001b[32m[08/18 19:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 1372/3226. 0.0909 s / img. ETA=0:02:59\n",
            "\u001b[32m[08/18 19:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 1426/3226. 0.0909 s / img. ETA=0:02:53\n",
            "\u001b[32m[08/18 19:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 1482/3226. 0.0907 s / img. ETA=0:02:47\n",
            "\u001b[32m[08/18 19:56:22 d2.evaluation.evaluator]: \u001b[0mInference done 1538/3226. 0.0906 s / img. ETA=0:02:42\n",
            "\u001b[32m[08/18 19:56:27 d2.evaluation.evaluator]: \u001b[0mInference done 1593/3226. 0.0906 s / img. ETA=0:02:36\n",
            "\u001b[32m[08/18 19:56:32 d2.evaluation.evaluator]: \u001b[0mInference done 1637/3226. 0.0905 s / img. ETA=0:02:33\n",
            "\u001b[32m[08/18 19:56:37 d2.evaluation.evaluator]: \u001b[0mInference done 1691/3226. 0.0905 s / img. ETA=0:02:27\n",
            "\u001b[32m[08/18 19:56:42 d2.evaluation.evaluator]: \u001b[0mInference done 1745/3226. 0.0905 s / img. ETA=0:02:22\n",
            "\u001b[32m[08/18 19:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 1799/3226. 0.0906 s / img. ETA=0:02:17\n",
            "\u001b[32m[08/18 19:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 1853/3226. 0.0906 s / img. ETA=0:02:11\n",
            "\u001b[32m[08/18 19:56:58 d2.evaluation.evaluator]: \u001b[0mInference done 1907/3226. 0.0906 s / img. ETA=0:02:06\n",
            "\u001b[32m[08/18 19:57:03 d2.evaluation.evaluator]: \u001b[0mInference done 1962/3226. 0.0905 s / img. ETA=0:02:01\n",
            "\u001b[32m[08/18 19:57:08 d2.evaluation.evaluator]: \u001b[0mInference done 2016/3226. 0.0905 s / img. ETA=0:01:55\n",
            "\u001b[32m[08/18 19:57:13 d2.evaluation.evaluator]: \u001b[0mInference done 2069/3226. 0.0906 s / img. ETA=0:01:50\n",
            "\u001b[32m[08/18 19:57:19 d2.evaluation.evaluator]: \u001b[0mInference done 2121/3226. 0.0906 s / img. ETA=0:01:46\n",
            "\u001b[32m[08/18 19:57:24 d2.evaluation.evaluator]: \u001b[0mInference done 2175/3226. 0.0906 s / img. ETA=0:01:41\n",
            "\u001b[32m[08/18 19:57:29 d2.evaluation.evaluator]: \u001b[0mInference done 2229/3226. 0.0906 s / img. ETA=0:01:35\n",
            "\u001b[32m[08/18 19:57:34 d2.evaluation.evaluator]: \u001b[0mInference done 2283/3226. 0.0906 s / img. ETA=0:01:30\n",
            "\u001b[32m[08/18 19:57:39 d2.evaluation.evaluator]: \u001b[0mInference done 2336/3226. 0.0906 s / img. ETA=0:01:25\n",
            "\u001b[32m[08/18 19:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 2389/3226. 0.0906 s / img. ETA=0:01:20\n",
            "\u001b[32m[08/18 19:57:49 d2.evaluation.evaluator]: \u001b[0mInference done 2443/3226. 0.0906 s / img. ETA=0:01:15\n",
            "\u001b[32m[08/18 19:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 2496/3226. 0.0906 s / img. ETA=0:01:10\n",
            "\u001b[32m[08/18 19:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 2551/3226. 0.0906 s / img. ETA=0:01:04\n",
            "\u001b[32m[08/18 19:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 2605/3226. 0.0906 s / img. ETA=0:00:59\n",
            "\u001b[32m[08/18 19:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 2659/3226. 0.0906 s / img. ETA=0:00:54\n",
            "\u001b[32m[08/18 19:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 2712/3226. 0.0906 s / img. ETA=0:00:49\n",
            "\u001b[32m[08/18 19:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 2751/3226. 0.0906 s / img. ETA=0:00:45\n",
            "\u001b[32m[08/18 19:58:24 d2.evaluation.evaluator]: \u001b[0mInference done 2805/3226. 0.0906 s / img. ETA=0:00:40\n",
            "\u001b[32m[08/18 19:58:29 d2.evaluation.evaluator]: \u001b[0mInference done 2859/3226. 0.0906 s / img. ETA=0:00:35\n",
            "\u001b[32m[08/18 19:58:34 d2.evaluation.evaluator]: \u001b[0mInference done 2912/3226. 0.0906 s / img. ETA=0:00:30\n",
            "\u001b[32m[08/18 19:58:39 d2.evaluation.evaluator]: \u001b[0mInference done 2967/3226. 0.0906 s / img. ETA=0:00:24\n",
            "\u001b[32m[08/18 19:58:44 d2.evaluation.evaluator]: \u001b[0mInference done 3021/3226. 0.0906 s / img. ETA=0:00:19\n",
            "\u001b[32m[08/18 19:58:49 d2.evaluation.evaluator]: \u001b[0mInference done 3075/3226. 0.0906 s / img. ETA=0:00:14\n",
            "\u001b[32m[08/18 19:58:54 d2.evaluation.evaluator]: \u001b[0mInference done 3129/3226. 0.0906 s / img. ETA=0:00:09\n",
            "\u001b[32m[08/18 19:58:59 d2.evaluation.evaluator]: \u001b[0mInference done 3182/3226. 0.0906 s / img. ETA=0:00:04\n",
            "\u001b[32m[08/18 19:59:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:08.689573 (0.095837 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/18 19:59:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:51 (0.090624 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/18 19:59:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/18 19:59:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./drive/My Drive/Face detection/WIDER_DeTr/inference/coco_instances_results.json\n",
            "\u001b[32m[08/18 20:00:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=15.62s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 15.99 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.40 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "\u001b[32m[08/18 20:01:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.000 | 0.001  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
            "\u001b[32m[08/18 20:01:07 d2.engine.defaults]: \u001b[0mEvaluation results for face_val in csv format:\n",
            "\u001b[32m[08/18 20:01:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/18 20:01:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[08/18 20:01:07 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0002,0.0008,0.0000,0.0000,0.0002,0.0000\n",
            "\u001b[32m[08/18 20:01:09 d2.utils.events]: \u001b[0m eta: 3 days, 21:50:51  iter: 2440759  total_loss: 115.181  loss_ce: 0.053  loss_bbox: 0.325  loss_giou: 0.908  loss_ce_0: 0.055  loss_bbox_0: 0.292  loss_giou_0: 0.921  loss_ce_1: 0.058  loss_bbox_1: 0.370  loss_giou_1: 0.988  loss_ce_2: 0.057  loss_bbox_2: 0.261  loss_giou_2: 0.920  loss_ce_3: 0.059  loss_bbox_3: 0.352  loss_giou_3: 0.916  loss_ce_4: 0.055  loss_bbox_4: 0.300  loss_giou_4: 0.881  time: 0.2957  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:01:15 d2.utils.events]: \u001b[0m eta: 3 days, 21:46:41  iter: 2440779  total_loss: 114.955  loss_ce: 0.054  loss_bbox: 0.424  loss_giou: 0.836  loss_ce_0: 0.056  loss_bbox_0: 0.369  loss_giou_0: 0.913  loss_ce_1: 0.056  loss_bbox_1: 0.407  loss_giou_1: 0.882  loss_ce_2: 0.053  loss_bbox_2: 0.408  loss_giou_2: 0.856  loss_ce_3: 0.059  loss_bbox_3: 0.333  loss_giou_3: 0.921  loss_ce_4: 0.057  loss_bbox_4: 0.412  loss_giou_4: 0.794  time: 0.2956  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:01:21 d2.utils.events]: \u001b[0m eta: 3 days, 21:46:35  iter: 2440799  total_loss: 126.908  loss_ce: 0.082  loss_bbox: 0.363  loss_giou: 0.858  loss_ce_0: 0.083  loss_bbox_0: 0.315  loss_giou_0: 0.763  loss_ce_1: 0.090  loss_bbox_1: 0.346  loss_giou_1: 0.897  loss_ce_2: 0.082  loss_bbox_2: 0.330  loss_giou_2: 0.861  loss_ce_3: 0.086  loss_bbox_3: 0.303  loss_giou_3: 0.749  loss_ce_4: 0.084  loss_bbox_4: 0.312  loss_giou_4: 0.891  time: 0.2954  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:01:26 d2.utils.events]: \u001b[0m eta: 3 days, 21:45:29  iter: 2440819  total_loss: 119.202  loss_ce: 0.064  loss_bbox: 0.356  loss_giou: 1.000  loss_ce_0: 0.065  loss_bbox_0: 0.333  loss_giou_0: 0.926  loss_ce_1: 0.069  loss_bbox_1: 0.328  loss_giou_1: 0.977  loss_ce_2: 0.068  loss_bbox_2: 0.336  loss_giou_2: 0.890  loss_ce_3: 0.066  loss_bbox_3: 0.292  loss_giou_3: 0.931  loss_ce_4: 0.069  loss_bbox_4: 0.341  loss_giou_4: 0.858  time: 0.2952  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:01:32 d2.utils.events]: \u001b[0m eta: 3 days, 21:44:26  iter: 2440839  total_loss: 134.577  loss_ce: 0.100  loss_bbox: 0.377  loss_giou: 1.115  loss_ce_0: 0.101  loss_bbox_0: 0.268  loss_giou_0: 0.992  loss_ce_1: 0.102  loss_bbox_1: 0.356  loss_giou_1: 1.112  loss_ce_2: 0.094  loss_bbox_2: 0.313  loss_giou_2: 1.145  loss_ce_3: 0.099  loss_bbox_3: 0.297  loss_giou_3: 1.070  loss_ce_4: 0.096  loss_bbox_4: 0.351  loss_giou_4: 1.012  time: 0.2950  data_time: 0.0020  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:01:38 d2.utils.events]: \u001b[0m eta: 3 days, 21:45:17  iter: 2440859  total_loss: 120.901  loss_ce: 0.065  loss_bbox: 0.398  loss_giou: 1.070  loss_ce_0: 0.068  loss_bbox_0: 0.376  loss_giou_0: 0.954  loss_ce_1: 0.070  loss_bbox_1: 0.384  loss_giou_1: 0.918  loss_ce_2: 0.066  loss_bbox_2: 0.384  loss_giou_2: 0.930  loss_ce_3: 0.068  loss_bbox_3: 0.370  loss_giou_3: 0.903  loss_ce_4: 0.069  loss_bbox_4: 0.414  loss_giou_4: 0.840  time: 0.2949  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:01:44 d2.utils.events]: \u001b[0m eta: 3 days, 21:43:05  iter: 2440879  total_loss: 145.671  loss_ce: 0.125  loss_bbox: 0.327  loss_giou: 1.180  loss_ce_0: 0.123  loss_bbox_0: 0.337  loss_giou_0: 1.191  loss_ce_1: 0.128  loss_bbox_1: 0.366  loss_giou_1: 1.233  loss_ce_2: 0.129  loss_bbox_2: 0.304  loss_giou_2: 1.114  loss_ce_3: 0.123  loss_bbox_3: 0.296  loss_giou_3: 1.112  loss_ce_4: 0.127  loss_bbox_4: 0.326  loss_giou_4: 1.104  time: 0.2947  data_time: 0.0020  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:01:49 d2.utils.events]: \u001b[0m eta: 3 days, 21:42:50  iter: 2440899  total_loss: 185.870  loss_ce: 0.209  loss_bbox: 0.338  loss_giou: 1.386  loss_ce_0: 0.217  loss_bbox_0: 0.342  loss_giou_0: 1.336  loss_ce_1: 0.210  loss_bbox_1: 0.346  loss_giou_1: 1.300  loss_ce_2: 0.210  loss_bbox_2: 0.323  loss_giou_2: 1.390  loss_ce_3: 0.211  loss_bbox_3: 0.310  loss_giou_3: 1.282  loss_ce_4: 0.207  loss_bbox_4: 0.301  loss_giou_4: 1.335  time: 0.2946  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:01:55 d2.utils.events]: \u001b[0m eta: 3 days, 21:42:44  iter: 2440919  total_loss: 131.031  loss_ce: 0.088  loss_bbox: 0.345  loss_giou: 1.114  loss_ce_0: 0.083  loss_bbox_0: 0.291  loss_giou_0: 1.102  loss_ce_1: 0.088  loss_bbox_1: 0.316  loss_giou_1: 1.168  loss_ce_2: 0.083  loss_bbox_2: 0.332  loss_giou_2: 1.181  loss_ce_3: 0.086  loss_bbox_3: 0.293  loss_giou_3: 1.067  loss_ce_4: 0.089  loss_bbox_4: 0.289  loss_giou_4: 0.996  time: 0.2946  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:02:01 d2.utils.events]: \u001b[0m eta: 3 days, 21:39:06  iter: 2440939  total_loss: 114.830  loss_ce: 0.054  loss_bbox: 0.300  loss_giou: 0.825  loss_ce_0: 0.052  loss_bbox_0: 0.359  loss_giou_0: 1.001  loss_ce_1: 0.057  loss_bbox_1: 0.306  loss_giou_1: 0.957  loss_ce_2: 0.051  loss_bbox_2: 0.317  loss_giou_2: 0.961  loss_ce_3: 0.055  loss_bbox_3: 0.350  loss_giou_3: 0.917  loss_ce_4: 0.055  loss_bbox_4: 0.321  loss_giou_4: 0.861  time: 0.2944  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:02:07 d2.utils.events]: \u001b[0m eta: 3 days, 21:42:33  iter: 2440959  total_loss: 113.941  loss_ce: 0.056  loss_bbox: 0.325  loss_giou: 0.799  loss_ce_0: 0.056  loss_bbox_0: 0.282  loss_giou_0: 0.679  loss_ce_1: 0.060  loss_bbox_1: 0.307  loss_giou_1: 0.678  loss_ce_2: 0.056  loss_bbox_2: 0.323  loss_giou_2: 0.699  loss_ce_3: 0.058  loss_bbox_3: 0.271  loss_giou_3: 0.657  loss_ce_4: 0.057  loss_bbox_4: 0.258  loss_giou_4: 0.624  time: 0.2945  data_time: 0.0023  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:02:13 d2.utils.events]: \u001b[0m eta: 3 days, 21:43:04  iter: 2440979  total_loss: 142.433  loss_ce: 0.117  loss_bbox: 0.347  loss_giou: 1.233  loss_ce_0: 0.117  loss_bbox_0: 0.309  loss_giou_0: 1.220  loss_ce_1: 0.120  loss_bbox_1: 0.295  loss_giou_1: 1.163  loss_ce_2: 0.120  loss_bbox_2: 0.336  loss_giou_2: 1.083  loss_ce_3: 0.116  loss_bbox_3: 0.310  loss_giou_3: 1.150  loss_ce_4: 0.122  loss_bbox_4: 0.291  loss_giou_4: 1.234  time: 0.2947  data_time: 0.0021  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:02:19 d2.utils.events]: \u001b[0m eta: 3 days, 21:43:39  iter: 2440999  total_loss: 121.260  loss_ce: 0.073  loss_bbox: 0.386  loss_giou: 1.046  loss_ce_0: 0.077  loss_bbox_0: 0.409  loss_giou_0: 0.964  loss_ce_1: 0.078  loss_bbox_1: 0.413  loss_giou_1: 1.130  loss_ce_2: 0.078  loss_bbox_2: 0.306  loss_giou_2: 0.930  loss_ce_3: 0.078  loss_bbox_3: 0.395  loss_giou_3: 1.043  loss_ce_4: 0.076  loss_bbox_4: 0.398  loss_giou_4: 1.002  time: 0.2947  data_time: 0.0020  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:02:25 d2.utils.events]: \u001b[0m eta: 3 days, 21:42:52  iter: 2441019  total_loss: 113.419  loss_ce: 0.051  loss_bbox: 0.324  loss_giou: 0.732  loss_ce_0: 0.055  loss_bbox_0: 0.347  loss_giou_0: 0.896  loss_ce_1: 0.055  loss_bbox_1: 0.350  loss_giou_1: 0.826  loss_ce_2: 0.055  loss_bbox_2: 0.357  loss_giou_2: 0.931  loss_ce_3: 0.055  loss_bbox_3: 0.302  loss_giou_3: 0.709  loss_ce_4: 0.052  loss_bbox_4: 0.311  loss_giou_4: 0.858  time: 0.2945  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:02:31 d2.utils.events]: \u001b[0m eta: 3 days, 21:49:48  iter: 2441039  total_loss: 125.098  loss_ce: 0.070  loss_bbox: 0.351  loss_giou: 1.102  loss_ce_0: 0.072  loss_bbox_0: 0.366  loss_giou_0: 1.100  loss_ce_1: 0.075  loss_bbox_1: 0.403  loss_giou_1: 1.078  loss_ce_2: 0.072  loss_bbox_2: 0.427  loss_giou_2: 1.139  loss_ce_3: 0.073  loss_bbox_3: 0.400  loss_giou_3: 1.114  loss_ce_4: 0.068  loss_bbox_4: 0.334  loss_giou_4: 1.271  time: 0.2944  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:02:36 d2.utils.events]: \u001b[0m eta: 3 days, 21:41:06  iter: 2441059  total_loss: 127.573  loss_ce: 0.086  loss_bbox: 0.355  loss_giou: 0.954  loss_ce_0: 0.089  loss_bbox_0: 0.370  loss_giou_0: 1.068  loss_ce_1: 0.091  loss_bbox_1: 0.313  loss_giou_1: 0.998  loss_ce_2: 0.089  loss_bbox_2: 0.380  loss_giou_2: 0.949  loss_ce_3: 0.092  loss_bbox_3: 0.327  loss_giou_3: 0.975  loss_ce_4: 0.086  loss_bbox_4: 0.339  loss_giou_4: 0.981  time: 0.2941  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:02:42 d2.utils.events]: \u001b[0m eta: 3 days, 21:25:35  iter: 2441079  total_loss: 119.698  loss_ce: 0.066  loss_bbox: 0.357  loss_giou: 0.902  loss_ce_0: 0.067  loss_bbox_0: 0.318  loss_giou_0: 0.901  loss_ce_1: 0.074  loss_bbox_1: 0.395  loss_giou_1: 0.944  loss_ce_2: 0.068  loss_bbox_2: 0.374  loss_giou_2: 0.891  loss_ce_3: 0.071  loss_bbox_3: 0.362  loss_giou_3: 0.924  loss_ce_4: 0.069  loss_bbox_4: 0.327  loss_giou_4: 0.767  time: 0.2941  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:02:48 d2.utils.events]: \u001b[0m eta: 3 days, 21:20:58  iter: 2441099  total_loss: 122.277  loss_ce: 0.074  loss_bbox: 0.329  loss_giou: 1.101  loss_ce_0: 0.081  loss_bbox_0: 0.343  loss_giou_0: 1.141  loss_ce_1: 0.080  loss_bbox_1: 0.336  loss_giou_1: 1.065  loss_ce_2: 0.078  loss_bbox_2: 0.330  loss_giou_2: 1.076  loss_ce_3: 0.078  loss_bbox_3: 0.294  loss_giou_3: 1.027  loss_ce_4: 0.075  loss_bbox_4: 0.305  loss_giou_4: 1.037  time: 0.2939  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:02:54 d2.utils.events]: \u001b[0m eta: 3 days, 21:19:37  iter: 2441119  total_loss: 122.459  loss_ce: 0.073  loss_bbox: 0.309  loss_giou: 0.964  loss_ce_0: 0.078  loss_bbox_0: 0.277  loss_giou_0: 0.998  loss_ce_1: 0.078  loss_bbox_1: 0.291  loss_giou_1: 1.002  loss_ce_2: 0.078  loss_bbox_2: 0.319  loss_giou_2: 0.956  loss_ce_3: 0.079  loss_bbox_3: 0.313  loss_giou_3: 1.007  loss_ce_4: 0.078  loss_bbox_4: 0.362  loss_giou_4: 1.004  time: 0.2938  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:02:59 d2.utils.events]: \u001b[0m eta: 3 days, 21:08:57  iter: 2441139  total_loss: 120.327  loss_ce: 0.058  loss_bbox: 0.413  loss_giou: 0.874  loss_ce_0: 0.061  loss_bbox_0: 0.368  loss_giou_0: 0.952  loss_ce_1: 0.065  loss_bbox_1: 0.313  loss_giou_1: 0.857  loss_ce_2: 0.062  loss_bbox_2: 0.326  loss_giou_2: 0.994  loss_ce_3: 0.062  loss_bbox_3: 0.328  loss_giou_3: 0.864  loss_ce_4: 0.062  loss_bbox_4: 0.340  loss_giou_4: 0.898  time: 0.2938  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:03:05 d2.utils.events]: \u001b[0m eta: 3 days, 20:59:55  iter: 2441159  total_loss: 126.864  loss_ce: 0.078  loss_bbox: 0.315  loss_giou: 0.962  loss_ce_0: 0.082  loss_bbox_0: 0.330  loss_giou_0: 0.979  loss_ce_1: 0.077  loss_bbox_1: 0.272  loss_giou_1: 1.129  loss_ce_2: 0.081  loss_bbox_2: 0.272  loss_giou_2: 1.030  loss_ce_3: 0.078  loss_bbox_3: 0.283  loss_giou_3: 1.093  loss_ce_4: 0.080  loss_bbox_4: 0.292  loss_giou_4: 1.048  time: 0.2935  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:03:11 d2.utils.events]: \u001b[0m eta: 3 days, 20:59:22  iter: 2441179  total_loss: 129.957  loss_ce: 0.086  loss_bbox: 0.303  loss_giou: 1.173  loss_ce_0: 0.094  loss_bbox_0: 0.334  loss_giou_0: 1.302  loss_ce_1: 0.091  loss_bbox_1: 0.328  loss_giou_1: 1.303  loss_ce_2: 0.089  loss_bbox_2: 0.315  loss_giou_2: 1.225  loss_ce_3: 0.091  loss_bbox_3: 0.308  loss_giou_3: 1.403  loss_ce_4: 0.092  loss_bbox_4: 0.317  loss_giou_4: 1.040  time: 0.2934  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:03:16 d2.utils.events]: \u001b[0m eta: 3 days, 20:58:19  iter: 2441199  total_loss: 127.746  loss_ce: 0.085  loss_bbox: 0.322  loss_giou: 1.037  loss_ce_0: 0.085  loss_bbox_0: 0.298  loss_giou_0: 1.025  loss_ce_1: 0.088  loss_bbox_1: 0.287  loss_giou_1: 1.023  loss_ce_2: 0.082  loss_bbox_2: 0.275  loss_giou_2: 1.131  loss_ce_3: 0.089  loss_bbox_3: 0.330  loss_giou_3: 1.089  loss_ce_4: 0.086  loss_bbox_4: 0.287  loss_giou_4: 0.938  time: 0.2933  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:03:22 d2.utils.events]: \u001b[0m eta: 3 days, 20:58:22  iter: 2441219  total_loss: 139.482  loss_ce: 0.110  loss_bbox: 0.355  loss_giou: 1.124  loss_ce_0: 0.112  loss_bbox_0: 0.305  loss_giou_0: 1.121  loss_ce_1: 0.115  loss_bbox_1: 0.331  loss_giou_1: 1.121  loss_ce_2: 0.113  loss_bbox_2: 0.330  loss_giou_2: 1.120  loss_ce_3: 0.114  loss_bbox_3: 0.289  loss_giou_3: 1.026  loss_ce_4: 0.114  loss_bbox_4: 0.307  loss_giou_4: 1.030  time: 0.2932  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:03:28 d2.utils.events]: \u001b[0m eta: 3 days, 20:51:24  iter: 2441239  total_loss: 125.257  loss_ce: 0.071  loss_bbox: 0.331  loss_giou: 1.049  loss_ce_0: 0.069  loss_bbox_0: 0.297  loss_giou_0: 1.150  loss_ce_1: 0.069  loss_bbox_1: 0.315  loss_giou_1: 1.188  loss_ce_2: 0.067  loss_bbox_2: 0.350  loss_giou_2: 1.117  loss_ce_3: 0.071  loss_bbox_3: 0.328  loss_giou_3: 1.045  loss_ce_4: 0.069  loss_bbox_4: 0.317  loss_giou_4: 1.190  time: 0.2932  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:03:34 d2.utils.events]: \u001b[0m eta: 3 days, 20:58:59  iter: 2441259  total_loss: 123.271  loss_ce: 0.071  loss_bbox: 0.367  loss_giou: 1.056  loss_ce_0: 0.075  loss_bbox_0: 0.374  loss_giou_0: 1.065  loss_ce_1: 0.072  loss_bbox_1: 0.342  loss_giou_1: 0.985  loss_ce_2: 0.073  loss_bbox_2: 0.343  loss_giou_2: 1.029  loss_ce_3: 0.074  loss_bbox_3: 0.371  loss_giou_3: 1.006  loss_ce_4: 0.074  loss_bbox_4: 0.325  loss_giou_4: 1.019  time: 0.2933  data_time: 0.0020  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:03:40 d2.utils.events]: \u001b[0m eta: 3 days, 20:54:12  iter: 2441279  total_loss: 150.763  loss_ce: 0.142  loss_bbox: 0.292  loss_giou: 1.054  loss_ce_0: 0.146  loss_bbox_0: 0.295  loss_giou_0: 1.124  loss_ce_1: 0.146  loss_bbox_1: 0.324  loss_giou_1: 1.153  loss_ce_2: 0.144  loss_bbox_2: 0.301  loss_giou_2: 1.080  loss_ce_3: 0.148  loss_bbox_3: 0.325  loss_giou_3: 1.049  loss_ce_4: 0.140  loss_bbox_4: 0.343  loss_giou_4: 1.084  time: 0.2932  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:03:46 d2.utils.events]: \u001b[0m eta: 3 days, 20:54:07  iter: 2441299  total_loss: 122.796  loss_ce: 0.068  loss_bbox: 0.327  loss_giou: 0.900  loss_ce_0: 0.072  loss_bbox_0: 0.316  loss_giou_0: 1.047  loss_ce_1: 0.070  loss_bbox_1: 0.330  loss_giou_1: 1.055  loss_ce_2: 0.070  loss_bbox_2: 0.327  loss_giou_2: 1.126  loss_ce_3: 0.072  loss_bbox_3: 0.361  loss_giou_3: 1.111  loss_ce_4: 0.071  loss_bbox_4: 0.288  loss_giou_4: 1.045  time: 0.2934  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:03:52 d2.utils.events]: \u001b[0m eta: 3 days, 20:51:01  iter: 2441319  total_loss: 126.445  loss_ce: 0.082  loss_bbox: 0.282  loss_giou: 0.866  loss_ce_0: 0.085  loss_bbox_0: 0.289  loss_giou_0: 0.951  loss_ce_1: 0.085  loss_bbox_1: 0.318  loss_giou_1: 0.968  loss_ce_2: 0.085  loss_bbox_2: 0.291  loss_giou_2: 1.007  loss_ce_3: 0.085  loss_bbox_3: 0.275  loss_giou_3: 0.983  loss_ce_4: 0.090  loss_bbox_4: 0.262  loss_giou_4: 0.924  time: 0.2934  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:03:58 d2.utils.events]: \u001b[0m eta: 3 days, 20:50:55  iter: 2441339  total_loss: 120.359  loss_ce: 0.056  loss_bbox: 0.353  loss_giou: 1.174  loss_ce_0: 0.051  loss_bbox_0: 0.257  loss_giou_0: 1.184  loss_ce_1: 0.054  loss_bbox_1: 0.291  loss_giou_1: 1.069  loss_ce_2: 0.055  loss_bbox_2: 0.340  loss_giou_2: 1.233  loss_ce_3: 0.057  loss_bbox_3: 0.284  loss_giou_3: 1.165  loss_ce_4: 0.055  loss_bbox_4: 0.306  loss_giou_4: 1.261  time: 0.2934  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:04:03 d2.utils.events]: \u001b[0m eta: 3 days, 20:40:56  iter: 2441359  total_loss: 114.072  loss_ce: 0.046  loss_bbox: 0.288  loss_giou: 0.696  loss_ce_0: 0.046  loss_bbox_0: 0.307  loss_giou_0: 0.651  loss_ce_1: 0.050  loss_bbox_1: 0.388  loss_giou_1: 0.792  loss_ce_2: 0.048  loss_bbox_2: 0.341  loss_giou_2: 0.897  loss_ce_3: 0.049  loss_bbox_3: 0.361  loss_giou_3: 0.787  loss_ce_4: 0.050  loss_bbox_4: 0.432  loss_giou_4: 0.875  time: 0.2932  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:04:09 d2.utils.events]: \u001b[0m eta: 3 days, 20:41:55  iter: 2441379  total_loss: 124.072  loss_ce: 0.070  loss_bbox: 0.332  loss_giou: 0.955  loss_ce_0: 0.068  loss_bbox_0: 0.306  loss_giou_0: 0.882  loss_ce_1: 0.072  loss_bbox_1: 0.323  loss_giou_1: 1.157  loss_ce_2: 0.068  loss_bbox_2: 0.342  loss_giou_2: 1.047  loss_ce_3: 0.068  loss_bbox_3: 0.293  loss_giou_3: 1.008  loss_ce_4: 0.070  loss_bbox_4: 0.297  loss_giou_4: 1.016  time: 0.2932  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:04:15 d2.utils.events]: \u001b[0m eta: 3 days, 20:37:57  iter: 2441399  total_loss: 126.029  loss_ce: 0.075  loss_bbox: 0.319  loss_giou: 0.811  loss_ce_0: 0.078  loss_bbox_0: 0.377  loss_giou_0: 0.868  loss_ce_1: 0.078  loss_bbox_1: 0.339  loss_giou_1: 0.984  loss_ce_2: 0.076  loss_bbox_2: 0.308  loss_giou_2: 0.849  loss_ce_3: 0.075  loss_bbox_3: 0.280  loss_giou_3: 0.902  loss_ce_4: 0.076  loss_bbox_4: 0.317  loss_giou_4: 1.014  time: 0.2931  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:04:21 d2.utils.events]: \u001b[0m eta: 3 days, 20:35:11  iter: 2441419  total_loss: 113.918  loss_ce: 0.046  loss_bbox: 0.316  loss_giou: 0.840  loss_ce_0: 0.046  loss_bbox_0: 0.375  loss_giou_0: 0.831  loss_ce_1: 0.049  loss_bbox_1: 0.319  loss_giou_1: 0.791  loss_ce_2: 0.046  loss_bbox_2: 0.392  loss_giou_2: 0.772  loss_ce_3: 0.048  loss_bbox_3: 0.303  loss_giou_3: 0.767  loss_ce_4: 0.050  loss_bbox_4: 0.355  loss_giou_4: 0.806  time: 0.2930  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:04:27 d2.utils.events]: \u001b[0m eta: 3 days, 20:37:45  iter: 2441439  total_loss: 124.459  loss_ce: 0.075  loss_bbox: 0.342  loss_giou: 1.089  loss_ce_0: 0.074  loss_bbox_0: 0.304  loss_giou_0: 1.072  loss_ce_1: 0.071  loss_bbox_1: 0.281  loss_giou_1: 1.080  loss_ce_2: 0.075  loss_bbox_2: 0.317  loss_giou_2: 1.170  loss_ce_3: 0.072  loss_bbox_3: 0.280  loss_giou_3: 1.198  loss_ce_4: 0.074  loss_bbox_4: 0.304  loss_giou_4: 1.073  time: 0.2931  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:04:33 d2.utils.events]: \u001b[0m eta: 3 days, 20:39:16  iter: 2441459  total_loss: 123.365  loss_ce: 0.070  loss_bbox: 0.346  loss_giou: 1.165  loss_ce_0: 0.065  loss_bbox_0: 0.295  loss_giou_0: 1.275  loss_ce_1: 0.072  loss_bbox_1: 0.265  loss_giou_1: 1.146  loss_ce_2: 0.068  loss_bbox_2: 0.310  loss_giou_2: 1.184  loss_ce_3: 0.070  loss_bbox_3: 0.353  loss_giou_3: 1.223  loss_ce_4: 0.068  loss_bbox_4: 0.268  loss_giou_4: 1.123  time: 0.2931  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:04:38 d2.utils.events]: \u001b[0m eta: 3 days, 20:35:51  iter: 2441479  total_loss: 130.175  loss_ce: 0.095  loss_bbox: 0.316  loss_giou: 1.112  loss_ce_0: 0.091  loss_bbox_0: 0.341  loss_giou_0: 1.162  loss_ce_1: 0.096  loss_bbox_1: 0.308  loss_giou_1: 1.084  loss_ce_2: 0.097  loss_bbox_2: 0.331  loss_giou_2: 1.102  loss_ce_3: 0.091  loss_bbox_3: 0.303  loss_giou_3: 1.157  loss_ce_4: 0.095  loss_bbox_4: 0.279  loss_giou_4: 1.068  time: 0.2931  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:04:44 d2.utils.events]: \u001b[0m eta: 3 days, 20:26:18  iter: 2441499  total_loss: 135.514  loss_ce: 0.111  loss_bbox: 0.280  loss_giou: 0.936  loss_ce_0: 0.110  loss_bbox_0: 0.288  loss_giou_0: 1.034  loss_ce_1: 0.115  loss_bbox_1: 0.320  loss_giou_1: 0.926  loss_ce_2: 0.110  loss_bbox_2: 0.294  loss_giou_2: 1.006  loss_ce_3: 0.116  loss_bbox_3: 0.277  loss_giou_3: 0.906  loss_ce_4: 0.115  loss_bbox_4: 0.283  loss_giou_4: 0.999  time: 0.2930  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:04:50 d2.utils.events]: \u001b[0m eta: 3 days, 20:25:13  iter: 2441519  total_loss: 138.757  loss_ce: 0.111  loss_bbox: 0.315  loss_giou: 1.133  loss_ce_0: 0.114  loss_bbox_0: 0.299  loss_giou_0: 1.180  loss_ce_1: 0.118  loss_bbox_1: 0.295  loss_giou_1: 1.164  loss_ce_2: 0.113  loss_bbox_2: 0.299  loss_giou_2: 1.087  loss_ce_3: 0.113  loss_bbox_3: 0.271  loss_giou_3: 1.108  loss_ce_4: 0.111  loss_bbox_4: 0.298  loss_giou_4: 1.070  time: 0.2928  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:04:55 d2.utils.events]: \u001b[0m eta: 3 days, 20:26:07  iter: 2441539  total_loss: 120.703  loss_ce: 0.066  loss_bbox: 0.317  loss_giou: 0.960  loss_ce_0: 0.065  loss_bbox_0: 0.299  loss_giou_0: 1.099  loss_ce_1: 0.069  loss_bbox_1: 0.368  loss_giou_1: 1.064  loss_ce_2: 0.066  loss_bbox_2: 0.358  loss_giou_2: 1.064  loss_ce_3: 0.069  loss_bbox_3: 0.359  loss_giou_3: 1.016  loss_ce_4: 0.067  loss_bbox_4: 0.337  loss_giou_4: 0.994  time: 0.2927  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:05:01 d2.utils.events]: \u001b[0m eta: 3 days, 20:25:48  iter: 2441559  total_loss: 125.927  loss_ce: 0.088  loss_bbox: 0.360  loss_giou: 0.972  loss_ce_0: 0.088  loss_bbox_0: 0.321  loss_giou_0: 0.919  loss_ce_1: 0.089  loss_bbox_1: 0.300  loss_giou_1: 0.979  loss_ce_2: 0.085  loss_bbox_2: 0.370  loss_giou_2: 1.001  loss_ce_3: 0.090  loss_bbox_3: 0.335  loss_giou_3: 0.961  loss_ce_4: 0.088  loss_bbox_4: 0.358  loss_giou_4: 0.965  time: 0.2928  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:05:07 d2.utils.events]: \u001b[0m eta: 3 days, 20:25:55  iter: 2441579  total_loss: 122.739  loss_ce: 0.073  loss_bbox: 0.322  loss_giou: 1.156  loss_ce_0: 0.070  loss_bbox_0: 0.316  loss_giou_0: 1.182  loss_ce_1: 0.074  loss_bbox_1: 0.303  loss_giou_1: 1.210  loss_ce_2: 0.071  loss_bbox_2: 0.281  loss_giou_2: 1.131  loss_ce_3: 0.074  loss_bbox_3: 0.295  loss_giou_3: 1.101  loss_ce_4: 0.076  loss_bbox_4: 0.314  loss_giou_4: 1.111  time: 0.2927  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:05:13 d2.utils.events]: \u001b[0m eta: 3 days, 20:25:49  iter: 2441599  total_loss: 123.579  loss_ce: 0.079  loss_bbox: 0.319  loss_giou: 1.002  loss_ce_0: 0.079  loss_bbox_0: 0.303  loss_giou_0: 1.165  loss_ce_1: 0.081  loss_bbox_1: 0.349  loss_giou_1: 1.197  loss_ce_2: 0.076  loss_bbox_2: 0.317  loss_giou_2: 1.078  loss_ce_3: 0.076  loss_bbox_3: 0.313  loss_giou_3: 0.939  loss_ce_4: 0.079  loss_bbox_4: 0.351  loss_giou_4: 1.170  time: 0.2927  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:05:19 d2.utils.events]: \u001b[0m eta: 3 days, 20:24:44  iter: 2441619  total_loss: 164.445  loss_ce: 0.165  loss_bbox: 0.308  loss_giou: 1.252  loss_ce_0: 0.175  loss_bbox_0: 0.295  loss_giou_0: 1.246  loss_ce_1: 0.169  loss_bbox_1: 0.295  loss_giou_1: 1.216  loss_ce_2: 0.168  loss_bbox_2: 0.321  loss_giou_2: 1.343  loss_ce_3: 0.173  loss_bbox_3: 0.295  loss_giou_3: 1.268  loss_ce_4: 0.165  loss_bbox_4: 0.266  loss_giou_4: 1.319  time: 0.2926  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:05:25 d2.utils.events]: \u001b[0m eta: 3 days, 20:21:22  iter: 2441639  total_loss: 122.983  loss_ce: 0.070  loss_bbox: 0.393  loss_giou: 0.882  loss_ce_0: 0.066  loss_bbox_0: 0.467  loss_giou_0: 1.001  loss_ce_1: 0.070  loss_bbox_1: 0.389  loss_giou_1: 0.931  loss_ce_2: 0.066  loss_bbox_2: 0.351  loss_giou_2: 0.914  loss_ce_3: 0.070  loss_bbox_3: 0.450  loss_giou_3: 0.890  loss_ce_4: 0.068  loss_bbox_4: 0.406  loss_giou_4: 1.006  time: 0.2925  data_time: 0.0020  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:05:30 d2.utils.events]: \u001b[0m eta: 3 days, 20:18:44  iter: 2441659  total_loss: 126.401  loss_ce: 0.081  loss_bbox: 0.315  loss_giou: 0.909  loss_ce_0: 0.079  loss_bbox_0: 0.329  loss_giou_0: 0.997  loss_ce_1: 0.084  loss_bbox_1: 0.346  loss_giou_1: 1.047  loss_ce_2: 0.077  loss_bbox_2: 0.336  loss_giou_2: 1.002  loss_ce_3: 0.089  loss_bbox_3: 0.298  loss_giou_3: 0.958  loss_ce_4: 0.083  loss_bbox_4: 0.310  loss_giou_4: 0.919  time: 0.2925  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:05:36 d2.utils.events]: \u001b[0m eta: 3 days, 20:15:43  iter: 2441679  total_loss: 115.354  loss_ce: 0.054  loss_bbox: 0.330  loss_giou: 0.950  loss_ce_0: 0.049  loss_bbox_0: 0.280  loss_giou_0: 0.885  loss_ce_1: 0.054  loss_bbox_1: 0.318  loss_giou_1: 0.893  loss_ce_2: 0.050  loss_bbox_2: 0.300  loss_giou_2: 0.846  loss_ce_3: 0.054  loss_bbox_3: 0.290  loss_giou_3: 0.885  loss_ce_4: 0.057  loss_bbox_4: 0.278  loss_giou_4: 0.795  time: 0.2924  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:05:42 d2.utils.events]: \u001b[0m eta: 3 days, 20:17:49  iter: 2441699  total_loss: 118.783  loss_ce: 0.063  loss_bbox: 0.265  loss_giou: 0.984  loss_ce_0: 0.057  loss_bbox_0: 0.284  loss_giou_0: 0.840  loss_ce_1: 0.063  loss_bbox_1: 0.301  loss_giou_1: 0.982  loss_ce_2: 0.058  loss_bbox_2: 0.292  loss_giou_2: 1.002  loss_ce_3: 0.062  loss_bbox_3: 0.268  loss_giou_3: 0.913  loss_ce_4: 0.061  loss_bbox_4: 0.287  loss_giou_4: 0.929  time: 0.2923  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:05:47 d2.utils.events]: \u001b[0m eta: 3 days, 20:10:31  iter: 2441719  total_loss: 131.291  loss_ce: 0.090  loss_bbox: 0.365  loss_giou: 1.160  loss_ce_0: 0.086  loss_bbox_0: 0.368  loss_giou_0: 1.276  loss_ce_1: 0.090  loss_bbox_1: 0.309  loss_giou_1: 1.202  loss_ce_2: 0.087  loss_bbox_2: 0.365  loss_giou_2: 1.187  loss_ce_3: 0.090  loss_bbox_3: 0.331  loss_giou_3: 1.084  loss_ce_4: 0.092  loss_bbox_4: 0.359  loss_giou_4: 1.176  time: 0.2922  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:05:53 d2.utils.events]: \u001b[0m eta: 3 days, 20:07:02  iter: 2441739  total_loss: 132.449  loss_ce: 0.090  loss_bbox: 0.309  loss_giou: 1.043  loss_ce_0: 0.091  loss_bbox_0: 0.309  loss_giou_0: 0.921  loss_ce_1: 0.094  loss_bbox_1: 0.288  loss_giou_1: 1.071  loss_ce_2: 0.091  loss_bbox_2: 0.338  loss_giou_2: 1.140  loss_ce_3: 0.094  loss_bbox_3: 0.326  loss_giou_3: 1.060  loss_ce_4: 0.092  loss_bbox_4: 0.337  loss_giou_4: 1.091  time: 0.2921  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:05:59 d2.utils.events]: \u001b[0m eta: 3 days, 20:02:09  iter: 2441759  total_loss: 119.140  loss_ce: 0.070  loss_bbox: 0.313  loss_giou: 0.919  loss_ce_0: 0.068  loss_bbox_0: 0.379  loss_giou_0: 0.950  loss_ce_1: 0.073  loss_bbox_1: 0.354  loss_giou_1: 0.867  loss_ce_2: 0.066  loss_bbox_2: 0.359  loss_giou_2: 0.816  loss_ce_3: 0.070  loss_bbox_3: 0.421  loss_giou_3: 0.943  loss_ce_4: 0.068  loss_bbox_4: 0.383  loss_giou_4: 0.955  time: 0.2920  data_time: 0.0020  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:06:05 d2.utils.events]: \u001b[0m eta: 3 days, 20:06:50  iter: 2441779  total_loss: 149.720  loss_ce: 0.131  loss_bbox: 0.354  loss_giou: 1.301  loss_ce_0: 0.130  loss_bbox_0: 0.351  loss_giou_0: 1.219  loss_ce_1: 0.136  loss_bbox_1: 0.336  loss_giou_1: 1.272  loss_ce_2: 0.132  loss_bbox_2: 0.363  loss_giou_2: 1.272  loss_ce_3: 0.137  loss_bbox_3: 0.329  loss_giou_3: 1.365  loss_ce_4: 0.129  loss_bbox_4: 0.346  loss_giou_4: 1.324  time: 0.2921  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:06:11 d2.utils.events]: \u001b[0m eta: 3 days, 20:10:08  iter: 2441799  total_loss: 136.959  loss_ce: 0.101  loss_bbox: 0.339  loss_giou: 1.018  loss_ce_0: 0.101  loss_bbox_0: 0.300  loss_giou_0: 1.026  loss_ce_1: 0.107  loss_bbox_1: 0.293  loss_giou_1: 1.082  loss_ce_2: 0.101  loss_bbox_2: 0.295  loss_giou_2: 1.112  loss_ce_3: 0.101  loss_bbox_3: 0.292  loss_giou_3: 1.054  loss_ce_4: 0.098  loss_bbox_4: 0.290  loss_giou_4: 1.120  time: 0.2922  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:06:17 d2.utils.events]: \u001b[0m eta: 3 days, 20:05:34  iter: 2441819  total_loss: 126.139  loss_ce: 0.074  loss_bbox: 0.350  loss_giou: 0.950  loss_ce_0: 0.069  loss_bbox_0: 0.294  loss_giou_0: 0.987  loss_ce_1: 0.076  loss_bbox_1: 0.364  loss_giou_1: 1.133  loss_ce_2: 0.071  loss_bbox_2: 0.311  loss_giou_2: 0.871  loss_ce_3: 0.072  loss_bbox_3: 0.308  loss_giou_3: 0.836  loss_ce_4: 0.069  loss_bbox_4: 0.317  loss_giou_4: 0.844  time: 0.2922  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:06:22 d2.utils.events]: \u001b[0m eta: 3 days, 19:58:53  iter: 2441839  total_loss: 128.362  loss_ce: 0.081  loss_bbox: 0.300  loss_giou: 0.987  loss_ce_0: 0.083  loss_bbox_0: 0.307  loss_giou_0: 0.971  loss_ce_1: 0.083  loss_bbox_1: 0.317  loss_giou_1: 1.037  loss_ce_2: 0.082  loss_bbox_2: 0.318  loss_giou_2: 1.069  loss_ce_3: 0.083  loss_bbox_3: 0.295  loss_giou_3: 1.001  loss_ce_4: 0.084  loss_bbox_4: 0.318  loss_giou_4: 1.034  time: 0.2920  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:06:28 d2.utils.events]: \u001b[0m eta: 3 days, 19:56:41  iter: 2441859  total_loss: 121.547  loss_ce: 0.067  loss_bbox: 0.333  loss_giou: 1.046  loss_ce_0: 0.065  loss_bbox_0: 0.276  loss_giou_0: 1.015  loss_ce_1: 0.067  loss_bbox_1: 0.295  loss_giou_1: 1.081  loss_ce_2: 0.069  loss_bbox_2: 0.268  loss_giou_2: 1.051  loss_ce_3: 0.064  loss_bbox_3: 0.248  loss_giou_3: 1.012  loss_ce_4: 0.064  loss_bbox_4: 0.316  loss_giou_4: 1.161  time: 0.2919  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:06:34 d2.utils.events]: \u001b[0m eta: 3 days, 19:57:35  iter: 2441879  total_loss: 125.385  loss_ce: 0.080  loss_bbox: 0.317  loss_giou: 1.003  loss_ce_0: 0.081  loss_bbox_0: 0.337  loss_giou_0: 1.123  loss_ce_1: 0.083  loss_bbox_1: 0.351  loss_giou_1: 1.115  loss_ce_2: 0.083  loss_bbox_2: 0.345  loss_giou_2: 0.979  loss_ce_3: 0.081  loss_bbox_3: 0.283  loss_giou_3: 0.946  loss_ce_4: 0.076  loss_bbox_4: 0.304  loss_giou_4: 1.142  time: 0.2920  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:06:40 d2.utils.events]: \u001b[0m eta: 3 days, 19:58:36  iter: 2441899  total_loss: 132.274  loss_ce: 0.099  loss_bbox: 0.295  loss_giou: 1.034  loss_ce_0: 0.099  loss_bbox_0: 0.258  loss_giou_0: 1.000  loss_ce_1: 0.100  loss_bbox_1: 0.270  loss_giou_1: 0.985  loss_ce_2: 0.098  loss_bbox_2: 0.315  loss_giou_2: 1.041  loss_ce_3: 0.100  loss_bbox_3: 0.272  loss_giou_3: 1.054  loss_ce_4: 0.098  loss_bbox_4: 0.286  loss_giou_4: 0.994  time: 0.2919  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:06:45 d2.utils.events]: \u001b[0m eta: 3 days, 19:56:24  iter: 2441919  total_loss: 113.408  loss_ce: 0.050  loss_bbox: 0.309  loss_giou: 0.835  loss_ce_0: 0.052  loss_bbox_0: 0.330  loss_giou_0: 0.732  loss_ce_1: 0.052  loss_bbox_1: 0.351  loss_giou_1: 0.842  loss_ce_2: 0.054  loss_bbox_2: 0.255  loss_giou_2: 0.702  loss_ce_3: 0.049  loss_bbox_3: 0.350  loss_giou_3: 0.872  loss_ce_4: 0.050  loss_bbox_4: 0.356  loss_giou_4: 0.796  time: 0.2918  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:06:51 d2.utils.events]: \u001b[0m eta: 3 days, 19:57:18  iter: 2441939  total_loss: 125.512  loss_ce: 0.074  loss_bbox: 0.358  loss_giou: 1.132  loss_ce_0: 0.078  loss_bbox_0: 0.334  loss_giou_0: 1.017  loss_ce_1: 0.079  loss_bbox_1: 0.354  loss_giou_1: 1.060  loss_ce_2: 0.077  loss_bbox_2: 0.328  loss_giou_2: 1.061  loss_ce_3: 0.078  loss_bbox_3: 0.325  loss_giou_3: 0.956  loss_ce_4: 0.077  loss_bbox_4: 0.338  loss_giou_4: 1.050  time: 0.2918  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:06:57 d2.utils.events]: \u001b[0m eta: 3 days, 19:55:48  iter: 2441959  total_loss: 120.119  loss_ce: 0.075  loss_bbox: 0.334  loss_giou: 0.917  loss_ce_0: 0.074  loss_bbox_0: 0.351  loss_giou_0: 0.977  loss_ce_1: 0.076  loss_bbox_1: 0.284  loss_giou_1: 0.967  loss_ce_2: 0.079  loss_bbox_2: 0.295  loss_giou_2: 0.872  loss_ce_3: 0.075  loss_bbox_3: 0.258  loss_giou_3: 0.841  loss_ce_4: 0.077  loss_bbox_4: 0.311  loss_giou_4: 0.927  time: 0.2917  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:07:03 d2.utils.events]: \u001b[0m eta: 3 days, 19:48:56  iter: 2441979  total_loss: 163.506  loss_ce: 0.186  loss_bbox: 0.330  loss_giou: 1.384  loss_ce_0: 0.184  loss_bbox_0: 0.381  loss_giou_0: 1.349  loss_ce_1: 0.182  loss_bbox_1: 0.359  loss_giou_1: 1.354  loss_ce_2: 0.182  loss_bbox_2: 0.326  loss_giou_2: 1.339  loss_ce_3: 0.183  loss_bbox_3: 0.300  loss_giou_3: 1.254  loss_ce_4: 0.182  loss_bbox_4: 0.357  loss_giou_4: 1.347  time: 0.2920  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:07:09 d2.utils.events]: \u001b[0m eta: 3 days, 19:48:50  iter: 2441999  total_loss: 124.152  loss_ce: 0.087  loss_bbox: 0.408  loss_giou: 1.076  loss_ce_0: 0.091  loss_bbox_0: 0.439  loss_giou_0: 1.019  loss_ce_1: 0.090  loss_bbox_1: 0.346  loss_giou_1: 0.897  loss_ce_2: 0.094  loss_bbox_2: 0.337  loss_giou_2: 0.934  loss_ce_3: 0.084  loss_bbox_3: 0.406  loss_giou_3: 0.930  loss_ce_4: 0.090  loss_bbox_4: 0.412  loss_giou_4: 1.027  time: 0.2920  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:07:15 d2.utils.events]: \u001b[0m eta: 3 days, 19:55:13  iter: 2442019  total_loss: 124.352  loss_ce: 0.089  loss_bbox: 0.315  loss_giou: 1.029  loss_ce_0: 0.088  loss_bbox_0: 0.300  loss_giou_0: 1.064  loss_ce_1: 0.091  loss_bbox_1: 0.298  loss_giou_1: 1.071  loss_ce_2: 0.091  loss_bbox_2: 0.304  loss_giou_2: 0.976  loss_ce_3: 0.085  loss_bbox_3: 0.319  loss_giou_3: 1.053  loss_ce_4: 0.092  loss_bbox_4: 0.354  loss_giou_4: 1.233  time: 0.2920  data_time: 0.0020  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:07:21 d2.utils.events]: \u001b[0m eta: 3 days, 19:49:55  iter: 2442039  total_loss: 122.696  loss_ce: 0.083  loss_bbox: 0.315  loss_giou: 1.092  loss_ce_0: 0.090  loss_bbox_0: 0.331  loss_giou_0: 1.021  loss_ce_1: 0.087  loss_bbox_1: 0.292  loss_giou_1: 1.098  loss_ce_2: 0.084  loss_bbox_2: 0.308  loss_giou_2: 1.009  loss_ce_3: 0.082  loss_bbox_3: 0.282  loss_giou_3: 1.116  loss_ce_4: 0.089  loss_bbox_4: 0.312  loss_giou_4: 1.044  time: 0.2920  data_time: 0.0022  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:07:26 d2.utils.events]: \u001b[0m eta: 3 days, 19:55:20  iter: 2442059  total_loss: 125.603  loss_ce: 0.085  loss_bbox: 0.333  loss_giou: 0.920  loss_ce_0: 0.090  loss_bbox_0: 0.339  loss_giou_0: 0.942  loss_ce_1: 0.092  loss_bbox_1: 0.303  loss_giou_1: 1.058  loss_ce_2: 0.094  loss_bbox_2: 0.286  loss_giou_2: 1.009  loss_ce_3: 0.088  loss_bbox_3: 0.320  loss_giou_3: 1.060  loss_ce_4: 0.096  loss_bbox_4: 0.329  loss_giou_4: 0.970  time: 0.2919  data_time: 0.0020  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:07:32 d2.utils.events]: \u001b[0m eta: 3 days, 19:56:38  iter: 2442079  total_loss: 120.543  loss_ce: 0.078  loss_bbox: 0.358  loss_giou: 0.972  loss_ce_0: 0.081  loss_bbox_0: 0.397  loss_giou_0: 1.025  loss_ce_1: 0.080  loss_bbox_1: 0.402  loss_giou_1: 0.976  loss_ce_2: 0.079  loss_bbox_2: 0.297  loss_giou_2: 0.968  loss_ce_3: 0.070  loss_bbox_3: 0.359  loss_giou_3: 0.927  loss_ce_4: 0.083  loss_bbox_4: 0.371  loss_giou_4: 1.063  time: 0.2920  data_time: 0.0019  lr: 0.000100  max_mem: 6548M\n",
            "\u001b[32m[08/18 20:07:38 d2.utils.events]: \u001b[0m eta: 3 days, 19:58:25  iter: 2442099  total_loss: 119.605  loss_ce: 0.074  loss_bbox: 0.262  loss_giou: 0.936  loss_ce_0: 0.072  loss_bbox_0: 0.344  loss_giou_0: 0.962  loss_ce_1: 0.076  loss_bbox_1: 0.349  loss_giou_1: 0.936  loss_ce_2: 0.074  loss_bbox_2: 0.335  loss_giou_2: 0.971  loss_ce_3: 0.067  loss_bbox_3: 0.327  loss_giou_3: 0.934  loss_ce_4: 0.077  loss_bbox_4: 0.315  loss_giou_4: 0.877  time: 0.2919  data_time: 0.0018  lr: 0.000100  max_mem: 6548M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oehRmfi00F_t",
        "colab_type": "text"
      },
      "source": [
        "Użycie modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLLN3H_E0GR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"face_val\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkWwYijgQ61c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = Trainer(cfg) \n",
        "trainer.resume_or_load(resume=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02GIDL6O0GYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dicts = val\n",
        "for d in random.sample(dataset_dicts, 1):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im,metadata=faces_metadata, scale=0.5)\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G60JHKE01Kdy",
        "colab_type": "text"
      },
      "source": [
        "AP metric on val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn2C4HA31Kkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "evaluator = COCOEvaluator(\"face_val\", cfg, False, output_dir=\"./Output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"face_val\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}